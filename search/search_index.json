{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Presidio : Data Protection and Anonymization SDK Presidio (Origin from Latin praesidium \u2018protection, garrison\u2019) helps to ensure sensitive data is properly managed and governed. It provides fast identification and anonymization modules for private entities in text and images such as credit card numbers, names, locations, social security numbers, bitcoin wallets, US phone numbers, financial data and more. Goals Allow organizations to preserve privacy in a simpler way by democratizing de-identification technologies and introducing transparency in decisions. Embrace extensibility and customizability to a specific business need. Facilitate both fully automated and semi-automated PII de-identification flows on multiple platforms. How it works Main features Predefined or custom PII recognizers leveraging Named Entity Recognition , regular expressions , rule based logic and checksum with relevant context in multiple languages. Options for connecting to external PII detection models. Multiple usage options, from Python or PySpark workloads through Docker to Kubernetes . Customizability in PII identification and anonymization. Module for redacting PII text in images . Warning Presidio can help identify sensitive/PII data in un/structured text. However, because Presidio is using trained ML models, there is no guarantee that Presidio will find all sensitive information. Consequently, additional systems and protections should be employed. Demo Try Presidio with your own data Presidio's modules Presidio analyzer : PII identification in text Presidio anonymizer : Anonymize detected PII entities using different anonymizers Presidio image redactor : Redact PII entities from images using OCR and PII identification Installing Presidio Using pip Using Docker From source Running Presidio Running Presidio via code Running Presidio as an HTTP service Setting up a development environment Perform PII identification using presidio-analyzer Perform PII anonymization using presidio-anonymizer Perform PII identification and anonymization in images using presidio-image-redactor Example deployments Support Before you submit an issue, please go over the documentation. For general discussions, please use the Github repo's discussion board . If you have a usage question, found a bug or have a suggestion for improvement, please file a Github issue . For other matters, please email presidio@microsoft.com .","title":"Home"},{"location":"#presidio-data-protection-and-anonymization-sdk","text":"Presidio (Origin from Latin praesidium \u2018protection, garrison\u2019) helps to ensure sensitive data is properly managed and governed. It provides fast identification and anonymization modules for private entities in text and images such as credit card numbers, names, locations, social security numbers, bitcoin wallets, US phone numbers, financial data and more.","title":"Presidio: Data Protection and Anonymization SDK"},{"location":"#goals","text":"Allow organizations to preserve privacy in a simpler way by democratizing de-identification technologies and introducing transparency in decisions. Embrace extensibility and customizability to a specific business need. Facilitate both fully automated and semi-automated PII de-identification flows on multiple platforms.","title":"Goals"},{"location":"#how-it-works","text":"","title":"How it works"},{"location":"#main-features","text":"Predefined or custom PII recognizers leveraging Named Entity Recognition , regular expressions , rule based logic and checksum with relevant context in multiple languages. Options for connecting to external PII detection models. Multiple usage options, from Python or PySpark workloads through Docker to Kubernetes . Customizability in PII identification and anonymization. Module for redacting PII text in images . Warning Presidio can help identify sensitive/PII data in un/structured text. However, because Presidio is using trained ML models, there is no guarantee that Presidio will find all sensitive information. Consequently, additional systems and protections should be employed.","title":"Main features"},{"location":"#demo","text":"Try Presidio with your own data","title":"Demo"},{"location":"#presidios-modules","text":"Presidio analyzer : PII identification in text Presidio anonymizer : Anonymize detected PII entities using different anonymizers Presidio image redactor : Redact PII entities from images using OCR and PII identification","title":"Presidio's modules"},{"location":"#installing-presidio","text":"Using pip Using Docker From source","title":"Installing Presidio"},{"location":"#running-presidio","text":"Running Presidio via code Running Presidio as an HTTP service Setting up a development environment Perform PII identification using presidio-analyzer Perform PII anonymization using presidio-anonymizer Perform PII identification and anonymization in images using presidio-image-redactor Example deployments","title":"Running Presidio"},{"location":"#support","text":"Before you submit an issue, please go over the documentation. For general discussions, please use the Github repo's discussion board . If you have a usage question, found a bug or have a suggestion for improvement, please file a Github issue . For other matters, please email presidio@microsoft.com .","title":"Support"},{"location":"api/","text":"Presidio API Api reference for Presidio's main python modules Presidio analyzer Python API reference Presidio anonymizer Python API reference Presidio image redactor Python API reference","title":"Presidio API"},{"location":"api/#presidio-api","text":"Api reference for Presidio's main python modules Presidio analyzer Python API reference Presidio anonymizer Python API reference Presidio image redactor Python API reference","title":"Presidio API"},{"location":"build_release/","text":"Build and release process Presidio leverages Azure DevOps YAML pipelines to validate, build, release and deliver presidio. The pipelines make use of templates for code reuse using YAML Schema . Description The following pipelines are provided and maintained as part of presidio development process: PR Validation - used to validate pull requests. Linting Security and compliance analysis Unit tests E2E tests CI - triggered on merge to main branch. Linting Security and compliance analysis Unit tests E2E tests deploys the artifacts to an internal dev environment. Release - manually triggered. releases presidio official artifacts pypi Microsoft container registry (and docker hub) GitHub updates the official demo environment. Variables used by the pipelines CI Pipeline ACR_AZURE_SUBSCRIPTION - Service connection to Azure subscription where Azure Container Registry is. ACR_REGISTRY_NAME - Name of Azure Container Registry. ANALYZER_DEV_APP_NAME - Name of existing App Service for Analyzer (development environment). ANONYMIZER_DEV_APP_NAME - Name of existing App Service for Anonymizer (development environment). IMAGE_REDACTOR_DEV_APP_NAME - Name of existing App Service for Image Redactor (development environment). DEV_AZURE_SUBSCRIPTION - Service connection to Azure subscription where App Services are (development environment). DEV_RESOURCE_GROUP_NAME - Name of resource group where App Services are (development environment). Release Pipeline ACR_AZURE_SUBSCRIPTION - Service connection to Azure subscription where Azure Container Registry is. ACR_REGISTRY_NAME - Name of Azure Container Registry. ANALYZER_PROD_APP_NAME - Name of existing App Service for Analyzer (production environment). ANONYMIZER_PROD_APP_NAME - Name of existing App Service for Anonymizer (production environment). PROD_AZURE_SUBSCRIPTION - Service connection to Azure subscription where App Services are (production environment). PROD_RESOURCE_GROUP_NAME - Name of resource group where App Services are (production environment). Import a pipeline to Azure Devops Sign in to your Azure DevOps organization and navigate to your project. In your project, navigate to the Pipelines page. Then choose the action to create a new pipeline. Walk through the steps of the wizard by first selecting 'Use the classic editor, and select GitHub as the location of your source code. You might be redirected to GitHub to sign in. If so, enter your GitHub credentials. When the list of repositories appears, select presidio repository. Point Azure Pipelines to the relevant yaml definition you'd like to import. Set the pipeline's name, the required triggers and variables and Select Save and run. A new run is started. Wait for the run to finish.","title":"Build and release process"},{"location":"build_release/#build-and-release-process","text":"Presidio leverages Azure DevOps YAML pipelines to validate, build, release and deliver presidio. The pipelines make use of templates for code reuse using YAML Schema .","title":"Build and release process"},{"location":"build_release/#description","text":"The following pipelines are provided and maintained as part of presidio development process: PR Validation - used to validate pull requests. Linting Security and compliance analysis Unit tests E2E tests CI - triggered on merge to main branch. Linting Security and compliance analysis Unit tests E2E tests deploys the artifacts to an internal dev environment. Release - manually triggered. releases presidio official artifacts pypi Microsoft container registry (and docker hub) GitHub updates the official demo environment.","title":"Description"},{"location":"build_release/#variables-used-by-the-pipelines","text":"","title":"Variables used by the pipelines"},{"location":"build_release/#ci-pipeline","text":"ACR_AZURE_SUBSCRIPTION - Service connection to Azure subscription where Azure Container Registry is. ACR_REGISTRY_NAME - Name of Azure Container Registry. ANALYZER_DEV_APP_NAME - Name of existing App Service for Analyzer (development environment). ANONYMIZER_DEV_APP_NAME - Name of existing App Service for Anonymizer (development environment). IMAGE_REDACTOR_DEV_APP_NAME - Name of existing App Service for Image Redactor (development environment). DEV_AZURE_SUBSCRIPTION - Service connection to Azure subscription where App Services are (development environment). DEV_RESOURCE_GROUP_NAME - Name of resource group where App Services are (development environment).","title":"CI Pipeline"},{"location":"build_release/#release-pipeline","text":"ACR_AZURE_SUBSCRIPTION - Service connection to Azure subscription where Azure Container Registry is. ACR_REGISTRY_NAME - Name of Azure Container Registry. ANALYZER_PROD_APP_NAME - Name of existing App Service for Analyzer (production environment). ANONYMIZER_PROD_APP_NAME - Name of existing App Service for Anonymizer (production environment). PROD_AZURE_SUBSCRIPTION - Service connection to Azure subscription where App Services are (production environment). PROD_RESOURCE_GROUP_NAME - Name of resource group where App Services are (production environment).","title":"Release Pipeline"},{"location":"build_release/#import-a-pipeline-to-azure-devops","text":"Sign in to your Azure DevOps organization and navigate to your project. In your project, navigate to the Pipelines page. Then choose the action to create a new pipeline. Walk through the steps of the wizard by first selecting 'Use the classic editor, and select GitHub as the location of your source code. You might be redirected to GitHub to sign in. If so, enter your GitHub credentials. When the list of repositories appears, select presidio repository. Point Azure Pipelines to the relevant yaml definition you'd like to import. Set the pipeline's name, the required triggers and variables and Select Save and run. A new run is started. Wait for the run to finish.","title":"Import a pipeline to Azure Devops"},{"location":"design/","text":"Presidio design Analyzer Anonymizer Image Redactor","title":"Design"},{"location":"design/#presidio-design","text":"","title":"Presidio design"},{"location":"design/#analyzer","text":"","title":"Analyzer"},{"location":"design/#anonymizer","text":"","title":"Anonymizer"},{"location":"design/#image-redactor","text":"","title":"Image Redactor"},{"location":"development/","text":"Setting Up a Development Environment Table of contents Getting started Cloning the repo To create a local copy of Presidio repository, follow Github instructions on how to clone a project using git. The project is structured so that: Each Presidio service has a designated directory: The service logic. Tests, both unit and integration. Serving it as an HTTP service (found in app.py). Python Packaging setup script (setup.py). In the project root directory, you will find common code for using, serving and testing Presidio as a cluster of services, as well as CI/CD pipelines codebase and documentation. Setting up Pipenv Pipenv is a Python workflow manager, handling dependencies and environment for Python packages. It is used by each Presidio service as the dependencies manager, to be aligned with the specific requirements versions. Follow these steps when starting to work on a Presidio service with Pipenv: Install Pipenv Using Pip pip install --user pipenv Using Homebrew (in MacOS) brew install pipenv Additional installation instructions for Pipenv: https://pipenv.readthedocs.io/en/latest/install/#installing-pipenv Have Pipenv create a virtualenv for the project and install all requirements in the Pipfile, including dev requirements. For example, in the presidio-analyzer folder, run: pipenv install --dev --sequential --skip-lock Run all tests: pipenv run pytest To run arbitrary scripts within the virtual env, start the command with pipenv run . For example: pipenv run flake8 pipenv run pip freeze pipenv run python -m spacy download en_core_web_lg Command 3 downloads the default spacy model needed for Presidio Analyzer.` Alternatively, activate the virtual environment and use the commands by starting a pipenv shell Start shell: pipenv shell Run commands in the shell pytest pip freeze Development guidelines A Github issue suggesting the change should be opened prior to a PR. All contributions should be documented, tested and linted. Please verify that all tests and lint checks pass successfully before proposing a change. To make the linting process easier, you can use pre-commit hooks to verify and automatically format code upon a git commit In order for a pull request to be accepted, the CI (containing unit tests, e2e tests and linting) needs to succeed, in addition to approvals from two maintainers. PRs should be small and solve/improve one issue at a time. If you have multiple suggestions for improvement, please open multiple PRs. Local build process After modifying presidio codebase, you might want to build presidio cluster locally, and run tests to spot regressions. The recommended way of doing so is using docker-compose (bundled with 'Docker Desktop' for Windows and Mac systems, more information can be found here ). Once installed, to start presidio cluster with all of its services in HTTP mode, run from the project root: docker-compose up --build -d Note Building for the first time might take some time, mainly on downloading the default spacy models. To validate that the services were built and started successfully, and to see the designated port for each, use docker-compose ps: >docker-compose ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 6d5a258d19c2 presidio-anonymizer \"/bin/sh -c 'pipenv \u2026\" 6 minutes ago Up 6 minutes 0 .0.0.0:5001->5001/tcp presidio_presidio-anonymizer_1 9aad2b68f93c presidio-analyzer \"/bin/sh -c 'pipenv \u2026\" 2 days ago Up 6 minutes 0 .0.0.0:5002->5001/tcp presidio_presidio-analyzer_1 1448dfb3ec2b presidio-image-redactor \"/bin/sh -c 'pipenv \u2026\" 2 seconds ago Up 2 seconds 0 .0.0.0:5003->5001/tcp presidio_presidio-image-redactor_1 Edit docker-compose.yml configuration file to change the default ports. Starting part of the cluster, or one service only, can be done by stating its image name as argument for docker-compose. For example for analyzer service: docker-compose up --build -d presidio-analyzer Testing We strive to have a full test coverage in Presidio, and expect every pull request to include tests. In each service directory, a 'test' directory can be found. In it, both unit tests, for testing single files or classes, and integration tests, for testing integration between the service components, or integration with external packages. Basic conventions For tests to be consistent and predictable, we use the following basic conventions: Treat tests as production code. Keep the tests concise and readable, with descriptive namings. Assert on one behavior at a time in each test. Test names should follow a pattern of test_when_[condition_to_test]_then_[expected_behavior] . For example: test_given_an_unknown_entity_then_anonymize_uses_defaults . Use test doubles and mocks when writing unit tests. Make less use of them when writing integration tests. Running tests Presidio uses the pytest framework for testing. See the pytest documentation for more information. Running the tests locally can be done in two ways: Using cli, from each service directory, run: pipenv run pytest Using your IDE. See configuration examples for JetBrains PyCharm / IntelliJ IDEA and Visual Studio Code End-to-end tests Since Presidio services can function as HTTP servers, Presidio uses an additional end-to-end (e2e) testing layer to test their REST APIs. This e2e test framework is located under 'e2e-tests' directory. In it, you can also find test scenarios testing the integration between Presidio services through REST API. These tests should be annotated with 'integration' pytest marker @pytest.mark.integration , while tests calling a single service API layer should be annotated with 'api' pytest marker @pytest.mark.api . Running the e2e-tests locally can be done in two ways: Using cli, from e2e-tests directory, run: On Mac / Linux / WSL: # Create a virtualenv named presidio-e2e (needs to be done only on the first run) python -m venv presidio-e2e # Activate the virtualenv source presidio-e2e/bin/activate # Install e2e-tests requirements using pip pip install -r requirements.txt # Run pytest pytest # Deactivate the virtualenv deactivate On Windows CMD / Powershell: # Create a virtualenv named presidio-e2e (needs to be done only on the first run) py -m venv presidio-e2e # Activate the virtualenv presidio-e2e \\S cripts \\a ctivate # Install e2e-tests requirements using pip pip install -r requirements.txt # Run pytest pytest # Deactivate the virtualenv deactivate Using your IDE See references in the section above. Note The e2e tests require a Presidio cluster to be up, for example using the containerized cluster with docker-compose. Build and run end-to-end tests locally Building and testing presidio locally, as explained above, can give good assurance on new changes and on regressions that might have introduced during development. As an easier method to build and automatically run end-to-end tests, is to use the run.bat script found in the project root: On Mac / Linux / WSL: chmod +x run.bat ./run.bat On Windows CMD / Powershell: run.bat Linting Presidio services are PEP8 compliant and continuously enforced on style guide issues during the build process using flake8 . Running flake8 locally, using pipenv run flake8 , you can check for those issues prior to committing a change. In addition to the basic flake8 functionality, Presidio uses the following extensions: pep8-naming : To check that variable names are PEP8 compliant. flake8-docstrings : To check that docstrings are compliant. Automatically format code and check for code styling To make the linting process easier, you can use pre-commit hooks to verify and automatically format code upon a git commit, using black : Install pre-commit package manager locally. From the project's root, enable pre-commit, installing git hooks in the .git/ directory by running: pre-commit install . Commit non PEP8 compliant code will cause commit failure and automatically format your code using black , as well as checking code formatting using flake8 ```sh >git commit -m 'autoformat' presidio-analyzer/presidio_analyzer/predefined_recognizers/us_ssn_recognizer.py black....................................................................Failed - hook id: black - files were modified by this hook reformatted presidio-analyzer/presidio_analyzer/predefined_recognizers/us_ssn_recognizer.py All done! 1 file reformatted. flake8...................................................................Passed ``` Committing again will finish successfully, with a well-formatted code.","title":"Setting up a development environment"},{"location":"development/#setting-up-a-development-environment","text":"","title":"Setting Up a Development Environment"},{"location":"development/#table-of-contents","text":"","title":"Table of contents"},{"location":"development/#getting-started","text":"","title":"Getting started"},{"location":"development/#cloning-the-repo","text":"To create a local copy of Presidio repository, follow Github instructions on how to clone a project using git. The project is structured so that: Each Presidio service has a designated directory: The service logic. Tests, both unit and integration. Serving it as an HTTP service (found in app.py). Python Packaging setup script (setup.py). In the project root directory, you will find common code for using, serving and testing Presidio as a cluster of services, as well as CI/CD pipelines codebase and documentation.","title":"Cloning the repo"},{"location":"development/#setting-up-pipenv","text":"Pipenv is a Python workflow manager, handling dependencies and environment for Python packages. It is used by each Presidio service as the dependencies manager, to be aligned with the specific requirements versions. Follow these steps when starting to work on a Presidio service with Pipenv: Install Pipenv Using Pip pip install --user pipenv Using Homebrew (in MacOS) brew install pipenv Additional installation instructions for Pipenv: https://pipenv.readthedocs.io/en/latest/install/#installing-pipenv Have Pipenv create a virtualenv for the project and install all requirements in the Pipfile, including dev requirements. For example, in the presidio-analyzer folder, run: pipenv install --dev --sequential --skip-lock Run all tests: pipenv run pytest To run arbitrary scripts within the virtual env, start the command with pipenv run . For example: pipenv run flake8 pipenv run pip freeze pipenv run python -m spacy download en_core_web_lg Command 3 downloads the default spacy model needed for Presidio Analyzer.`","title":"Setting up Pipenv"},{"location":"development/#alternatively-activate-the-virtual-environment-and-use-the-commands-by-starting-a-pipenv-shell","text":"Start shell: pipenv shell Run commands in the shell pytest pip freeze","title":"Alternatively, activate the virtual environment and use the commands by starting a pipenv shell"},{"location":"development/#development-guidelines","text":"A Github issue suggesting the change should be opened prior to a PR. All contributions should be documented, tested and linted. Please verify that all tests and lint checks pass successfully before proposing a change. To make the linting process easier, you can use pre-commit hooks to verify and automatically format code upon a git commit In order for a pull request to be accepted, the CI (containing unit tests, e2e tests and linting) needs to succeed, in addition to approvals from two maintainers. PRs should be small and solve/improve one issue at a time. If you have multiple suggestions for improvement, please open multiple PRs.","title":"Development guidelines"},{"location":"development/#local-build-process","text":"After modifying presidio codebase, you might want to build presidio cluster locally, and run tests to spot regressions. The recommended way of doing so is using docker-compose (bundled with 'Docker Desktop' for Windows and Mac systems, more information can be found here ). Once installed, to start presidio cluster with all of its services in HTTP mode, run from the project root: docker-compose up --build -d Note Building for the first time might take some time, mainly on downloading the default spacy models. To validate that the services were built and started successfully, and to see the designated port for each, use docker-compose ps: >docker-compose ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 6d5a258d19c2 presidio-anonymizer \"/bin/sh -c 'pipenv \u2026\" 6 minutes ago Up 6 minutes 0 .0.0.0:5001->5001/tcp presidio_presidio-anonymizer_1 9aad2b68f93c presidio-analyzer \"/bin/sh -c 'pipenv \u2026\" 2 days ago Up 6 minutes 0 .0.0.0:5002->5001/tcp presidio_presidio-analyzer_1 1448dfb3ec2b presidio-image-redactor \"/bin/sh -c 'pipenv \u2026\" 2 seconds ago Up 2 seconds 0 .0.0.0:5003->5001/tcp presidio_presidio-image-redactor_1 Edit docker-compose.yml configuration file to change the default ports. Starting part of the cluster, or one service only, can be done by stating its image name as argument for docker-compose. For example for analyzer service: docker-compose up --build -d presidio-analyzer","title":"Local build process"},{"location":"development/#testing","text":"We strive to have a full test coverage in Presidio, and expect every pull request to include tests. In each service directory, a 'test' directory can be found. In it, both unit tests, for testing single files or classes, and integration tests, for testing integration between the service components, or integration with external packages.","title":"Testing"},{"location":"development/#basic-conventions","text":"For tests to be consistent and predictable, we use the following basic conventions: Treat tests as production code. Keep the tests concise and readable, with descriptive namings. Assert on one behavior at a time in each test. Test names should follow a pattern of test_when_[condition_to_test]_then_[expected_behavior] . For example: test_given_an_unknown_entity_then_anonymize_uses_defaults . Use test doubles and mocks when writing unit tests. Make less use of them when writing integration tests.","title":"Basic conventions"},{"location":"development/#running-tests","text":"Presidio uses the pytest framework for testing. See the pytest documentation for more information. Running the tests locally can be done in two ways: Using cli, from each service directory, run: pipenv run pytest Using your IDE. See configuration examples for JetBrains PyCharm / IntelliJ IDEA and Visual Studio Code","title":"Running tests"},{"location":"development/#end-to-end-tests","text":"Since Presidio services can function as HTTP servers, Presidio uses an additional end-to-end (e2e) testing layer to test their REST APIs. This e2e test framework is located under 'e2e-tests' directory. In it, you can also find test scenarios testing the integration between Presidio services through REST API. These tests should be annotated with 'integration' pytest marker @pytest.mark.integration , while tests calling a single service API layer should be annotated with 'api' pytest marker @pytest.mark.api . Running the e2e-tests locally can be done in two ways: Using cli, from e2e-tests directory, run: On Mac / Linux / WSL: # Create a virtualenv named presidio-e2e (needs to be done only on the first run) python -m venv presidio-e2e # Activate the virtualenv source presidio-e2e/bin/activate # Install e2e-tests requirements using pip pip install -r requirements.txt # Run pytest pytest # Deactivate the virtualenv deactivate On Windows CMD / Powershell: # Create a virtualenv named presidio-e2e (needs to be done only on the first run) py -m venv presidio-e2e # Activate the virtualenv presidio-e2e \\S cripts \\a ctivate # Install e2e-tests requirements using pip pip install -r requirements.txt # Run pytest pytest # Deactivate the virtualenv deactivate Using your IDE See references in the section above. Note The e2e tests require a Presidio cluster to be up, for example using the containerized cluster with docker-compose.","title":"End-to-end tests"},{"location":"development/#build-and-run-end-to-end-tests-locally","text":"Building and testing presidio locally, as explained above, can give good assurance on new changes and on regressions that might have introduced during development. As an easier method to build and automatically run end-to-end tests, is to use the run.bat script found in the project root: On Mac / Linux / WSL: chmod +x run.bat ./run.bat On Windows CMD / Powershell: run.bat","title":"Build and run end-to-end tests locally"},{"location":"development/#linting","text":"Presidio services are PEP8 compliant and continuously enforced on style guide issues during the build process using flake8 . Running flake8 locally, using pipenv run flake8 , you can check for those issues prior to committing a change. In addition to the basic flake8 functionality, Presidio uses the following extensions: pep8-naming : To check that variable names are PEP8 compliant. flake8-docstrings : To check that docstrings are compliant.","title":"Linting"},{"location":"development/#automatically-format-code-and-check-for-code-styling","text":"To make the linting process easier, you can use pre-commit hooks to verify and automatically format code upon a git commit, using black : Install pre-commit package manager locally. From the project's root, enable pre-commit, installing git hooks in the .git/ directory by running: pre-commit install . Commit non PEP8 compliant code will cause commit failure and automatically format your code using black , as well as checking code formatting using flake8 ```sh >git commit -m 'autoformat' presidio-analyzer/presidio_analyzer/predefined_recognizers/us_ssn_recognizer.py black....................................................................Failed - hook id: black - files were modified by this hook reformatted presidio-analyzer/presidio_analyzer/predefined_recognizers/us_ssn_recognizer.py All done! 1 file reformatted. flake8...................................................................Passed ``` Committing again will finish successfully, with a well-formatted code.","title":"Automatically format code and check for code styling"},{"location":"getting_started/","text":"Getting started with Presidio Simple flow Using Presidio's modules as Python packages to get started Anonymize PII in text Install Presidio pip install presidio-analyzer pip install presidio-anonymizer python -m spacy download en_core_web_lg Analyze + Anonymize from presidio_analyzer import AnalyzerEngine from presidio_anonymizer import AnonymizerEngine text = \"My phone number is 212-555-5555\" # Set up the engine, loads the NLP module (spaCy model by default) # and other PII recognizers analyzer = AnalyzerEngine () # Call analyzer to get results results = analyzer . analyze ( text = text , entities = [ \"PHONE_NUMBER\" ], language = 'en' ) print ( results ) # Analyzer results are passed to the AnonymizerEngine for anonymization anonymizer = AnonymizerEngine () anonymized_text = anonymizer . anonymize ( text = text , analyzer_results = results ) print ( anonymized_text ) Anonymize PII in images Install presidio-image-redactor pip install presidio-image-redactor Redact PII from image from presidio_image_redactor import ImageRedactorEngine from PIL import Image image = Image . open ( path_to_image_file ) redactor = ImageRedactorEngine () redactor . redact ( image = image ) Read more Installing Presidio PII detection in text PII anonymization in text PII redaction in images","title":"Getting Started"},{"location":"getting_started/#getting-started-with-presidio","text":"","title":"Getting started with Presidio"},{"location":"getting_started/#simple-flow","text":"Using Presidio's modules as Python packages to get started Anonymize PII in text Install Presidio pip install presidio-analyzer pip install presidio-anonymizer python -m spacy download en_core_web_lg Analyze + Anonymize from presidio_analyzer import AnalyzerEngine from presidio_anonymizer import AnonymizerEngine text = \"My phone number is 212-555-5555\" # Set up the engine, loads the NLP module (spaCy model by default) # and other PII recognizers analyzer = AnalyzerEngine () # Call analyzer to get results results = analyzer . analyze ( text = text , entities = [ \"PHONE_NUMBER\" ], language = 'en' ) print ( results ) # Analyzer results are passed to the AnonymizerEngine for anonymization anonymizer = AnonymizerEngine () anonymized_text = anonymizer . anonymize ( text = text , analyzer_results = results ) print ( anonymized_text ) Anonymize PII in images Install presidio-image-redactor pip install presidio-image-redactor Redact PII from image from presidio_image_redactor import ImageRedactorEngine from PIL import Image image = Image . open ( path_to_image_file ) redactor = ImageRedactorEngine () redactor . redact ( image = image )","title":"Simple flow"},{"location":"getting_started/#read-more","text":"Installing Presidio PII detection in text PII anonymization in text PII redaction in images","title":"Read more"},{"location":"installation/","text":"Installing Presidio Description This document describes how to download and install the Presidio services locally. As Presidio is comprised of several packages/services, this document describes the installation of the entire Presidio suite using pip (as Python packages) or using Docker (As containerized services). Using pip Note Consider installing the Presidio python packages on a virtual environment like venv or conda . PII anonymization on text For PII anonymization on text, install the presidio-analyzer and presidio-anonymizer packages: pip install presidio_analyzer pip install presidio_anonymizer # Presidio analyzer requires a spaCy language model. python -m spacy download en_core_web_lg For a more detailed installation of each package, refer to the specific documentation: presidio-analyzer . presidio-anonymizer . PII redaction in images For PII redaction in images, install the presidio-image-redactor package: pip install presidio_image_redactor # Presidio image redactor uses the presidio-analyzer # which requires a spaCy language model: python -m spacy download en_core_web_lg Click here for more information on the presidio-image-redactor package. Using Docker Presidio can expose REST endpoints for each service using Flask and Docker. To download the Presidio Docker containers, run the following command: Note This requires Docker to be installed. Download Docker . For PII anonymization in text For PII detection and anonymization in text, the presidio-analyzer and presidio-anonymizer modules are required. # Download images docker pull mcr.microsoft.com/presidio-analyzer docker pull mcr.microsoft.com/presidio-anonymizer # Run containers with default ports docker run -d -p 5001 :5001 mcr.microsoft.com/presidio-analyzer:latest docker run -d -p 5002 :5001 mcr.microsoft.com/presidio-anonymizer:latest For PII redaction in images For PII detection in images, the presidio-image-redactor is required. # Download image docker pull mcr.microsoft.com/presidio-image-redactor # Run container with the default port docker run -d -p 5003 :5001 mcr.microsoft.com/presidio-image-redactor:latest Once the services are running, their APIs are available. API reference and example calls can be found here . Install from source To install Presidio from source, first clone the repo: using HTTPS git clone https://github.com/microsoft/presidio.git Using SSH git clone git@github.com:microsoft/presidio.git Then, build the containers locally. Note Presidio uses docker-compose to manage the different Presidio containers. From the root folder of the repo: docker-compose --build To run all Presidio services: docker-compose up -d Alternatively, you can build and run individual services. For example, for the presidio-anonymizer service: docker build ./presidio-anonymizer -t presidio/presidio-anonymizer And run: docker run -d -p 5002 :5001 presidio/presidio-anonymizer For more information on developing locally, refer to the setting up a development environment section.","title":"Installation"},{"location":"installation/#installing-presidio","text":"","title":"Installing Presidio"},{"location":"installation/#description","text":"This document describes how to download and install the Presidio services locally. As Presidio is comprised of several packages/services, this document describes the installation of the entire Presidio suite using pip (as Python packages) or using Docker (As containerized services).","title":"Description"},{"location":"installation/#using-pip","text":"Note Consider installing the Presidio python packages on a virtual environment like venv or conda .","title":"Using pip"},{"location":"installation/#pii-anonymization-on-text","text":"For PII anonymization on text, install the presidio-analyzer and presidio-anonymizer packages: pip install presidio_analyzer pip install presidio_anonymizer # Presidio analyzer requires a spaCy language model. python -m spacy download en_core_web_lg For a more detailed installation of each package, refer to the specific documentation: presidio-analyzer . presidio-anonymizer .","title":"PII anonymization on text"},{"location":"installation/#pii-redaction-in-images","text":"For PII redaction in images, install the presidio-image-redactor package: pip install presidio_image_redactor # Presidio image redactor uses the presidio-analyzer # which requires a spaCy language model: python -m spacy download en_core_web_lg Click here for more information on the presidio-image-redactor package.","title":"PII redaction in images"},{"location":"installation/#using-docker","text":"Presidio can expose REST endpoints for each service using Flask and Docker. To download the Presidio Docker containers, run the following command: Note This requires Docker to be installed. Download Docker .","title":"Using Docker"},{"location":"installation/#for-pii-anonymization-in-text","text":"For PII detection and anonymization in text, the presidio-analyzer and presidio-anonymizer modules are required. # Download images docker pull mcr.microsoft.com/presidio-analyzer docker pull mcr.microsoft.com/presidio-anonymizer # Run containers with default ports docker run -d -p 5001 :5001 mcr.microsoft.com/presidio-analyzer:latest docker run -d -p 5002 :5001 mcr.microsoft.com/presidio-anonymizer:latest","title":"For PII anonymization in text"},{"location":"installation/#for-pii-redaction-in-images","text":"For PII detection in images, the presidio-image-redactor is required. # Download image docker pull mcr.microsoft.com/presidio-image-redactor # Run container with the default port docker run -d -p 5003 :5001 mcr.microsoft.com/presidio-image-redactor:latest Once the services are running, their APIs are available. API reference and example calls can be found here .","title":"For PII redaction in images"},{"location":"installation/#install-from-source","text":"To install Presidio from source, first clone the repo: using HTTPS git clone https://github.com/microsoft/presidio.git Using SSH git clone git@github.com:microsoft/presidio.git Then, build the containers locally. Note Presidio uses docker-compose to manage the different Presidio containers. From the root folder of the repo: docker-compose --build To run all Presidio services: docker-compose up -d Alternatively, you can build and run individual services. For example, for the presidio-anonymizer service: docker build ./presidio-anonymizer -t presidio/presidio-anonymizer And run: docker run -d -p 5002 :5001 presidio/presidio-anonymizer For more information on developing locally, refer to the setting up a development environment section.","title":"Install from source"},{"location":"presidio_V2/","text":"Presidio Revamp (aka V2) As of March 2021, Presidio had undergo a revamp to a new version refereed to as V2 . The main changes introduced in V2 are: gRPC replaced with HTTP to allow more customizable APIs and easier debugging Focus on the Analyzer and Anonymizer services. Presidio Anonymizer is now Python based and pip installable. Presidio Analyzer does not use templates and external recognizer store. Image Redactor (formerly presidio-image-anonymizer) is in early beta and is Python based and pip installable. Other services are deprecated and potentially be migrated over time to V2 with the help of the community. Improved documentation, samples and build flows. Note The legacy V1 code base will continue to be available under branch V1 but will no longer be officially supported. API Changes The move from gRPC to HTTP based APIs included changes to the API requests. Change in payload - moving from structures to jsons. Removing templates from the API - includes flattening the json. Using snake_case instead of camelCase . Below is a detailed outline of all the changes done to the Analyzer and Anonymizer. Analyzer API Changes Legacy json request (gRPC) { \"text\" : \"My phone number is 212-555-5555\" , \"AnalyzeTemplateId\" : \"1234\" , \"AnalyzeTemplate\" : { \"Fields\" : [ { \"Name\" : \"PHONE_NUMBER\" , \"MinScore\" : \"0.5\" } ], \"AllFields\" : true , \"Description\" : \"template description\" , \"CreateTime\" : \"template creation time\" , \"ModifiedTime\" : \"template modification time\" , \"Language\" : \"fr\" , \"ResultsScoreThreshold\" : 0.5 } } V2 json request (HTTP) { \"text\" : \"My phone number is 212-555-5555\" , \"entities\" : [ \"PHONE_NUMBER\" ], \"language\" : \"en\" , \"correlation_id\" : \"213\" , \"score_threshold\" : 0.5 , \"trace\" : true , \"return_decision_process\" : true } Anonymizer API Changes Legacy json request (gRPC) { \"text\" : \"hello world, my name is Jane Doe. My number is: 034453334\" , \"template\" : { \"description\" : \"DEPRECATED\" , \"create_time\" : \"DEPRECATED\" , \"modified_time\" : \"DEPRECATED\" , \"default_transformation\" : { \"replace_value\" : { ... }, \"redact_value\" : { ... }, \"hash_value\" : { ... }, \"mask_value\" : { ... }, \"fpe_value\" : { ... } }, \"field_type_transformations\" : [ { \"fields\" : [ { \"name\" : \"FIRST_NAME\" , \"min_score\" : \"0.2\" } ], \"transfomarion\" : { \"replace_value\" : { ... }, \"redact_value\" : { ... }, \"hash_value\" : { ... }, \"mask_value\" : { ... }, \"fpe_value\" : { ... } } } ], \"analyze_results\" : [ { \"text\" : \"Jane\" , \"field\" : { \"name\" : \"FIRST_NAME\" , \"min_score\" : \"0.5\" }, \"location\" : { \"start\" : 24 , \"end\" : 32 , \"length\" : 6 }, \"score\" : 0.8 } ] } } V2 json request (HTTP) { \"text\" : \"hello world, my name is Jane Doe. My number is: 034453334\" , \"anonymizers\" : { \"DEFAULT\" : { \"type\" : \"replace\" , \"new_value\" : \"val\" }, \"PHONE_NUMBER\" : { \"type\" : \"mask\" , \"masking_char\" : \"*\" , \"chars_to_mask\" : 4 , \"from_end\" : true } }, \"analyzer_results\" : [ { \"start\" : 24 , \"end\" : 32 , \"score\" : 0.8 , \"entity_type\" : \"NAME\" }, { \"start\" : 24 , \"end\" : 28 , \"score\" : 0.8 , \"entity_type\" : \"FIRST_NAME\" }, { \"start\" : 29 , \"end\" : 32 , \"score\" : 0.6 , \"entity_type\" : \"LAST_NAME\" }, { \"start\" : 48 , \"end\" : 57 , \"score\" : 0.95 , \"entity_type\" : \"PHONE_NUMBER\" } ] } Specific for each anonymization type: Anonymization name Legacy format (V1) New json format (V2) Replace string newValue = 1; { \"new_value\": \"VALUE\" } Redact NONE NONE Mask string maskingCharacter = 1; int32 charsToMask = 2; bool fromEnd = 3; { \"chars_to_mask\": 10, \"from_end\": true, \"masking_char\": \"*\" } Hash NONE {\"hash_type\": \"VALUE\"}","title":"Changes from V1 to V2"},{"location":"presidio_V2/#presidio-revamp-aka-v2","text":"As of March 2021, Presidio had undergo a revamp to a new version refereed to as V2 . The main changes introduced in V2 are: gRPC replaced with HTTP to allow more customizable APIs and easier debugging Focus on the Analyzer and Anonymizer services. Presidio Anonymizer is now Python based and pip installable. Presidio Analyzer does not use templates and external recognizer store. Image Redactor (formerly presidio-image-anonymizer) is in early beta and is Python based and pip installable. Other services are deprecated and potentially be migrated over time to V2 with the help of the community. Improved documentation, samples and build flows. Note The legacy V1 code base will continue to be available under branch V1 but will no longer be officially supported.","title":"Presidio Revamp (aka V2)"},{"location":"presidio_V2/#api-changes","text":"The move from gRPC to HTTP based APIs included changes to the API requests. Change in payload - moving from structures to jsons. Removing templates from the API - includes flattening the json. Using snake_case instead of camelCase . Below is a detailed outline of all the changes done to the Analyzer and Anonymizer.","title":"API Changes"},{"location":"presidio_V2/#analyzer-api-changes","text":"","title":"Analyzer API Changes"},{"location":"presidio_V2/#legacy-json-request-grpc","text":"{ \"text\" : \"My phone number is 212-555-5555\" , \"AnalyzeTemplateId\" : \"1234\" , \"AnalyzeTemplate\" : { \"Fields\" : [ { \"Name\" : \"PHONE_NUMBER\" , \"MinScore\" : \"0.5\" } ], \"AllFields\" : true , \"Description\" : \"template description\" , \"CreateTime\" : \"template creation time\" , \"ModifiedTime\" : \"template modification time\" , \"Language\" : \"fr\" , \"ResultsScoreThreshold\" : 0.5 } }","title":"Legacy json request (gRPC)"},{"location":"presidio_V2/#v2-json-request-http","text":"{ \"text\" : \"My phone number is 212-555-5555\" , \"entities\" : [ \"PHONE_NUMBER\" ], \"language\" : \"en\" , \"correlation_id\" : \"213\" , \"score_threshold\" : 0.5 , \"trace\" : true , \"return_decision_process\" : true }","title":"V2 json request (HTTP)"},{"location":"presidio_V2/#anonymizer-api-changes","text":"","title":"Anonymizer API Changes"},{"location":"presidio_V2/#legacy-json-request-grpc_1","text":"{ \"text\" : \"hello world, my name is Jane Doe. My number is: 034453334\" , \"template\" : { \"description\" : \"DEPRECATED\" , \"create_time\" : \"DEPRECATED\" , \"modified_time\" : \"DEPRECATED\" , \"default_transformation\" : { \"replace_value\" : { ... }, \"redact_value\" : { ... }, \"hash_value\" : { ... }, \"mask_value\" : { ... }, \"fpe_value\" : { ... } }, \"field_type_transformations\" : [ { \"fields\" : [ { \"name\" : \"FIRST_NAME\" , \"min_score\" : \"0.2\" } ], \"transfomarion\" : { \"replace_value\" : { ... }, \"redact_value\" : { ... }, \"hash_value\" : { ... }, \"mask_value\" : { ... }, \"fpe_value\" : { ... } } } ], \"analyze_results\" : [ { \"text\" : \"Jane\" , \"field\" : { \"name\" : \"FIRST_NAME\" , \"min_score\" : \"0.5\" }, \"location\" : { \"start\" : 24 , \"end\" : 32 , \"length\" : 6 }, \"score\" : 0.8 } ] } }","title":"Legacy json request (gRPC)"},{"location":"presidio_V2/#v2-json-request-http_1","text":"{ \"text\" : \"hello world, my name is Jane Doe. My number is: 034453334\" , \"anonymizers\" : { \"DEFAULT\" : { \"type\" : \"replace\" , \"new_value\" : \"val\" }, \"PHONE_NUMBER\" : { \"type\" : \"mask\" , \"masking_char\" : \"*\" , \"chars_to_mask\" : 4 , \"from_end\" : true } }, \"analyzer_results\" : [ { \"start\" : 24 , \"end\" : 32 , \"score\" : 0.8 , \"entity_type\" : \"NAME\" }, { \"start\" : 24 , \"end\" : 28 , \"score\" : 0.8 , \"entity_type\" : \"FIRST_NAME\" }, { \"start\" : 29 , \"end\" : 32 , \"score\" : 0.6 , \"entity_type\" : \"LAST_NAME\" }, { \"start\" : 48 , \"end\" : 57 , \"score\" : 0.95 , \"entity_type\" : \"PHONE_NUMBER\" } ] } Specific for each anonymization type: Anonymization name Legacy format (V1) New json format (V2) Replace string newValue = 1; { \"new_value\": \"VALUE\" } Redact NONE NONE Mask string maskingCharacter = 1; int32 charsToMask = 2; bool fromEnd = 3; { \"chars_to_mask\": 10, \"from_end\": true, \"masking_char\": \"*\" } Hash NONE {\"hash_type\": \"VALUE\"}","title":"V2 json request (HTTP)"},{"location":"supported_entities/","text":"PII entities supported by Presidio Presidio contains predefined recognizers for PII entities. This page describes the different entities Presidio can detect and the method Presidio employs to detect those. In addition, Presidio allows you to add custom entity recognizers. For more information, refer to the adding new recognizers documentation . List of supported entities Global Entity Type Description Detection Method CREDIT_CARD A credit card number is between 12 to 19 digits. https://en.wikipedia.org/wiki/Payment_card_number Pattern match and checksum CRYPTO A Crypto wallet number. Currently only Bitcoin address is supported Pattern match, context and checksum DATE_TIME Absolute or relative dates or periods or times smaller than a day. Pattern match and context DOMAIN_NAME A domain name as defined by the DNS standard. Pattern match, context and top level domain validation EMAIL_ADDRESS An email address identifies an email box to which email messages are delivered Pattern match, context and RFC-822 validation IBAN_CODE The International Bank Account Number (IBAN) is an internationally agreed system of identifying bank accounts across national borders to facilitate the communication and processing of cross border transactions with a reduced risk of transcription errors. Pattern match, context and checksum IP_ADDRESS An Internet Protocol (IP) address (either IPv4 or IPv6). Pattern match, context and checksum NRP A person\u2019s Nationality, religious or political group. Custom logic and context LOCATION Name of politically or geographically defined location (cities, provinces, countries, international regions, bodies of water, mountains Custom logic and context PERSON A full person name, which can include first names, middle names or initials, and last names. Custom logic and context PHONE_NUMBER A telephone number Custom logic, pattern match and context USA FieldType Description Detection Method US_BANK_NUMBER A US bank account number is between 8 to 17 digits. Pattern match and context US_DRIVER_LICENSE A US driver license according to https://ntsi.com/drivers-license-format/ Pattern match and context US_ITIN US Individual Taxpayer Identification Number (ITIN). Nine digits that start with a \"9\" and contain a \"7\" or \"8\" as the 4 digit. Pattern match and context US_PASSPORT A US passport number with 9 digits. Pattern match and context US_SSN A US Social Security Number (SSN) with 9 digits. Pattern match and context UK FieldType Description Detection Method UK_NHS A UK NHS number is 10 digits. Pattern match, context and checksum Spain FieldType Description Detection Method NIF A spanish NIF number (Personal tax ID) . Pattern match, context and checksum Singapore FieldType Description Detection Method FIN/NRIC A National Registration Identification Card Pattern match and context Adding a custom PII entity See this documentation for instructions on how to add a new Recognizer for a new type of PII entity. Connecting to 3rd party PII detectors See this documentation for instructions on how to implement an external PII detector for a new or existing type of PII entity.","title":"Supported entities"},{"location":"supported_entities/#pii-entities-supported-by-presidio","text":"Presidio contains predefined recognizers for PII entities. This page describes the different entities Presidio can detect and the method Presidio employs to detect those. In addition, Presidio allows you to add custom entity recognizers. For more information, refer to the adding new recognizers documentation .","title":"PII entities supported by Presidio"},{"location":"supported_entities/#list-of-supported-entities","text":"","title":"List of supported entities"},{"location":"supported_entities/#global","text":"Entity Type Description Detection Method CREDIT_CARD A credit card number is between 12 to 19 digits. https://en.wikipedia.org/wiki/Payment_card_number Pattern match and checksum CRYPTO A Crypto wallet number. Currently only Bitcoin address is supported Pattern match, context and checksum DATE_TIME Absolute or relative dates or periods or times smaller than a day. Pattern match and context DOMAIN_NAME A domain name as defined by the DNS standard. Pattern match, context and top level domain validation EMAIL_ADDRESS An email address identifies an email box to which email messages are delivered Pattern match, context and RFC-822 validation IBAN_CODE The International Bank Account Number (IBAN) is an internationally agreed system of identifying bank accounts across national borders to facilitate the communication and processing of cross border transactions with a reduced risk of transcription errors. Pattern match, context and checksum IP_ADDRESS An Internet Protocol (IP) address (either IPv4 or IPv6). Pattern match, context and checksum NRP A person\u2019s Nationality, religious or political group. Custom logic and context LOCATION Name of politically or geographically defined location (cities, provinces, countries, international regions, bodies of water, mountains Custom logic and context PERSON A full person name, which can include first names, middle names or initials, and last names. Custom logic and context PHONE_NUMBER A telephone number Custom logic, pattern match and context","title":"Global"},{"location":"supported_entities/#usa","text":"FieldType Description Detection Method US_BANK_NUMBER A US bank account number is between 8 to 17 digits. Pattern match and context US_DRIVER_LICENSE A US driver license according to https://ntsi.com/drivers-license-format/ Pattern match and context US_ITIN US Individual Taxpayer Identification Number (ITIN). Nine digits that start with a \"9\" and contain a \"7\" or \"8\" as the 4 digit. Pattern match and context US_PASSPORT A US passport number with 9 digits. Pattern match and context US_SSN A US Social Security Number (SSN) with 9 digits. Pattern match and context","title":"USA"},{"location":"supported_entities/#uk","text":"FieldType Description Detection Method UK_NHS A UK NHS number is 10 digits. Pattern match, context and checksum","title":"UK"},{"location":"supported_entities/#spain","text":"FieldType Description Detection Method NIF A spanish NIF number (Personal tax ID) . Pattern match, context and checksum","title":"Spain"},{"location":"supported_entities/#singapore","text":"FieldType Description Detection Method FIN/NRIC A National Registration Identification Card Pattern match and context","title":"Singapore"},{"location":"supported_entities/#adding-a-custom-pii-entity","text":"See this documentation for instructions on how to add a new Recognizer for a new type of PII entity.","title":"Adding a custom PII entity"},{"location":"supported_entities/#connecting-to-3rd-party-pii-detectors","text":"See this documentation for instructions on how to implement an external PII detector for a new or existing type of PII entity.","title":"Connecting to 3rd party PII detectors"},{"location":"text_anonymization/","text":"Text anonymization Presidio's features two main modules for anonymization PII in text: Presidio analyzer : Identification PII in text Presidio anonymizer : Anonymize detected PII entities using different anonymizers","title":"Home"},{"location":"text_anonymization/#text-anonymization","text":"Presidio's features two main modules for anonymization PII in text: Presidio analyzer : Identification PII in text Presidio anonymizer : Anonymize detected PII entities using different anonymizers","title":"Text anonymization"},{"location":"analyzer/","text":"Presidio Analyzer The Presidio analyzer is a Python based service for detecting PII entities in text. During analysis, it runs a set of different PII Recognizers , each one in charge of detecting one or more PII entities using different mechanisms. Presidio analyzer comes with a set of predefined recognizers, but can easily be extended with other types of custom recognizers. Predefined and custom recognizers leverage regex, Named Entity Recognition and other types of logic to detect PII in unstructured text. Installation Using pip Note Consider installing the Presidio python packages on a virtual environment like venv or conda. To get started with Presidio-analyzer, download the package and the en_core_web_lg spaCy model: pip install presidio-analyzer python -m spacy download en_core_web_lg Using Docker Note This requires Docker to be installed. Download Docker . # Download image from Dockerhub docker pull mcr.microsoft.com/presidio-analyzer # Run the container with the default port docker run -d -p 5002 :5002 mcr.microsoft.com/presidio-analyzer:latest From source First, clone the Presidio repo. See here for instructions . Then, build the presidio-analyzer container: cd presidio-analyzer docker build . -t presidio/presidio-analyzer Getting started Python Once the Presidio-analyzer package is installed, run this simple analysis script: from presidio_analyzer import AnalyzerEngine # Set up the engine, loads the NLP module (spaCy model by default) and other PII recognizers analyzer = AnalyzerEngine () # Call analyzer to get results results = analyzer . analyze ( text = \"My phone number is 212-555-5555\" , entities = [ \"PHONE_NUMBER\" ], language = 'en' ) print ( results ) As an HTTP server You can run presidio analyzer as an http server using either python runtime or using a docker container. Using docker container cd presidio-analyzer docker run -p 5002 :5002 presidio-analyzer Using python runtime Note This requires the Presidio Github repository to be cloned. cd presidio-analyzer python app.py curl -d '{\"text\":\"John Smith drivers license is AC432223\", \"language\":\"en\"}' -H \"Content-Type: application/json\" -X POST http://localhost:3000/analyze Creating PII recognizers Presidio analyzer can be easily extended to support additional PII entities. See this tutorial on adding new PII recognizers for more information. Multi-language support Presidio can be used to detect PII entities in multiple languages. Refer to the multi-language support for more information. Outputting the analyzer decision process Presidio analyzer has a built in mechanism for tracing each decision made. This can be useful when attempting to understand a specific PII detection. For more info, see the decision process documentation. Supported entities For a list of the current supported entities: Supported entities . API reference Follow the API Spec for the Analyzer REST API reference details and Analyzer Python API for Python API reference","title":"Analyzer Home"},{"location":"analyzer/#presidio-analyzer","text":"The Presidio analyzer is a Python based service for detecting PII entities in text. During analysis, it runs a set of different PII Recognizers , each one in charge of detecting one or more PII entities using different mechanisms. Presidio analyzer comes with a set of predefined recognizers, but can easily be extended with other types of custom recognizers. Predefined and custom recognizers leverage regex, Named Entity Recognition and other types of logic to detect PII in unstructured text.","title":"Presidio Analyzer"},{"location":"analyzer/#installation","text":"Using pip Note Consider installing the Presidio python packages on a virtual environment like venv or conda. To get started with Presidio-analyzer, download the package and the en_core_web_lg spaCy model: pip install presidio-analyzer python -m spacy download en_core_web_lg Using Docker Note This requires Docker to be installed. Download Docker . # Download image from Dockerhub docker pull mcr.microsoft.com/presidio-analyzer # Run the container with the default port docker run -d -p 5002 :5002 mcr.microsoft.com/presidio-analyzer:latest From source First, clone the Presidio repo. See here for instructions . Then, build the presidio-analyzer container: cd presidio-analyzer docker build . -t presidio/presidio-analyzer","title":"Installation"},{"location":"analyzer/#getting-started","text":"Python Once the Presidio-analyzer package is installed, run this simple analysis script: from presidio_analyzer import AnalyzerEngine # Set up the engine, loads the NLP module (spaCy model by default) and other PII recognizers analyzer = AnalyzerEngine () # Call analyzer to get results results = analyzer . analyze ( text = \"My phone number is 212-555-5555\" , entities = [ \"PHONE_NUMBER\" ], language = 'en' ) print ( results ) As an HTTP server You can run presidio analyzer as an http server using either python runtime or using a docker container.","title":"Getting started"},{"location":"analyzer/#using-docker-container","text":"cd presidio-analyzer docker run -p 5002 :5002 presidio-analyzer","title":"Using docker container"},{"location":"analyzer/#using-python-runtime","text":"Note This requires the Presidio Github repository to be cloned. cd presidio-analyzer python app.py curl -d '{\"text\":\"John Smith drivers license is AC432223\", \"language\":\"en\"}' -H \"Content-Type: application/json\" -X POST http://localhost:3000/analyze","title":"Using python runtime"},{"location":"analyzer/#creating-pii-recognizers","text":"Presidio analyzer can be easily extended to support additional PII entities. See this tutorial on adding new PII recognizers for more information.","title":"Creating PII recognizers"},{"location":"analyzer/#multi-language-support","text":"Presidio can be used to detect PII entities in multiple languages. Refer to the multi-language support for more information.","title":"Multi-language support"},{"location":"analyzer/#outputting-the-analyzer-decision-process","text":"Presidio analyzer has a built in mechanism for tracing each decision made. This can be useful when attempting to understand a specific PII detection. For more info, see the decision process documentation.","title":"Outputting the analyzer decision process"},{"location":"analyzer/#supported-entities","text":"For a list of the current supported entities: Supported entities .","title":"Supported entities"},{"location":"analyzer/#api-reference","text":"Follow the API Spec for the Analyzer REST API reference details and Analyzer Python API for Python API reference","title":"API reference"},{"location":"analyzer/adding_recognizers/","text":"Supporting detection of new types of PII entities Presidio can be extended to support detection of new types of PII entities, and to support additional languages. Introduction to recognizer development Entity recognizers are Python objects capable of detecting one or more entities in a specific language. In order to extend Presidio's detection capabilities to new types of PII entities, these EntityRecognizer objects should be added to the existing list of recognizers. Types of recognizer classes in Presidio The following class diagram shows the different types of recognizer families Presidio contains. The EntityRecognizer is an abstract class for all recognizers. The RemoteRecognizer is an abstract class for calling external PII detectors. See more info here . The abstract class LocalRecognizer is implemented by all recognizers running within the Presidio-analyzer process. The PatternRecognizer is an class for supporting regex and deny-list based recognition logic, including validation (e.g., with checksum) and context support. See an example here . Extending the analyzer for additional PII entities Create a new class based on EntityRecognizer . Add the new recognizer to the recognizer registry so that the AnalyzerEngine can use the new recognizer during analysis. Simple example For simple recognizers based on regular expressions or deny-lists, we can leverage the provided PatternRecognizer : from presidio_analyzer import PatternRecognizer titles_recognizer = PatternRecognizer ( supported_entity = \"TITLE\" , deny_list = [ \"Mr.\" , \"Mrs.\" , \"Miss\" ]) Calling the recognizer itself: titles_recognizer . analyze ( text = \"Mr. Schmidt\" , entities = \"TITLE\" ) Adding it to the list of recognizers: from presidio_analyzer import AnalyzerEngine , RecognizerRegistry registry = RecognizerRegistry () registry . load_predefined_recognizers () # Add the recognizer to the existing list of recognizers registry . add_recognizer ( titles_recognizer ) # Set up analyzer with our updated recognizer registry analyzer = AnalyzerEngine ( registry = registry ) # Run with input text text = \"His name is Mr. Jones\" results = analyzer . analyze ( text = text , language = \"en\" ) print ( results ) Alternatively, we can add the recognizer directly to the existing registry: from presidio_analyzer import AnalyzerEngine analyzer = AnalyzerEngine () analyzer . registry . add_recognizer ( titles_recognizer ) results = analyzer . analyze ( text = text , language = \"en\" ) print ( results ) Creating a new EntityRecognizer in code To create a new recognizer via code: Create a new Python class which implements LocalRecognizer . ( LocalRecognizer implements the base EntityRecognizer class) This class has the following functions: i. load: load a model / resource to be used during recognition def load ( self ) ii. analyze: The main function to be called for getting entities out of the new recognizer: def analyze ( self , text , entities , nlp_artifacts ) Notes: 1. Each recognizer has access to different NLP assets such as tokens, lemmas , and more. These are given through the nlp_artifacts parameter. Refer to the source code for more information. The analyze method should return a list of RecognizerResult . Add it to the recognizer registry using registry.add_recognizer(my_recognizer) . Creating a remote recognizer A remote recognizer is an EntityRecognizer object interacting with an external service. The external service could be a 3rd party PII detection service or a custom service deployed in parallel to Presidio. Sample implementation of a RemoteRecognizer . In this example, an external PII detection service exposes two APIs: detect and supported_entities . The class implemented here, ExampleRemoteRecognizer , uses the requests package to call the external service via HTTP. In this code snippet, we simulate the external PII detector by using the Presidio analyzer. In reality, we would adapt this code to fit the external PII detector we have in hand. Creating pre-defined recognizers Once a recognizer is created, it can either be added to the RecognizerRegistry via the add_recognizer method, or it could be added into the list of predefined recognizers. To add a recognizer to the list of pre-defined recognizers: Clone the repo. Create a file containing the new recognizer Python class. Add the recognizer to the recognizers_map dict in the RecognizerRegistry.load_predefined_recognizers method. In this map, the key is the language the recognizer supports, and the value is the class itself. If your recognizer detects entities in multiple languages, add it to under the \"ALL\" key. Optional: Update documentation (e.g., the supported entities list ). PII detection in different languages For recognizers in new languages, refer to the languages documentation . Considerations when creating recognizers Best practices for developing PII recognizers .","title":"Tutorial"},{"location":"analyzer/adding_recognizers/#supporting-detection-of-new-types-of-pii-entities","text":"Presidio can be extended to support detection of new types of PII entities, and to support additional languages.","title":"Supporting detection of new types of PII entities"},{"location":"analyzer/adding_recognizers/#introduction-to-recognizer-development","text":"Entity recognizers are Python objects capable of detecting one or more entities in a specific language. In order to extend Presidio's detection capabilities to new types of PII entities, these EntityRecognizer objects should be added to the existing list of recognizers.","title":"Introduction to recognizer development"},{"location":"analyzer/adding_recognizers/#types-of-recognizer-classes-in-presidio","text":"The following class diagram shows the different types of recognizer families Presidio contains. The EntityRecognizer is an abstract class for all recognizers. The RemoteRecognizer is an abstract class for calling external PII detectors. See more info here . The abstract class LocalRecognizer is implemented by all recognizers running within the Presidio-analyzer process. The PatternRecognizer is an class for supporting regex and deny-list based recognition logic, including validation (e.g., with checksum) and context support. See an example here .","title":"Types of recognizer classes in Presidio"},{"location":"analyzer/adding_recognizers/#extending-the-analyzer-for-additional-pii-entities","text":"Create a new class based on EntityRecognizer . Add the new recognizer to the recognizer registry so that the AnalyzerEngine can use the new recognizer during analysis.","title":"Extending the analyzer for additional PII entities"},{"location":"analyzer/adding_recognizers/#simple-example","text":"For simple recognizers based on regular expressions or deny-lists, we can leverage the provided PatternRecognizer : from presidio_analyzer import PatternRecognizer titles_recognizer = PatternRecognizer ( supported_entity = \"TITLE\" , deny_list = [ \"Mr.\" , \"Mrs.\" , \"Miss\" ]) Calling the recognizer itself: titles_recognizer . analyze ( text = \"Mr. Schmidt\" , entities = \"TITLE\" ) Adding it to the list of recognizers: from presidio_analyzer import AnalyzerEngine , RecognizerRegistry registry = RecognizerRegistry () registry . load_predefined_recognizers () # Add the recognizer to the existing list of recognizers registry . add_recognizer ( titles_recognizer ) # Set up analyzer with our updated recognizer registry analyzer = AnalyzerEngine ( registry = registry ) # Run with input text text = \"His name is Mr. Jones\" results = analyzer . analyze ( text = text , language = \"en\" ) print ( results ) Alternatively, we can add the recognizer directly to the existing registry: from presidio_analyzer import AnalyzerEngine analyzer = AnalyzerEngine () analyzer . registry . add_recognizer ( titles_recognizer ) results = analyzer . analyze ( text = text , language = \"en\" ) print ( results )","title":"Simple example"},{"location":"analyzer/adding_recognizers/#creating-a-new-entityrecognizer-in-code","text":"To create a new recognizer via code: Create a new Python class which implements LocalRecognizer . ( LocalRecognizer implements the base EntityRecognizer class) This class has the following functions: i. load: load a model / resource to be used during recognition def load ( self ) ii. analyze: The main function to be called for getting entities out of the new recognizer: def analyze ( self , text , entities , nlp_artifacts ) Notes: 1. Each recognizer has access to different NLP assets such as tokens, lemmas , and more. These are given through the nlp_artifacts parameter. Refer to the source code for more information. The analyze method should return a list of RecognizerResult . Add it to the recognizer registry using registry.add_recognizer(my_recognizer) .","title":"Creating a new EntityRecognizer in code"},{"location":"analyzer/adding_recognizers/#creating-a-remote-recognizer","text":"A remote recognizer is an EntityRecognizer object interacting with an external service. The external service could be a 3rd party PII detection service or a custom service deployed in parallel to Presidio. Sample implementation of a RemoteRecognizer . In this example, an external PII detection service exposes two APIs: detect and supported_entities . The class implemented here, ExampleRemoteRecognizer , uses the requests package to call the external service via HTTP. In this code snippet, we simulate the external PII detector by using the Presidio analyzer. In reality, we would adapt this code to fit the external PII detector we have in hand.","title":"Creating a remote recognizer"},{"location":"analyzer/adding_recognizers/#creating-pre-defined-recognizers","text":"Once a recognizer is created, it can either be added to the RecognizerRegistry via the add_recognizer method, or it could be added into the list of predefined recognizers. To add a recognizer to the list of pre-defined recognizers: Clone the repo. Create a file containing the new recognizer Python class. Add the recognizer to the recognizers_map dict in the RecognizerRegistry.load_predefined_recognizers method. In this map, the key is the language the recognizer supports, and the value is the class itself. If your recognizer detects entities in multiple languages, add it to under the \"ALL\" key. Optional: Update documentation (e.g., the supported entities list ).","title":"Creating pre-defined recognizers"},{"location":"analyzer/adding_recognizers/#pii-detection-in-different-languages","text":"For recognizers in new languages, refer to the languages documentation .","title":"PII detection in different languages"},{"location":"analyzer/adding_recognizers/#considerations-when-creating-recognizers","text":"Best practices for developing PII recognizers .","title":"Considerations when creating recognizers"},{"location":"analyzer/decision_process/","text":"The Presidio-analyzer decision process Background Presidio-analyzer's decision process exposes information on why a specific PII was detected. Such information could contain: Which recognizer detected the entity Which regex pattern was used Interpretability mechanisms in ML models Which context words improved the score Confidence scores before and after each step And more. Usage The decision process can be leveraged in two ways: Presidio-analyzer can log its decision process into a designated logger, which allows you to investigate a specific api request, by exposing a correlation-id as part of the api response headers. The decision process can be returned as part of the /analyze response. Getting the decision process as part of the response The decision process result can be added to the response. To enable it, call the analyze method with return_decision_process set as True. For example: HTTP curl -d '{ \"text\": \"John Smith drivers license is AC432223\", \"language\": \"en\", \"return_decision_process\": true}' -H \"Content-Type: application/json\" -X POST http://localhost:3000/analyze Python from presidio_analyzer import AnalyzerEngine # Set up the engine, loads the NLP module (spaCy model by default) # and other PII recognizers analyzer = AnalyzerEngine () # Call analyzer to get results results = analyzer . analyze ( text = 'My phone number is 212-555-5555' , entities = [ 'PHONE_NUMBER' ], language = 'en' , return_decision_process = True ) # Get the decision process results for the first result print ( results [ 0 ] . analysis_explanation ) Logging the decision process Logging of the decision process is turned off by default. To turn it on, create the AnalyzerEngine object with log_decision_process=True . For example: from presidio_analyzer import AnalyzerEngine # Set up the engine, loads the NLP module (spaCy model by default) # and other PII recognizers analyzer = AnalyzerEngine ( log_decision_process = True ) # Call analyzer to get results results = analyzer . analyze ( text = 'My phone number is 212-555-5555' , entities = [ 'PHONE_NUMBER' ], language = 'en' , correlation_id = \"xyz\" ) The decision process logs will be written to standard output. Note that it is possible to define a correlation-id which is the trace identification. It will help you to query the stdout logs. The id can be retrieved from each API response header: x-correlation-id . By having the traces written into the stdout it's very easy to configure a monitoring solution to ease the process of reading processing the tracing logs in a distributed system. Examples For the a request with the following text: My name is Bart Simpson, my Credit card is: 4095-2609-9393-4932, my phone is 425 8829090 The following traces will be written to log, with this format: [Date Time][decision_process][Log Level][Unique Correlation ID][Trace Message] [2019-07-14 14:22:32,409][decision_process][INFO][00000000-0000-0000-0000-000000000000][nlp artifacts:{'entities': (Bart Simpson, 4095, 425), 'tokens': ['My', 'name', 'is', 'Bart', 'Simpson', ',', 'my', 'Credit', 'card', 'is', ':', '4095', '-', '2609', '-', '9393', '-', '4932', ',', ' ', 'my', 'phone', 'is', '425', '8829090'], 'lemmas': ['My', 'name', 'be', 'Bart', 'Simpson', ',', 'my', 'Credit', 'card', 'be', ':', '4095', '-', '2609', '-', '9393', '-', '4932', ',', ' ', 'my', 'phone', 'be', '425', '8829090'], 'tokens_indices': [0, 3, 8, 11, 16, 23, 25, 28, 35, 40, 42, 44, 48, 49, 53, 54, 58, 59, 63, 65, 66, 69, 75, 78, 82], 'keywords': ['bart', 'simpson', 'credit', 'card', '4095', '2609', '9393', '4932', ' ', 'phone', '425', '8829090']}] [2019-07-14 14:22:32,417][decision_process][INFO][00000000-0000-0000-0000-000000000000][[\"{'entity_type': 'CREDIT_CARD', 'start': 44, 'end': 63, 'score': 1.0, 'analysis_explanation': {'recognizer': 'CreditCardRecognizer', 'pattern_name': 'All Credit Cards (weak)', 'pattern': '\\\\\\\\b((4\\\\\\\\d{3})|(5[0-5]\\\\\\\\d{2})|(6\\\\\\\\d{3})|(1\\\\\\\\d{3})|(3\\\\\\\\d{3}))[- ]?(\\\\\\\\d{3,4})[- ]?(\\\\\\\\d{3,4})[- ]?(\\\\\\\\d{3,5})\\\\\\\\b', 'original_score': 0.3, 'score': 1.0, 'textual_explanation': None, 'score_context_improvement': 0.7, 'supportive_context_word': 'credit', 'validation_result': True}}\", \"{'entity_type': 'PERSON', 'start': 11, 'end': 23, 'score': 0.85, 'analysis_explanation': {'recognizer': 'SpacyRecognizer', 'pattern_name': None, 'pattern': None, 'original_score': 0.85, 'score': 0.85, 'textual_explanation': \\\"Identified as PERSON by Spacy's Named Entity Recognition\\\", 'score_context_improvement': 0, 'supportive_context_word': '', 'validation_result': None}}\", \"{'entity_type': 'PHONE_NUMBER', 'start': 78, 'end': 89, 'score': 0.85, 'analysis_explanation': {'recognizer': 'UsPhoneRecognizer', 'pattern_name': 'Phone (medium)', 'pattern': '\\\\\\\\b(\\\\\\\\d{3}[-\\\\\\\\.\\\\\\\\s]\\\\\\\\d{3}[-\\\\\\\\.\\\\\\\\s]??\\\\\\\\d{4})\\\\\\\\b', 'original_score': 0.5, 'score': 0.85, 'textual_explanation': None, 'score_context_improvement': 0.35, 'supportive_context_word': 'phone', 'validation_result': None}}\"]] Writing custom decision process for a recognizer When creating new PII recognizers, it is possible to add information about the recognizer's decision process. This information will be traced or returned to the user, depending on the configuration. For example, the spacy_recognizer.py implements a custom trace as follows: SPACY_DEFAULT_EXPLANATION = \"Identified as {} by Spacy's Named Entity Recognition\" def build_spacy_explanation ( recognizer_name , original_score , entity ): explanation = AnalysisExplanation ( recognizer = recognizer_name , original_score = original_score , textual_explanation = SPACY_DEFAULT_EXPLANATION . format ( entity )) return explanation The textual_explanation field in AnalysisExplanation class allows you to add your own custom text into the final trace which will be written. Note These traces leverage the Python logging mechanisms. In the default configuration, A StreamHandler is used to write these logs to sys.stdout . Warning Decision-process traces explain why PIIs were detected, but not why they were not detected!","title":"Tracing the decision process"},{"location":"analyzer/decision_process/#the-presidio-analyzer-decision-process","text":"","title":"The Presidio-analyzer decision process"},{"location":"analyzer/decision_process/#background","text":"Presidio-analyzer's decision process exposes information on why a specific PII was detected. Such information could contain: Which recognizer detected the entity Which regex pattern was used Interpretability mechanisms in ML models Which context words improved the score Confidence scores before and after each step And more.","title":"Background"},{"location":"analyzer/decision_process/#usage","text":"The decision process can be leveraged in two ways: Presidio-analyzer can log its decision process into a designated logger, which allows you to investigate a specific api request, by exposing a correlation-id as part of the api response headers. The decision process can be returned as part of the /analyze response.","title":"Usage"},{"location":"analyzer/decision_process/#getting-the-decision-process-as-part-of-the-response","text":"The decision process result can be added to the response. To enable it, call the analyze method with return_decision_process set as True. For example: HTTP curl -d '{ \"text\": \"John Smith drivers license is AC432223\", \"language\": \"en\", \"return_decision_process\": true}' -H \"Content-Type: application/json\" -X POST http://localhost:3000/analyze Python from presidio_analyzer import AnalyzerEngine # Set up the engine, loads the NLP module (spaCy model by default) # and other PII recognizers analyzer = AnalyzerEngine () # Call analyzer to get results results = analyzer . analyze ( text = 'My phone number is 212-555-5555' , entities = [ 'PHONE_NUMBER' ], language = 'en' , return_decision_process = True ) # Get the decision process results for the first result print ( results [ 0 ] . analysis_explanation )","title":"Getting the decision process as part of the response"},{"location":"analyzer/decision_process/#logging-the-decision-process","text":"Logging of the decision process is turned off by default. To turn it on, create the AnalyzerEngine object with log_decision_process=True . For example: from presidio_analyzer import AnalyzerEngine # Set up the engine, loads the NLP module (spaCy model by default) # and other PII recognizers analyzer = AnalyzerEngine ( log_decision_process = True ) # Call analyzer to get results results = analyzer . analyze ( text = 'My phone number is 212-555-5555' , entities = [ 'PHONE_NUMBER' ], language = 'en' , correlation_id = \"xyz\" ) The decision process logs will be written to standard output. Note that it is possible to define a correlation-id which is the trace identification. It will help you to query the stdout logs. The id can be retrieved from each API response header: x-correlation-id . By having the traces written into the stdout it's very easy to configure a monitoring solution to ease the process of reading processing the tracing logs in a distributed system.","title":"Logging the decision process"},{"location":"analyzer/decision_process/#examples","text":"For the a request with the following text: My name is Bart Simpson, my Credit card is: 4095-2609-9393-4932, my phone is 425 8829090 The following traces will be written to log, with this format: [Date Time][decision_process][Log Level][Unique Correlation ID][Trace Message] [2019-07-14 14:22:32,409][decision_process][INFO][00000000-0000-0000-0000-000000000000][nlp artifacts:{'entities': (Bart Simpson, 4095, 425), 'tokens': ['My', 'name', 'is', 'Bart', 'Simpson', ',', 'my', 'Credit', 'card', 'is', ':', '4095', '-', '2609', '-', '9393', '-', '4932', ',', ' ', 'my', 'phone', 'is', '425', '8829090'], 'lemmas': ['My', 'name', 'be', 'Bart', 'Simpson', ',', 'my', 'Credit', 'card', 'be', ':', '4095', '-', '2609', '-', '9393', '-', '4932', ',', ' ', 'my', 'phone', 'be', '425', '8829090'], 'tokens_indices': [0, 3, 8, 11, 16, 23, 25, 28, 35, 40, 42, 44, 48, 49, 53, 54, 58, 59, 63, 65, 66, 69, 75, 78, 82], 'keywords': ['bart', 'simpson', 'credit', 'card', '4095', '2609', '9393', '4932', ' ', 'phone', '425', '8829090']}] [2019-07-14 14:22:32,417][decision_process][INFO][00000000-0000-0000-0000-000000000000][[\"{'entity_type': 'CREDIT_CARD', 'start': 44, 'end': 63, 'score': 1.0, 'analysis_explanation': {'recognizer': 'CreditCardRecognizer', 'pattern_name': 'All Credit Cards (weak)', 'pattern': '\\\\\\\\b((4\\\\\\\\d{3})|(5[0-5]\\\\\\\\d{2})|(6\\\\\\\\d{3})|(1\\\\\\\\d{3})|(3\\\\\\\\d{3}))[- ]?(\\\\\\\\d{3,4})[- ]?(\\\\\\\\d{3,4})[- ]?(\\\\\\\\d{3,5})\\\\\\\\b', 'original_score': 0.3, 'score': 1.0, 'textual_explanation': None, 'score_context_improvement': 0.7, 'supportive_context_word': 'credit', 'validation_result': True}}\", \"{'entity_type': 'PERSON', 'start': 11, 'end': 23, 'score': 0.85, 'analysis_explanation': {'recognizer': 'SpacyRecognizer', 'pattern_name': None, 'pattern': None, 'original_score': 0.85, 'score': 0.85, 'textual_explanation': \\\"Identified as PERSON by Spacy's Named Entity Recognition\\\", 'score_context_improvement': 0, 'supportive_context_word': '', 'validation_result': None}}\", \"{'entity_type': 'PHONE_NUMBER', 'start': 78, 'end': 89, 'score': 0.85, 'analysis_explanation': {'recognizer': 'UsPhoneRecognizer', 'pattern_name': 'Phone (medium)', 'pattern': '\\\\\\\\b(\\\\\\\\d{3}[-\\\\\\\\.\\\\\\\\s]\\\\\\\\d{3}[-\\\\\\\\.\\\\\\\\s]??\\\\\\\\d{4})\\\\\\\\b', 'original_score': 0.5, 'score': 0.85, 'textual_explanation': None, 'score_context_improvement': 0.35, 'supportive_context_word': 'phone', 'validation_result': None}}\"]]","title":"Examples"},{"location":"analyzer/decision_process/#writing-custom-decision-process-for-a-recognizer","text":"When creating new PII recognizers, it is possible to add information about the recognizer's decision process. This information will be traced or returned to the user, depending on the configuration. For example, the spacy_recognizer.py implements a custom trace as follows: SPACY_DEFAULT_EXPLANATION = \"Identified as {} by Spacy's Named Entity Recognition\" def build_spacy_explanation ( recognizer_name , original_score , entity ): explanation = AnalysisExplanation ( recognizer = recognizer_name , original_score = original_score , textual_explanation = SPACY_DEFAULT_EXPLANATION . format ( entity )) return explanation The textual_explanation field in AnalysisExplanation class allows you to add your own custom text into the final trace which will be written. Note These traces leverage the Python logging mechanisms. In the default configuration, A StreamHandler is used to write these logs to sys.stdout . Warning Decision-process traces explain why PIIs were detected, but not why they were not detected!","title":"Writing custom decision process for a recognizer"},{"location":"analyzer/developing_recognizers/","text":"Recognizers Development - Best Practices and Considerations Recognizers are the main building blocks in Presidio. Each recognizer is in charge of detecting one or more entities in one or more languages. Recognizers define the logic for detection, as well as the confidence a prediction receives and a list of words to be used when context is leveraged. Implementation Considerations Accuracy Each recognizer, regardless of its complexity, could have false positives and false negatives. When adding new recognizers, we try to balance the effect of each recognizer on the entire system. A recognizer with many false positives would affect the system's usability, while a recognizer with many false negatives might require more work before it can be integrated. For reproducibility purposes, it is be best to note how the recognizer's accuracy was tested, and on which datasets. For tools and documentation on evaluating and analyzing recognizers, refer to the presidio-research Github repository . Note When contributing recognizers to the Presidio OSS, new predefined recognizers should be added to the supported entities list , and follow the contribution guidelines . Performance Make sure your recognizer doesn't take too long to process text. Anything above 100ms per request with 100 tokens is probably not good enough. Environment When adding new recognizers that have 3rd party dependencies, make sure that the new dependencies don't interfere with Presidio's dependencies. In the case of a conflict, one can create an isolated model environment (outside the main presidio-analyzer process) and implement a RemoteRecognizer on the presidio-analyzer side to interact with the model's endpoint. In addition, make sure the license on the 3rd party dependency allows you to use it for any purpose. Recognizer Types Generally speaking, there are three types of recognizers: Deny Lists A deny list is a list of words that should be removed during text analysis. For example, it can include a list of titles ( [\"Mr.\", \"Mrs.\", \"Ms.\", \"Dr.\"] to detect a \"Title\" entity.) See this documentation on adding a new recognizer. The PatternRecognizer class has built-in support for a deny-list input. Pattern Based Pattern based recognizers use regular expressions to identify entities in text. See this documentation on adding a new recognizer via code. The PatternRecognizer class should be extended. See some examples here: Examples Examples of pattern based recognizers are the CreditCardRecognizer and EmailRecognizer . Machine Learning (ML) Based or Rule-Based Many PII entities are undetectable using naive approaches like deny-lists or regular expressions. In these cases, we would wish to utilize a Machine Learning model capable of identifying entities in free text, or a rule-based recognizer. There are four options for adding ML and rule based recognizers: Utilize SpaCy or Stanza Presidio currently uses spaCy as a framework for text analysis and Named Entity Recognition (NER), and stanza as an alternative. To avoid introducing new tools, it is recommended to first try to use spaCy or stanza over other tools if possible. spaCy provides descent results compared to state-of-the-art NER models, but with much better computational performance. spaCy and stanza models could be trained from scratch, used in combination with pre-trained embeddings, or retrained to detect new entities. When integrating such a model into Presidio, a class inheriting from the EntityRecognizer should be created. Utilize Scikit-learn or Similar Scikit-learn models tend to be fast, but usually have lower accuracy than deep learning methods. However, for well defined problems with well defined features, they can provide very good results. When integrating such a model into Presidio, a class inheriting from the EntityRecognizer should be created. Apply Custom Logic In some cases, rule-based logic provides the best way of detecting entities. The Presidio EntityRecognizer API allows you to use spaCy / stanza extracted features like lemmas, part of speech, dependencies and more to create your logic. When integrating such logic into Presidio, a class inheriting from the EntityRecognizer should be created. Deep Learning Based Methods Deep learning methods offer excellent detection rates for NER. They are however more complex to train, deploy and tend to be slower than traditional approaches. When creating a DL based method for PII detection, there are two main alternatives for integrating it with Presidio: Create an external endpoint (either local or remote) which is isolated from the presidio-analyzer process. On the presidio-analyzer side, one would extend the RemoteRecognizer class and implement the network interface between presidio-analyzer and the endpoint of the model's container. Integrate the model as an additional EntityRecognizer within the presidio-analyzer flow. Considerations for selecting one option over another Ease of integration. Runtime considerations (For example if the new model requires a GPU). 3rd party dependencies of the new model vs. the existing presidio-analyzer package.","title":"Best practices in developing recognizers"},{"location":"analyzer/developing_recognizers/#recognizers-development-best-practices-and-considerations","text":"Recognizers are the main building blocks in Presidio. Each recognizer is in charge of detecting one or more entities in one or more languages. Recognizers define the logic for detection, as well as the confidence a prediction receives and a list of words to be used when context is leveraged.","title":"Recognizers Development - Best Practices and Considerations"},{"location":"analyzer/developing_recognizers/#implementation-considerations","text":"","title":"Implementation Considerations"},{"location":"analyzer/developing_recognizers/#accuracy","text":"Each recognizer, regardless of its complexity, could have false positives and false negatives. When adding new recognizers, we try to balance the effect of each recognizer on the entire system. A recognizer with many false positives would affect the system's usability, while a recognizer with many false negatives might require more work before it can be integrated. For reproducibility purposes, it is be best to note how the recognizer's accuracy was tested, and on which datasets. For tools and documentation on evaluating and analyzing recognizers, refer to the presidio-research Github repository . Note When contributing recognizers to the Presidio OSS, new predefined recognizers should be added to the supported entities list , and follow the contribution guidelines .","title":"Accuracy"},{"location":"analyzer/developing_recognizers/#performance","text":"Make sure your recognizer doesn't take too long to process text. Anything above 100ms per request with 100 tokens is probably not good enough.","title":"Performance"},{"location":"analyzer/developing_recognizers/#environment","text":"When adding new recognizers that have 3rd party dependencies, make sure that the new dependencies don't interfere with Presidio's dependencies. In the case of a conflict, one can create an isolated model environment (outside the main presidio-analyzer process) and implement a RemoteRecognizer on the presidio-analyzer side to interact with the model's endpoint. In addition, make sure the license on the 3rd party dependency allows you to use it for any purpose.","title":"Environment"},{"location":"analyzer/developing_recognizers/#recognizer-types","text":"Generally speaking, there are three types of recognizers:","title":"Recognizer Types"},{"location":"analyzer/developing_recognizers/#deny-lists","text":"A deny list is a list of words that should be removed during text analysis. For example, it can include a list of titles ( [\"Mr.\", \"Mrs.\", \"Ms.\", \"Dr.\"] to detect a \"Title\" entity.) See this documentation on adding a new recognizer. The PatternRecognizer class has built-in support for a deny-list input.","title":"Deny Lists"},{"location":"analyzer/developing_recognizers/#pattern-based","text":"Pattern based recognizers use regular expressions to identify entities in text. See this documentation on adding a new recognizer via code. The PatternRecognizer class should be extended. See some examples here: Examples Examples of pattern based recognizers are the CreditCardRecognizer and EmailRecognizer .","title":"Pattern Based"},{"location":"analyzer/developing_recognizers/#machine-learning-ml-based-or-rule-based","text":"Many PII entities are undetectable using naive approaches like deny-lists or regular expressions. In these cases, we would wish to utilize a Machine Learning model capable of identifying entities in free text, or a rule-based recognizer. There are four options for adding ML and rule based recognizers:","title":"Machine Learning (ML) Based or Rule-Based"},{"location":"analyzer/developing_recognizers/#utilize-spacy-or-stanza","text":"Presidio currently uses spaCy as a framework for text analysis and Named Entity Recognition (NER), and stanza as an alternative. To avoid introducing new tools, it is recommended to first try to use spaCy or stanza over other tools if possible. spaCy provides descent results compared to state-of-the-art NER models, but with much better computational performance. spaCy and stanza models could be trained from scratch, used in combination with pre-trained embeddings, or retrained to detect new entities. When integrating such a model into Presidio, a class inheriting from the EntityRecognizer should be created.","title":"Utilize SpaCy or Stanza"},{"location":"analyzer/developing_recognizers/#utilize-scikit-learn-or-similar","text":"Scikit-learn models tend to be fast, but usually have lower accuracy than deep learning methods. However, for well defined problems with well defined features, they can provide very good results. When integrating such a model into Presidio, a class inheriting from the EntityRecognizer should be created.","title":"Utilize Scikit-learn or Similar"},{"location":"analyzer/developing_recognizers/#apply-custom-logic","text":"In some cases, rule-based logic provides the best way of detecting entities. The Presidio EntityRecognizer API allows you to use spaCy / stanza extracted features like lemmas, part of speech, dependencies and more to create your logic. When integrating such logic into Presidio, a class inheriting from the EntityRecognizer should be created.","title":"Apply Custom Logic"},{"location":"analyzer/developing_recognizers/#deep-learning-based-methods","text":"Deep learning methods offer excellent detection rates for NER. They are however more complex to train, deploy and tend to be slower than traditional approaches. When creating a DL based method for PII detection, there are two main alternatives for integrating it with Presidio: Create an external endpoint (either local or remote) which is isolated from the presidio-analyzer process. On the presidio-analyzer side, one would extend the RemoteRecognizer class and implement the network interface between presidio-analyzer and the endpoint of the model's container. Integrate the model as an additional EntityRecognizer within the presidio-analyzer flow. Considerations for selecting one option over another Ease of integration. Runtime considerations (For example if the new model requires a GPU). 3rd party dependencies of the new model vs. the existing presidio-analyzer package.","title":"Deep Learning Based Methods"},{"location":"analyzer/languages/","text":"PII detection in different languages Presidio supports PII detection in multiple languages. In its default configuration, it contains recognizers and models for English. To extend Presidio to detect PII in an additional language, these modules require modification: The NlpEngine containing the NLP model which performs tokenization, lemmatization, Named Entity Recognition and other NLP tasks. PII recognizers (different EntityRecognizer objects) should be adapted or created. Note While different detection mechanisms such as regular expressions are language agnostic, the context words used to increase the PII detection confidence aren't. Consider updating the list of context words for each recognizer to leverage context words in additional languages. Table of contents Configuring the NLP Engine Set up language specific recognizers Automatically install NLP models into the Docker container Configuring the NLP Engine As its internal NLP engine, Presidio supports both spaCy and Stanza . To set up new models, follow these two steps: Download the spaCy/Stanza NER models for your desired language. To download a new model with spaCy: shell script python -m spacy download es_core_news_md In this example we download the medium size model for Spanish. To download a new model with Stanza: import stanza stanza . download ( \"en\" ) # where en is the language code of the model. For the available models, follow these links: spaCy , stanza . Update the models configuration in one of two ways: Via code : Create an NlpEngine using the NlpEnginerProvider class, and pass it to the AnalyzerEngine as input: from presidio_analyzer import AnalyzerEngine , RecognizerRegistry from presidio_analyzer.nlp_engine import NlpEngineProvider # Create configuration containing engine name and models configuration = { \"nlp_engine_name\" : \"spacy\" , \"models\" : [{ \"lang_code\" : \"es\" , \"model_name\" : \"es_core_news_md\" }, { \"lang_code\" : \"en\" , \"model_name\" : \"en_core_web_lg\" }], } # Create NLP engine based on configuration provider = NlpEngineProvider ( nlp_configuration = configuration ) nlp_engine_with_spanish = provider . create_engine () # Pass the created NLP engine and supported_languages to the AnalyzerEngine analyzer = AnalyzerEngine ( nlp_engine = nlp_engine_with_spanish , supported_languages = [ \"en\" , \"es\" ] ) # Analyze in different languages results_spanish = analyzer . analyze ( text = \"Mi nombre es David\" , language = \"es\" ) print ( results_spanish ) results_english = analyzer . analyze ( text = \"My name is David\" , language = \"en\" ) print ( results_english ) Via configuration : Set up the models which should be used in the default conf file . An example Conf file: nlp_engine_name : spacy models : - lang_code : en model_name : en_core_web_lg - lang_code : es model_name : es_core_news_md The default conf file is read during the default initialization of the AnalyzerEngine . Alternatively, the path to a custom configuration file can be passed to the NlpEngineProvider : from presidio_analyzer import AnalyzerEngine , RecognizerRegistry from presidio_analyzer.nlp_engine import NlpEngineProvider # Create NLP engine based on configuration file provider = NlpEngineProvider ( conf_file = \"PATH_TO_YAML\" ) nlp_engine_with_spanish = provider . create_engine () # Pass created NLP engine and supported_languages to the AnalyzerEngine analyzer = AnalyzerEngine ( nlp_engine = nlp_engine_with_spanish , supported_languages = [ \"en\" , \"es\" ] ) # Analyze in different languages results_spanish = analyzer . analyze ( text = \"Mi nombre es David\" , language = \"es\" ) print ( results_spanish ) results_english = analyzer . analyze ( text = \"My name is David\" , language = \"en\" ) print ( results_english ) In this examples we create an NlpEngine holding two spaCy models (one in English: en_core_web_lg and one in Spanish: es_core_news_md ), define the supported_languages parameter accordingly, and can send requests in each of these languages. Set up language specific recognizers Recognizers are language dependent either by their logic or by the context words used while scanning the surrounding of a detected entity. As these context words are used to increase score, they should be in the expected input language. Consider updating the context words of existing recognizers or add new recognizers to support new languages. Each recognizer can support one language. For example: from presidio_analyzer import AnalyzerEngine , RecognizerRegistry from presidio_analyzer.predefined_recognizers import EmailRecognizer # Setting up an English Email recognizer: email_recognizer_en = EmailRecognizer ( supported_language = \"en\" , context = [ \"email\" , \"mail\" ]) # Setting up a Spanish Email recognizer email_recognizer_es = EmailRecognizer ( supported_language = \"es\" , context = [ \"correo\" , \"electr\u00f3nico\" ]) registry = RecognizerRegistry () # Add recognizers to registry registry . add_recognizer ( email_recognizer_en ) registry . add_recognizer ( email_recognizer_es ) # Set up analyzer with our updated recognizer registry analyzer = AnalyzerEngine ( registry = registry , supported_languages = [ \"en\" , \"es\" ], nlp_engine = nlp_engine_with_spanish ) analyzer . analyze ( ... ) Automatically install NLP models into the Docker container When packaging the code into a Docker container, NLP models are automatically installed. To define which models should be installed, update the conf/default.yaml file. This file is read during the docker build phase and the models defined in it are installed automatically.","title":"Multi-language support"},{"location":"analyzer/languages/#pii-detection-in-different-languages","text":"Presidio supports PII detection in multiple languages. In its default configuration, it contains recognizers and models for English. To extend Presidio to detect PII in an additional language, these modules require modification: The NlpEngine containing the NLP model which performs tokenization, lemmatization, Named Entity Recognition and other NLP tasks. PII recognizers (different EntityRecognizer objects) should be adapted or created. Note While different detection mechanisms such as regular expressions are language agnostic, the context words used to increase the PII detection confidence aren't. Consider updating the list of context words for each recognizer to leverage context words in additional languages.","title":"PII detection in different languages"},{"location":"analyzer/languages/#table-of-contents","text":"Configuring the NLP Engine Set up language specific recognizers Automatically install NLP models into the Docker container","title":"Table of contents"},{"location":"analyzer/languages/#configuring-the-nlp-engine","text":"As its internal NLP engine, Presidio supports both spaCy and Stanza . To set up new models, follow these two steps: Download the spaCy/Stanza NER models for your desired language. To download a new model with spaCy: shell script python -m spacy download es_core_news_md In this example we download the medium size model for Spanish. To download a new model with Stanza: import stanza stanza . download ( \"en\" ) # where en is the language code of the model. For the available models, follow these links: spaCy , stanza . Update the models configuration in one of two ways: Via code : Create an NlpEngine using the NlpEnginerProvider class, and pass it to the AnalyzerEngine as input: from presidio_analyzer import AnalyzerEngine , RecognizerRegistry from presidio_analyzer.nlp_engine import NlpEngineProvider # Create configuration containing engine name and models configuration = { \"nlp_engine_name\" : \"spacy\" , \"models\" : [{ \"lang_code\" : \"es\" , \"model_name\" : \"es_core_news_md\" }, { \"lang_code\" : \"en\" , \"model_name\" : \"en_core_web_lg\" }], } # Create NLP engine based on configuration provider = NlpEngineProvider ( nlp_configuration = configuration ) nlp_engine_with_spanish = provider . create_engine () # Pass the created NLP engine and supported_languages to the AnalyzerEngine analyzer = AnalyzerEngine ( nlp_engine = nlp_engine_with_spanish , supported_languages = [ \"en\" , \"es\" ] ) # Analyze in different languages results_spanish = analyzer . analyze ( text = \"Mi nombre es David\" , language = \"es\" ) print ( results_spanish ) results_english = analyzer . analyze ( text = \"My name is David\" , language = \"en\" ) print ( results_english ) Via configuration : Set up the models which should be used in the default conf file . An example Conf file: nlp_engine_name : spacy models : - lang_code : en model_name : en_core_web_lg - lang_code : es model_name : es_core_news_md The default conf file is read during the default initialization of the AnalyzerEngine . Alternatively, the path to a custom configuration file can be passed to the NlpEngineProvider : from presidio_analyzer import AnalyzerEngine , RecognizerRegistry from presidio_analyzer.nlp_engine import NlpEngineProvider # Create NLP engine based on configuration file provider = NlpEngineProvider ( conf_file = \"PATH_TO_YAML\" ) nlp_engine_with_spanish = provider . create_engine () # Pass created NLP engine and supported_languages to the AnalyzerEngine analyzer = AnalyzerEngine ( nlp_engine = nlp_engine_with_spanish , supported_languages = [ \"en\" , \"es\" ] ) # Analyze in different languages results_spanish = analyzer . analyze ( text = \"Mi nombre es David\" , language = \"es\" ) print ( results_spanish ) results_english = analyzer . analyze ( text = \"My name is David\" , language = \"en\" ) print ( results_english ) In this examples we create an NlpEngine holding two spaCy models (one in English: en_core_web_lg and one in Spanish: es_core_news_md ), define the supported_languages parameter accordingly, and can send requests in each of these languages.","title":"Configuring the NLP Engine"},{"location":"analyzer/languages/#set-up-language-specific-recognizers","text":"Recognizers are language dependent either by their logic or by the context words used while scanning the surrounding of a detected entity. As these context words are used to increase score, they should be in the expected input language. Consider updating the context words of existing recognizers or add new recognizers to support new languages. Each recognizer can support one language. For example: from presidio_analyzer import AnalyzerEngine , RecognizerRegistry from presidio_analyzer.predefined_recognizers import EmailRecognizer # Setting up an English Email recognizer: email_recognizer_en = EmailRecognizer ( supported_language = \"en\" , context = [ \"email\" , \"mail\" ]) # Setting up a Spanish Email recognizer email_recognizer_es = EmailRecognizer ( supported_language = \"es\" , context = [ \"correo\" , \"electr\u00f3nico\" ]) registry = RecognizerRegistry () # Add recognizers to registry registry . add_recognizer ( email_recognizer_en ) registry . add_recognizer ( email_recognizer_es ) # Set up analyzer with our updated recognizer registry analyzer = AnalyzerEngine ( registry = registry , supported_languages = [ \"en\" , \"es\" ], nlp_engine = nlp_engine_with_spanish ) analyzer . analyze ( ... )","title":"Set up language specific recognizers"},{"location":"analyzer/languages/#automatically-install-nlp-models-into-the-docker-container","text":"When packaging the code into a Docker container, NLP models are automatically installed. To define which models should be installed, update the conf/default.yaml file. This file is read during the docker build phase and the models defined in it are installed automatically.","title":"Automatically install NLP models into the Docker container"},{"location":"anonymizer/","text":"Presidio Anonymizer The Presidio anonymizer is a Python based module for anonymizing detected PII text entities with desired values. Persidio anonymizer comes with predefined anonymizers but can easily be extended. Installation Using pip Note Consider installing the Presidio python packages on a virtual environment like venv or conda. To get started with Presidio-anonymizer, run: pip install presidio-anonymizer Using Docker Note This requires Docker to be installed. Download Docker . # Download image from Dockerhub docker pull mcr.microsoft.com/presidio-anonymizer # Run the container with the default port docker run -d -p 5001 :5001 mcr.microsoft.com/presidio-anonymizer:latest From source First, clone the Presidio repo. See here for instructions . Then, build the presidio-anonymizer container: cd presidio-anonnymizer docker build . -t presidio/presidio-anonymizer Getting started Python Once the Presidio-anonymizer package is installed, run this simple script: from presidio_anonymizer import AnonymizerEngine from presidio_anonymizer.entities import AnalyzerResult , AnonymizerConfig # Initialize the engine with logger. engine = AnonymizerEngine () # Class the anonymize function with the text, analyzer results and # Anonymizers config to define the anonymization type. result = engine . anonymize ( text = \"My name is Bond, James Bond\" , analyzer_results = [ AnalyzerResult ( \"PERSON\" , 11 , 15 , 0.8 ), AnalyzerResult ( \"PERSON\" , 17 , 27 , 0.8 )], anonymizers_config = { \"PERSON\" : AnonymizerConfig ( \"replace\" , { \"new_value\" : \"BIP\" })} ) print ( result ) As an HTTP server You can run presidio anonymizer as an http server using either python runtime or using a docker container. Using docker container cd presidio-anonymizer docker run -p 5001 :5001 presidio-anonymizer Using python runtime Note This requires the Presidio Github repository to be cloned. cd presidio-anonymizer python app.py Anonymize: curl -XPOST http://localhost:3000/anonymize -H \"Content-Type: application/json\" -d @payload payload example: { \"text\" : \"hello world, my name is Jane Doe. My number is: 034453334\" , \"anonymizers\" : { \"PHONE_NUMBER\" : { \"type\" : \"mask\" , \"masking_char\" : \"*\" , \"chars_to_mask\" : 4 , \"from_end\" : true } } , \"analyzer_results\" : [ { \"start\" : 24 , \"end\" : 32 , \"score\" : 0 .8, \"entity_type\" : \"NAME\" } , { \"start\" : 24 , \"end\" : 28 , \"score\" : 0 .8, \"entity_type\" : \"FIRST_NAME\" } , { \"start\" : 29 , \"end\" : 32 , \"score\" : 0 .6, \"entity_type\" : \"LAST_NAME\" } , { \"start\" : 48 , \"end\" : 57 , \"score\" : 0 .95, \"entity_type\" : \"PHONE_NUMBER\" } ]} Built-in anonymizers: Anonymizer type Description Parameters replace replaces the PII with desired value new_value - replaces existing text with the given value. If new_value is not supplied or empty, default behavior will be: <entity_type> e.g: <PHONE_NUMBER> redact removes the PII completely from text None hash hash the PII using either sha256, sha512 or md5 hash_type - sets the type of hashing. Can be either sha256 , sha512 or md5 . The default hash type is sha256 . mask replaces the PII with a given character chars_to_mask - the amount of characters out of the PII that should be replaced. masking_char - the character to be replaced with. from_end - Whether to mask the PII from it's end. Note If anonymizers map is empty or \"DEFAULT\" key is not stated, the default anonymizer is \"replace\" for all entities. The replacing value will be the entity type e.g.: <PHONE_NUMBER> Overlapping Anonymization Scenarios As the input text could potentially have overlapping PII entities, there are different anonymization scenarios: No overlap (single PII) - single PII over text entity, uses a given or default anonymizer to anonymize and replace the PII text entity. Full overlap of PIIs - When one text have several PIIs, the PII with the higher score will be taken. Between PIIs with identical scores, the selection will be arbitrary. One PII is contained in another - anonymizer will use the PII with larger text. Partial intersection - both will be returned concatenated. Example of how each scenario would work. Our text will be: My name is Inigo Montoya. You Killed my Father. Prepare to die. BTW my number is: 03-232323. No overlaps - only Inigo was recognized as NAME: My name is <NAME> Montoya. You Killed my Father. Prepare to die. BTW my number is: 03-232323. Full overlap - the number was recognized as PHONE_NUMBER with score of 0.7 and as SSN with score of 0.6, we will take the higher score: My name is Inigo Montoya. You Killed my Father. Prepare to die. BTW my number is: <PHONE_NUMBER> One PII is contained is another - Inigo was recognized as FIRST_NAME and Inigo Montoya was recognized as NAME, we will take the larger one: My name is <NAME>. You Killed my Father. Prepare to die. BTW my number is: 03-232323. Partial intersection - the number 03-2323 is recognized as a PHONE_NUMBER but 232323 is recognized as SSN: My name is Inigo Montoya. You Killed my Father. Prepare to die. BTW my number is: <PHONE_NUMBER><SSN>. Creating new anonymizers Presidio anonymizer can be easily extended to support additional anonnymization methods. See this tutorial on adding new anonymization methods for more information. API reference Follow the API Spec for the Anonymizer REST API reference details and Anonymizer Python API for Python API reference","title":"Anonymizer Home"},{"location":"anonymizer/#presidio-anonymizer","text":"The Presidio anonymizer is a Python based module for anonymizing detected PII text entities with desired values. Persidio anonymizer comes with predefined anonymizers but can easily be extended.","title":"Presidio Anonymizer"},{"location":"anonymizer/#installation","text":"Using pip Note Consider installing the Presidio python packages on a virtual environment like venv or conda. To get started with Presidio-anonymizer, run: pip install presidio-anonymizer Using Docker Note This requires Docker to be installed. Download Docker . # Download image from Dockerhub docker pull mcr.microsoft.com/presidio-anonymizer # Run the container with the default port docker run -d -p 5001 :5001 mcr.microsoft.com/presidio-anonymizer:latest From source First, clone the Presidio repo. See here for instructions . Then, build the presidio-anonymizer container: cd presidio-anonnymizer docker build . -t presidio/presidio-anonymizer","title":"Installation"},{"location":"anonymizer/#getting-started","text":"Python Once the Presidio-anonymizer package is installed, run this simple script: from presidio_anonymizer import AnonymizerEngine from presidio_anonymizer.entities import AnalyzerResult , AnonymizerConfig # Initialize the engine with logger. engine = AnonymizerEngine () # Class the anonymize function with the text, analyzer results and # Anonymizers config to define the anonymization type. result = engine . anonymize ( text = \"My name is Bond, James Bond\" , analyzer_results = [ AnalyzerResult ( \"PERSON\" , 11 , 15 , 0.8 ), AnalyzerResult ( \"PERSON\" , 17 , 27 , 0.8 )], anonymizers_config = { \"PERSON\" : AnonymizerConfig ( \"replace\" , { \"new_value\" : \"BIP\" })} ) print ( result ) As an HTTP server You can run presidio anonymizer as an http server using either python runtime or using a docker container.","title":"Getting started"},{"location":"anonymizer/#using-docker-container","text":"cd presidio-anonymizer docker run -p 5001 :5001 presidio-anonymizer","title":"Using docker container"},{"location":"anonymizer/#using-python-runtime","text":"Note This requires the Presidio Github repository to be cloned. cd presidio-anonymizer python app.py Anonymize: curl -XPOST http://localhost:3000/anonymize -H \"Content-Type: application/json\" -d @payload payload example: { \"text\" : \"hello world, my name is Jane Doe. My number is: 034453334\" , \"anonymizers\" : { \"PHONE_NUMBER\" : { \"type\" : \"mask\" , \"masking_char\" : \"*\" , \"chars_to_mask\" : 4 , \"from_end\" : true } } , \"analyzer_results\" : [ { \"start\" : 24 , \"end\" : 32 , \"score\" : 0 .8, \"entity_type\" : \"NAME\" } , { \"start\" : 24 , \"end\" : 28 , \"score\" : 0 .8, \"entity_type\" : \"FIRST_NAME\" } , { \"start\" : 29 , \"end\" : 32 , \"score\" : 0 .6, \"entity_type\" : \"LAST_NAME\" } , { \"start\" : 48 , \"end\" : 57 , \"score\" : 0 .95, \"entity_type\" : \"PHONE_NUMBER\" } ]}","title":"Using python runtime"},{"location":"anonymizer/#built-in-anonymizers","text":"Anonymizer type Description Parameters replace replaces the PII with desired value new_value - replaces existing text with the given value. If new_value is not supplied or empty, default behavior will be: <entity_type> e.g: <PHONE_NUMBER> redact removes the PII completely from text None hash hash the PII using either sha256, sha512 or md5 hash_type - sets the type of hashing. Can be either sha256 , sha512 or md5 . The default hash type is sha256 . mask replaces the PII with a given character chars_to_mask - the amount of characters out of the PII that should be replaced. masking_char - the character to be replaced with. from_end - Whether to mask the PII from it's end. Note If anonymizers map is empty or \"DEFAULT\" key is not stated, the default anonymizer is \"replace\" for all entities. The replacing value will be the entity type e.g.: <PHONE_NUMBER>","title":"Built-in anonymizers:"},{"location":"anonymizer/#overlapping-anonymization-scenarios","text":"As the input text could potentially have overlapping PII entities, there are different anonymization scenarios: No overlap (single PII) - single PII over text entity, uses a given or default anonymizer to anonymize and replace the PII text entity. Full overlap of PIIs - When one text have several PIIs, the PII with the higher score will be taken. Between PIIs with identical scores, the selection will be arbitrary. One PII is contained in another - anonymizer will use the PII with larger text. Partial intersection - both will be returned concatenated. Example of how each scenario would work. Our text will be: My name is Inigo Montoya. You Killed my Father. Prepare to die. BTW my number is: 03-232323. No overlaps - only Inigo was recognized as NAME: My name is <NAME> Montoya. You Killed my Father. Prepare to die. BTW my number is: 03-232323. Full overlap - the number was recognized as PHONE_NUMBER with score of 0.7 and as SSN with score of 0.6, we will take the higher score: My name is Inigo Montoya. You Killed my Father. Prepare to die. BTW my number is: <PHONE_NUMBER> One PII is contained is another - Inigo was recognized as FIRST_NAME and Inigo Montoya was recognized as NAME, we will take the larger one: My name is <NAME>. You Killed my Father. Prepare to die. BTW my number is: 03-232323. Partial intersection - the number 03-2323 is recognized as a PHONE_NUMBER but 232323 is recognized as SSN: My name is Inigo Montoya. You Killed my Father. Prepare to die. BTW my number is: <PHONE_NUMBER><SSN>.","title":"Overlapping Anonymization Scenarios"},{"location":"anonymizer/#creating-new-anonymizers","text":"Presidio anonymizer can be easily extended to support additional anonnymization methods. See this tutorial on adding new anonymization methods for more information.","title":"Creating new anonymizers"},{"location":"anonymizer/#api-reference","text":"Follow the API Spec for the Anonymizer REST API reference details and Anonymizer Python API for Python API reference","title":"API reference"},{"location":"anonymizer/adding_anonymizers/","text":"Supporting new types of PII anonymizers Presidio anonymizer can be easily extended to support additional anonnymization methods. Extending the anonymizer for additional PII anonymizations: Under the path presidio_anonymizer/anonymizers create new python class implemeting the abstract Anonymizer class Implement the methods: anonymize - gets the data and returns a new text expected to replace the old one. validate - validate the parameters entered for the anonymizer exists and valid. anonymizer_name - this method helps to automatically load the existing anonymizers. Add the class to presidio_anonymizer/anonymizers/ init .py. Restart the anonymizer. Note The list of anonymizers is being loaded dynamically each time Presidio Anonymizer is started.","title":"Developing PII anonymizers"},{"location":"anonymizer/adding_anonymizers/#supporting-new-types-of-pii-anonymizers","text":"Presidio anonymizer can be easily extended to support additional anonnymization methods.","title":"Supporting new types of PII anonymizers"},{"location":"anonymizer/adding_anonymizers/#extending-the-anonymizer-for-additional-pii-anonymizations","text":"Under the path presidio_anonymizer/anonymizers create new python class implemeting the abstract Anonymizer class Implement the methods: anonymize - gets the data and returns a new text expected to replace the old one. validate - validate the parameters entered for the anonymizer exists and valid. anonymizer_name - this method helps to automatically load the existing anonymizers. Add the class to presidio_anonymizer/anonymizers/ init .py. Restart the anonymizer. Note The list of anonymizers is being loaded dynamically each time Presidio Anonymizer is started.","title":"Extending the anonymizer for additional PII anonymizations:"},{"location":"api/analyzer_python/","text":"Presidio Analyzer API Reference AnalyzerEngine Entry point for Presidio Analyzer. Orchestrating the detection of PII entities and all related logic. Parameters: Name Type Description Default registry instance of type RecognizerRegistry required nlp_engine instance of type NlpEngine (for example SpacyNlpEngine) required app_tracer instance of type AppTracer, used to trace the logic used during each request for interpretability reasons. required log_decision_process bool, defines whether the decision process within the analyzer should be logged or not. required default_score_threshold Minimum confidence value for detected entities to be returned required supported_languages List of possible languages this engine could be run on. Used for loading the right NLP models and recognizers for these languages. required analyze ( self , text , language , entities = None , correlation_id = None , score_threshold = None , return_decision_process = False ) Find PII entities in text using different PII recognizers for a given language. :example: from presidio_analyzer import AnalyzerEngine Set up the engine, loads the NLP module (spaCy model by default) and other PII recognizers analyzer = AnalyzerEngine() Call analyzer to get results results = analyzer.analyze(text='My phone number is 212-555-5555', entities=['PHONE_NUMBER'], language='en') # noqa D501 print(results) [type: PHONE_NUMBER, start: 19, end: 31, score: 0.85] Parameters: Name Type Description Default text str the text to analyze required language str the language of the text required entities Optional[List[str]] List of PII entities that should be looked for in the text. If entities=None then all entities are looked for. None correlation_id Optional[str] cross call ID for this request None score_threshold Optional[float] A minimum value for which to return an identified entity None return_decision_process Optional[bool] Whether the analysis decision process steps returned in the response. False Returns: Type Description List[presidio_analyzer.recognizer_result.RecognizerResult] an array of the found entities in the text Source code in presidio_analyzer/analyzer_engine.py def analyze ( self , text : str , language : str , entities : Optional [ List [ str ]] = None , correlation_id : Optional [ str ] = None , score_threshold : Optional [ float ] = None , return_decision_process : Optional [ bool ] = False , ) -> List [ RecognizerResult ]: \"\"\" Find PII entities in text using different PII recognizers for a given language. :param text: the text to analyze :param language: the language of the text :param entities: List of PII entities that should be looked for in the text. If entities=None then all entities are looked for. :param correlation_id: cross call ID for this request :param score_threshold: A minimum value for which to return an identified entity :param return_decision_process: Whether the analysis decision process steps returned in the response. :return: an array of the found entities in the text :example: >>> from presidio_analyzer import AnalyzerEngine >>> # Set up the engine, loads the NLP module (spaCy model by default) >>> # and other PII recognizers >>> analyzer = AnalyzerEngine() >>> # Call analyzer to get results >>> results = analyzer.analyze(text='My phone number is 212-555-5555', entities=['PHONE_NUMBER'], language='en') # noqa D501 >>> print(results) [type: PHONE_NUMBER, start: 19, end: 31, score: 0.85] \"\"\" all_fields = not entities recognizers = self . registry . get_recognizers ( language = language , entities = entities , all_fields = all_fields ) if all_fields : # Since all_fields=True, list all entities by iterating # over all recognizers entities = self . get_supported_entities ( language = language ) # run the nlp pipeline over the given text, store the results in # a NlpArtifacts instance nlp_artifacts = self . nlp_engine . process_text ( text , language ) if self . log_decision_process : self . app_tracer . trace ( correlation_id , \"nlp artifacts:\" + nlp_artifacts . to_json () ) results = [] for recognizer in recognizers : # Lazy loading of the relevant recognizers if not recognizer . is_loaded : recognizer . load () recognizer . is_loaded = True # analyze using the current recognizer and append the results current_results = recognizer . analyze ( text = text , entities = entities , nlp_artifacts = nlp_artifacts ) if current_results : results . extend ( current_results ) if self . log_decision_process : self . app_tracer . trace ( correlation_id , json . dumps ([ str ( result . to_dict ()) for result in results ]), ) # Remove duplicates or low score results results = EntityRecognizer . remove_duplicates ( results ) results = self . __remove_low_scores ( results , score_threshold ) if not return_decision_process : results = self . __remove_decision_process ( results ) return results get_recognizers ( self , language = None ) Return a list of PII recognizers currently loaded. Parameters: Name Type Description Default language Optional[str] Return the recognizers supporting a given language. None Returns: Type Description List[presidio_analyzer.entity_recognizer.EntityRecognizer] List of [Recognizer] as a RecognizersAllResponse Source code in presidio_analyzer/analyzer_engine.py def get_recognizers ( self , language : Optional [ str ] = None ) -> List [ EntityRecognizer ]: \"\"\" Return a list of PII recognizers currently loaded. :param language: Return the recognizers supporting a given language. :return: List of [Recognizer] as a RecognizersAllResponse \"\"\" if not language : languages = self . supported_languages else : languages = [ language ] recognizers = [] for language in languages : logger . info ( f \"Fetching all recognizers for language { language } \" ) recognizers . extend ( self . registry . get_recognizers ( language = language , all_fields = True ) ) return list ( set ( recognizers )) get_supported_entities ( self , language = None ) Return a list of the entities that can be detected. Parameters: Name Type Description Default language Optional[str] Return only entities supported in a specific language. None Returns: Type Description List[str] List of entity names Source code in presidio_analyzer/analyzer_engine.py def get_supported_entities ( self , language : Optional [ str ] = None ) -> List [ str ]: \"\"\" Return a list of the entities that can be detected. :param language: Return only entities supported in a specific language. :return: List of entity names \"\"\" recognizers = self . get_recognizers ( language = language ) supported_entities = [] for recognizer in recognizers : supported_entities . extend ( recognizer . get_supported_entities ()) return list ( set ( supported_entities )) RecognizerRegistry Detect, register and hold all recognizers to be used by the analyzer. Parameters: Name Type Description Default recognizers An optional list of recognizers, that will be available instead of the predefined recognizers required add_recognizer ( self , recognizer ) Add a new recognizer to the list of recognizers. Parameters: Name Type Description Default recognizer EntityRecognizer Recognizer to add required Source code in presidio_analyzer/recognizer_registry/recognizer_registry.py def add_recognizer ( self , recognizer : EntityRecognizer ) -> None : \"\"\" Add a new recognizer to the list of recognizers. :param recognizer: Recognizer to add \"\"\" if not isinstance ( recognizer , EntityRecognizer ): raise ValueError ( \"Input is not of type EntityRecognizer\" ) self . recognizers . append ( recognizer ) get_recognizers ( self , language , entities = None , all_fields = False ) Return a list of recognizers which supports the specified name and language. Parameters: Name Type Description Default entities Optional[List[str]] the requested entities None language str the requested language required all_fields bool a flag to return all fields of a requested language. False Returns: Type Description List[presidio_analyzer.entity_recognizer.EntityRecognizer] A list of the recognizers which supports the supplied entities and language Source code in presidio_analyzer/recognizer_registry/recognizer_registry.py def get_recognizers ( self , language : str , entities : Optional [ List [ str ]] = None , all_fields : bool = False , ) -> List [ EntityRecognizer ]: \"\"\" Return a list of recognizers which supports the specified name and language. :param entities: the requested entities :param language: the requested language :param all_fields: a flag to return all fields of a requested language. :return: A list of the recognizers which supports the supplied entities and language \"\"\" if language is None : raise ValueError ( \"No language provided\" ) if entities is None and all_fields is False : raise ValueError ( \"No entities provided\" ) all_possible_recognizers = self . recognizers # filter out unwanted recognizers to_return = [] if all_fields : to_return = [ rec for rec in all_possible_recognizers if language == rec . supported_language ] else : for entity in entities : subset = [ rec for rec in all_possible_recognizers if entity in rec . supported_entities and language == rec . supported_language ] if not subset : logger . warning ( \"Entity %s doesn't have the corresponding\" \" recognizer in language : %s \" , entity , language , ) else : to_return . extend ( subset ) logger . debug ( \"Returning a total of %s recognizers\" , str ( len ( to_return )), ) if not to_return : raise ValueError ( \"No matching recognizers were found to serve the request.\" ) return to_return load_predefined_recognizers ( self , languages = None , nlp_engine = None ) Load the existing recognizers into memory. Parameters: Name Type Description Default languages Optional[List[str]] List of languages for which to load recognizers None nlp_engine NlpEngine The NLP engine to use. None Returns: Type Description None None Source code in presidio_analyzer/recognizer_registry/recognizer_registry.py def load_predefined_recognizers ( self , languages : Optional [ List [ str ]] = None , nlp_engine : NlpEngine = None ) -> None : \"\"\" Load the existing recognizers into memory. :param languages: List of languages for which to load recognizers :param nlp_engine: The NLP engine to use. :return: None \"\"\" if not languages : languages = [ \"en\" ] nlp_recognizer = self . _get_nlp_recognizer ( nlp_engine ) recognizers_map = { \"en\" : [ UsBankRecognizer , UsLicenseRecognizer , UsItinRecognizer , UsPassportRecognizer , UsPhoneRecognizer , UsSsnRecognizer , NhsRecognizer , SgFinRecognizer , ], \"es\" : [ EsNifRecognizer ], \"ALL\" : [ CreditCardRecognizer , CryptoRecognizer , DomainRecognizer , EmailRecognizer , IbanRecognizer , IpRecognizer , nlp_recognizer , ], } for lang in languages : lang_recognizers = [ rc () for rc in recognizers_map . get ( lang , [])] self . recognizers . extend ( lang_recognizers ) all_recognizers = [ rc ( supported_language = lang ) for rc in recognizers_map . get ( \"ALL\" , []) ] self . recognizers . extend ( all_recognizers ) remove_recognizer ( self , recognizer_name ) Remove a recognizer based on its name. Parameters: Name Type Description Default recognizer_name str Name of recognizer to remove required Source code in presidio_analyzer/recognizer_registry/recognizer_registry.py def remove_recognizer ( self , recognizer_name : str ) -> None : \"\"\" Remove a recognizer based on its name. :param recognizer_name: Name of recognizer to remove \"\"\" new_recognizers = [ rec for rec in self . recognizers if rec . name != recognizer_name ] logger . info ( \"Removed %s recognizers which had the name %s \" , str ( len ( self . recognizers ) - len ( new_recognizers )), recognizer_name , ) self . recognizers = new_recognizers EntityRecognizer A class representing an abstract PII entity recognizer. EntityRecognizer is an abstract class to be inherited by Recognizers which hold the logic for recognizing specific PII entities. Parameters: Name Type Description Default supported_entities the entities supported by this recognizer (for example, phone number, address, etc.) required supported_language the language supported by this recognizer. The supported langauge code is iso6391Name required name the name of this recognizer (optional) required version the recognizer current version required analyze ( self , text , entities , nlp_artifacts ) Analyze text to identify entities. Parameters: Name Type Description Default text str The text to be analyzed required entities List[str] The list of entities this recognizer is able to detect required nlp_artifacts NlpArtifacts A group of attributes which are the result of an NLP process over the input text. required Returns: Type Description List[presidio_analyzer.recognizer_result.RecognizerResult] List of results detected by this recognizer. Source code in presidio_analyzer/entity_recognizer.py @abstractmethod def analyze ( self , text : str , entities : List [ str ], nlp_artifacts : NlpArtifacts ) -> List [ RecognizerResult ]: \"\"\" Analyze text to identify entities. :param text: The text to be analyzed :param entities: The list of entities this recognizer is able to detect :param nlp_artifacts: A group of attributes which are the result of an NLP process over the input text. :return: List of results detected by this recognizer. \"\"\" return None enhance_using_context ( self , text , raw_results , nlp_artifacts , recognizer_context_words ) Update results in case surrounding words are relevant to the context words. Using the surrounding words of the actual word matches, look for specific strings that if found contribute to the score of the result, improving the confidence that the match is indeed of that PII entity type Parameters: Name Type Description Default text str The actual text that was analyzed required raw_results List[presidio_analyzer.recognizer_result.RecognizerResult] Recognizer results which didn't take context into consideration required nlp_artifacts NlpArtifacts The nlp artifacts contains elements such as lemmatized tokens for better accuracy of the context enhancement process required recognizer_context_words List[str] The words the current recognizer supports (words to lookup) required Source code in presidio_analyzer/entity_recognizer.py def enhance_using_context ( self , text : str , raw_results : List [ RecognizerResult ], nlp_artifacts : NlpArtifacts , recognizer_context_words : List [ str ], ) -> List [ RecognizerResult ]: \"\"\" Update results in case surrounding words are relevant to the context words. Using the surrounding words of the actual word matches, look for specific strings that if found contribute to the score of the result, improving the confidence that the match is indeed of that PII entity type :param text: The actual text that was analyzed :param raw_results: Recognizer results which didn't take context into consideration :param nlp_artifacts: The nlp artifacts contains elements such as lemmatized tokens for better accuracy of the context enhancement process :param recognizer_context_words: The words the current recognizer supports (words to lookup) \"\"\" # create a deep copy of the results object so we can manipulate it results = copy . deepcopy ( raw_results ) # Sanity if nlp_artifacts is None : logger . warning ( \"[ %s ]. NLP artifacts were not provided\" , self . name ) return results if recognizer_context_words is None or recognizer_context_words == []: logger . info ( \"recognizer ' %s ' does not support context \" \"enhancement\" , self . name ) return results for result in results : # extract lemmatized context from the surrounding of the match word = text [ result . start : result . end ] surrounding_words = self . __extract_surrounding_words ( nlp_artifacts = nlp_artifacts , word = word , start = result . start ) supportive_context_word = self . __find_supportive_word_in_context ( surrounding_words , recognizer_context_words ) if supportive_context_word != \"\" : result . score += self . CONTEXT_SIMILARITY_FACTOR result . score = max ( result . score , self . MIN_SCORE_WITH_CONTEXT_SIMILARITY ) result . score = min ( result . score , EntityRecognizer . MAX_SCORE ) # Update the explainability object with context information # helped improving the score result . analysis_explanation . set_supportive_context_word ( supportive_context_word ) result . analysis_explanation . set_improved_score ( result . score ) return results from_dict ( entity_recognizer_dict ) classmethod Create EntityRecognizer from a dict input. Parameters: Name Type Description Default entity_recognizer_dict Dict Dict containing keys and values for instantiation required Source code in presidio_analyzer/entity_recognizer.py @classmethod def from_dict ( cls , entity_recognizer_dict : Dict ) -> \"EntityRecognizer\" : \"\"\" Create EntityRecognizer from a dict input. :param entity_recognizer_dict: Dict containing keys and values for instantiation \"\"\" return cls ( ** entity_recognizer_dict ) get_supported_entities ( self ) Return the list of entities this recognizer can identify. Returns: Type Description List[str] A list of the supported entities by this recognizer Source code in presidio_analyzer/entity_recognizer.py def get_supported_entities ( self ) -> List [ str ]: \"\"\" Return the list of entities this recognizer can identify. :return: A list of the supported entities by this recognizer \"\"\" return self . supported_entities get_supported_language ( self ) Return the language this recognizer can support. Returns: Type Description str A list of the supported language by this recognizer Source code in presidio_analyzer/entity_recognizer.py def get_supported_language ( self ) -> str : \"\"\" Return the language this recognizer can support. :return: A list of the supported language by this recognizer \"\"\" return self . supported_language get_version ( self ) Return the version of this recognizer. Returns: Type Description str The current version of this recognizer Source code in presidio_analyzer/entity_recognizer.py def get_version ( self ) -> str : \"\"\" Return the version of this recognizer. :return: The current version of this recognizer \"\"\" return self . version load ( self ) Initialize the recognizer assets if needed. (e.g. machine learning models) Source code in presidio_analyzer/entity_recognizer.py @abstractmethod def load ( self ) -> None : \"\"\" Initialize the recognizer assets if needed. (e.g. machine learning models) \"\"\" remove_duplicates ( results ) staticmethod Remove duplicate results. Remove duplicates in case the two results have identical start and ends and types. Parameters: Name Type Description Default results List[presidio_analyzer.recognizer_result.RecognizerResult] List[RecognizerResult] required Returns: Type Description List[presidio_analyzer.recognizer_result.RecognizerResult] List[RecognizerResult] Source code in presidio_analyzer/entity_recognizer.py @staticmethod def remove_duplicates ( results : List [ RecognizerResult ]) -> List [ RecognizerResult ]: \"\"\" Remove duplicate results. Remove duplicates in case the two results have identical start and ends and types. :param results: List[RecognizerResult] :return: List[RecognizerResult] \"\"\" # bug# 597: Analyzer remove duplicates doesn't handle all cases of one # result as a substring of the other results = sorted ( results , key = lambda x : ( - x . score , x . start , x . end - x . start )) filtered_results = [] for result in results : if result . score == 0 : continue valid_result = True if result not in filtered_results : for filtered in filtered_results : # If result is equal to or substring of # one of the other results if ( result . contained_in ( filtered ) and result . entity_type == filtered . entity_type ): valid_result = False break if valid_result : filtered_results . append ( result ) return filtered_results to_dict ( self ) Serialize self to dictionary. Returns: Type Description Dict a dictionary Source code in presidio_analyzer/entity_recognizer.py def to_dict ( self ) -> Dict : \"\"\" Serialize self to dictionary. :return: a dictionary \"\"\" return_dict = { \"supported_entities\" : self . supported_entities , \"supported_language\" : self . supported_language , \"name\" : self . name , \"version\" : self . version , } return return_dict RemoteRecognizer A configuration for a recognizer that runs on a different process / remote machine. Parameters: Name Type Description Default supported_entities A list of entities this recognizer can identify required name name of recognizer required supported_language The language this recognizer can detect entities in required version Version of this recognizer required analyze ( self , text , entities , nlp_artifacts ) Call an external service for PII detection. Parameters: Name Type Description Default text str text to be analyzed required entities List[str] Entities that should be looked for required nlp_artifacts NlpArtifacts Additional metadata from the NLP engine required Returns: Type Description List of identified PII entities Source code in presidio_analyzer/remote_recognizer.py @abstractmethod def analyze ( self , text : str , entities : List [ str ], nlp_artifacts : NlpArtifacts ): # noqa ANN201 \"\"\" Call an external service for PII detection. :param text: text to be analyzed :param entities: Entities that should be looked for :param nlp_artifacts: Additional metadata from the NLP engine :return: List of identified PII entities \"\"\" # 1. Call the external service. # 2. Translate results into List[RecognizerResult] pass get_supported_entities ( self ) Return the list of entities this recognizer can identify. Returns: Type Description List[str] A list of the supported entities by this recognizer Source code in presidio_analyzer/remote_recognizer.py @abstractmethod def get_supported_entities ( self ) -> List [ str ]: # noqa D102 pass load ( self ) Initialize the recognizer assets if needed. (e.g. machine learning models) Source code in presidio_analyzer/remote_recognizer.py @abstractmethod def load ( self ): # noqa D102 pass LocalRecognizer PII entity recognizer which runs on the same process as the AnalyzerEngine. PatternRecognizer PII entity recognizer using regular expressions or deny-lists. Parameters: Name Type Description Default patterns A list of patterns to detect required deny_list A list of words to detect, in case our recognizer uses a predefined list of words (deny list) required context list of context words required analyze ( self , text , entities , nlp_artifacts = None , regex_flags = None ) Analyzes text to detect PII using regular expressions or deny-lists. Parameters: Name Type Description Default text str Text to be analyzed required entities List[str] Entities this recognizer can detect required nlp_artifacts NlpArtifacts Output values from the NLP engine None regex_flags int None Returns: Type Description List[presidio_analyzer.recognizer_result.RecognizerResult] Source code in presidio_analyzer/pattern_recognizer.py def analyze ( self , text : str , entities : List [ str ], nlp_artifacts : NlpArtifacts = None , regex_flags : int = None , ) -> List [ RecognizerResult ]: \"\"\" Analyzes text to detect PII using regular expressions or deny-lists. :param text: Text to be analyzed :param entities: Entities this recognizer can detect :param nlp_artifacts: Output values from the NLP engine :param regex_flags: :return: \"\"\" results = [] if self . patterns : pattern_result = self . __analyze_patterns ( text , regex_flags ) if pattern_result and self . context : # try to improve the results score using the surrounding # context words enhanced_result = self . enhance_using_context ( text , pattern_result , nlp_artifacts , self . context ) results . extend ( enhanced_result ) elif pattern_result : results . extend ( pattern_result ) return results build_regex_explanation ( recognizer_name , pattern_name , pattern , original_score , validation_result ) staticmethod Construct an explanation for why this entity was detected. Parameters: Name Type Description Default recognizer_name str Name of recognizer detecting the entity required pattern_name str Regex pattern name which detected the entity required pattern str Regex pattern logic required original_score float Score given by the recognizer required validation_result bool Whether validation was used and its result required Returns: Type Description AnalysisExplanation Analysis explanation Source code in presidio_analyzer/pattern_recognizer.py @staticmethod def build_regex_explanation ( recognizer_name : str , pattern_name : str , pattern : str , original_score : float , validation_result : bool , ) -> AnalysisExplanation : \"\"\" Construct an explanation for why this entity was detected. :param recognizer_name: Name of recognizer detecting the entity :param pattern_name: Regex pattern name which detected the entity :param pattern: Regex pattern logic :param original_score: Score given by the recognizer :param validation_result: Whether validation was used and its result :return: Analysis explanation \"\"\" explanation = AnalysisExplanation ( recognizer = recognizer_name , original_score = original_score , pattern_name = pattern_name , pattern = pattern , validation_result = validation_result , ) return explanation from_dict ( entity_recognizer_dict ) classmethod Create instance from a serialized dict. Source code in presidio_analyzer/pattern_recognizer.py @classmethod def from_dict ( cls , entity_recognizer_dict : Dict ) -> \"PatternRecognizer\" : \"\"\"Create instance from a serialized dict.\"\"\" patterns = entity_recognizer_dict . get ( \"patterns\" ) if patterns : patterns_list = [ Pattern . from_dict ( pat ) for pat in patterns ] entity_recognizer_dict [ \"patterns\" ] = patterns_list return cls ( ** entity_recognizer_dict ) invalidate_result ( self , pattern_text ) Logic to check for result invalidation by running pruning logic. For example, each SSN number group should not consist of all the same digits. Parameters: Name Type Description Default pattern_text str the text to validated. Only the part in text that was detected by the regex engine required Returns: Type Description Optional[bool] A bool indicating whether the result is invalidated Source code in presidio_analyzer/pattern_recognizer.py def invalidate_result ( self , pattern_text : str ) -> Optional [ bool ]: \"\"\" Logic to check for result invalidation by running pruning logic. For example, each SSN number group should not consist of all the same digits. :param pattern_text: the text to validated. Only the part in text that was detected by the regex engine :return: A bool indicating whether the result is invalidated \"\"\" return None load ( self ) Initialize the recognizer assets if needed. (e.g. machine learning models) Source code in presidio_analyzer/pattern_recognizer.py def load ( self ): # noqa D102 pass to_dict ( self ) Serialize instance into a dictionary. Source code in presidio_analyzer/pattern_recognizer.py def to_dict ( self ) -> Dict : \"\"\"Serialize instance into a dictionary.\"\"\" return_dict = super () . to_dict () return_dict [ \"patterns\" ] = [ pat . to_dict () for pat in self . patterns ] return_dict [ \"deny_list\" ] = self . deny_list return_dict [ \"context\" ] = self . context return_dict [ \"supported_entity\" ] = return_dict [ \"supported_entities\" ][ 0 ] del return_dict [ \"supported_entities\" ] return return_dict validate_result ( self , pattern_text ) Validate the pattern logic e.g., by running checksum on a detected pattern. Parameters: Name Type Description Default pattern_text str the text to validated. Only the part in text that was detected by the regex engine required Returns: Type Description Optional[bool] A bool indicating whether the validation was successful. Source code in presidio_analyzer/pattern_recognizer.py def validate_result ( self , pattern_text : str ) -> Optional [ bool ]: \"\"\" Validate the pattern logic e.g., by running checksum on a detected pattern. :param pattern_text: the text to validated. Only the part in text that was detected by the regex engine :return: A bool indicating whether the validation was successful. \"\"\" return None NlpArtifacts NlpArtifacts is an abstraction layer over the results of an NLP pipeline. processing over a given text, it holds attributes such as entities, tokens and lemmas which can be used by any recognizer set_keywords ( nlp_engine , lemmas , language ) staticmethod Return keywords fpr text. Extracts lemmas with certain conditions as keywords. Source code in presidio_analyzer/nlp_engine/nlp_artifacts.py @staticmethod def set_keywords ( nlp_engine , lemmas : List [ str ], language : str # noqa ANN001 ) -> List [ str ]: \"\"\" Return keywords fpr text. Extracts lemmas with certain conditions as keywords. \"\"\" if not nlp_engine : return [] keywords = [ k . lower () for k in lemmas if not nlp_engine . is_stopword ( k , language ) and not nlp_engine . is_punct ( k , language ) and k != \"-PRON-\" and k != \"be\" ] # best effort, try even further to break tokens into sub tokens, # this can result in reducing false negatives keywords = [ i . split ( \":\" ) for i in keywords ] # splitting the list can, if happened, will result in list of lists, # we flatten the list keywords = [ item for sublist in keywords for item in sublist ] return keywords to_json ( self ) Convert nlp artifacts to json. Source code in presidio_analyzer/nlp_engine/nlp_artifacts.py def to_json ( self ) -> str : \"\"\"Convert nlp artifacts to json.\"\"\" return_dict = self . __dict__ . copy () # Converting spaCy tokens and spans to string as they are not serializable if \"tokens\" in return_dict : return_dict [ \"tokens\" ] = [ token . text for token in self . tokens ] if \"entities\" in return_dict : return_dict [ \"entities\" ] = [ entity . text for entity in self . entities ] return json . dumps ( return_dict ) NlpEngine is an abstraction layer over the nlp module. It provides NLP preprocessing functionality as well as other queries on tokens. is_punct ( self , word , language ) Return true if the given word is a punctuation word. (within the given language) Source code in presidio_analyzer/nlp_engine/nlp_engine.py @abstractmethod def is_punct ( self , word : str , language : str ) -> bool : \"\"\" Return true if the given word is a punctuation word. (within the given language) \"\"\" is_stopword ( self , word , language ) Return true if the given word is a stop word. (within the given language) Source code in presidio_analyzer/nlp_engine/nlp_engine.py @abstractmethod def is_stopword ( self , word : str , language : str ) -> bool : \"\"\" Return true if the given word is a stop word. (within the given language) \"\"\" process_text ( self , text , language ) Execute the NLP pipeline on the given text and language. Source code in presidio_analyzer/nlp_engine/nlp_engine.py @abstractmethod def process_text ( self , text : str , language : str ) -> NlpArtifacts : \"\"\"Execute the NLP pipeline on the given text and language.\"\"\" SpacyNlpEngine is an abstraction layer over the nlp module. It provides processing functionality as well as other queries on tokens. The SpacyNlpEngine uses SpaCy as its NLP module __init__ ( self , models = None ) special Initialize a wrapper on spaCy functionality. Parameters: Name Type Description Default models Optional[Dict[str, str]] Dictionary with the name of the spaCy model per language. For example: models = {\"en\": \"en_core_web_lg\"} None Source code in presidio_analyzer/nlp_engine/spacy_nlp_engine.py def __init__ ( self , models : Optional [ Dict [ str , str ]] = None ): \"\"\" Initialize a wrapper on spaCy functionality. :param models: Dictionary with the name of the spaCy model per language. For example: models = {\"en\": \"en_core_web_lg\"} \"\"\" if not models : models = { \"en\" : \"en_core_web_lg\" } logger . debug ( f \"Loading SpaCy models: { models . values () } \" ) self . nlp = { lang_code : spacy . load ( model_name , disable = [ \"parser\" , \"tagger\" ]) for lang_code , model_name in models . items () } get_nlp ( self , language ) Return the language model loaded for a language. Parameters: Name Type Description Default language str Name of language required Returns: Type Description Language Language model from spaCy Source code in presidio_analyzer/nlp_engine/spacy_nlp_engine.py def get_nlp ( self , language : str ) -> Language : \"\"\" Return the language model loaded for a language. :param language: Name of language :return: Language model from spaCy \"\"\" return self . nlp [ language ] is_punct ( self , word , language ) Return true if the given word is a punctuation word. (within the given language). Source code in presidio_analyzer/nlp_engine/spacy_nlp_engine.py def is_punct ( self , word : str , language : str ) -> bool : \"\"\" Return true if the given word is a punctuation word. (within the given language). \"\"\" return self . nlp [ language ] . vocab [ word ] . is_punct is_stopword ( self , word , language ) Return true if the given word is a stop word. (within the given language) Source code in presidio_analyzer/nlp_engine/spacy_nlp_engine.py def is_stopword ( self , word : str , language : str ) -> bool : \"\"\" Return true if the given word is a stop word. (within the given language) \"\"\" return self . nlp [ language ] . vocab [ word ] . is_stop process_text ( self , text , language ) Execute the SpaCy NLP pipeline on the given text and language. Source code in presidio_analyzer/nlp_engine/spacy_nlp_engine.py def process_text ( self , text : str , language : str ) -> NlpArtifacts : \"\"\"Execute the SpaCy NLP pipeline on the given text and language.\"\"\" doc = self . nlp [ language ]( text ) return self . _doc_to_nlp_artifact ( doc , language ) Create different NLP engines from configuration. Parameters: Name Type Description Default nlp_engines List of available NLP engines. Default: (SpacyNlpEngine, StanzaNlpEngine) required nlp_configuration Dict containing nlp configuration Example configuration: { \"nlp_engine_name\": \"spacy\", \"models\": [{\"lang_code\": \"en\", \"model_name\": \"en_core_web_lg\" }] } Nlp engine names available by default: spacy, stanza. required conf_file Path to yaml file containing nlp engine configuration. required create_engine ( self ) Create an NLP engine instance. Source code in presidio_analyzer/nlp_engine/nlp_engine_provider.py def create_engine ( self ) -> NlpEngine : \"\"\"Create an NLP engine instance.\"\"\" if ( not self . nlp_configuration or not self . nlp_configuration . get ( \"models\" ) or not self . nlp_configuration . get ( \"nlp_engine_name\" ) ): raise ValueError ( \"Illegal nlp configuration. \" \"Configuration should include nlp_engine_name and models \" \"(list of model_name for each lang_code).\" ) try : nlp_engine_name = self . nlp_configuration [ \"nlp_engine_name\" ] nlp_engine_class = self . nlp_engines [ nlp_engine_name ] nlp_engine_opts = { m [ \"lang_code\" ]: m [ \"model_name\" ] for m in self . nlp_configuration [ \"models\" ] } engine = nlp_engine_class ( nlp_engine_opts ) logger . info ( f \"Created NLP engine: { engine . engine_name } . \" f \"Loaded models: { list ( engine . nlp . keys ()) } \" ) return engine except KeyError : raise ValueError ( \"Wrong NLP engine configuration\" ) RecognizerResult Recognizer Result represents the findings of the detected entity. Result of a recognizer analyzing the text. Parameters: Name Type Description Default entity_type the type of the entity required start the start location of the detected entity required end the end location of the detected entity required score the score of the detection required analysis_explanation contains the explanation of why this entity was identified required __repr__ ( self ) special Return a string representation of the instance. Source code in presidio_analyzer/recognizer_result.py def __repr__ ( self ) -> str : \"\"\"Return a string representation of the instance.\"\"\" return self . __str__ () __str__ ( self ) special Return a string representation of the instance. Source code in presidio_analyzer/recognizer_result.py def __str__ ( self ) -> str : \"\"\"Return a string representation of the instance.\"\"\" return ( f \"type: { self . entity_type } , \" f \"start: { self . start } , \" f \"end: { self . end } , \" f \"score: { self . score } \" ) append_analysis_explenation_text ( self , text ) Add text to the analysis explanation. Source code in presidio_analyzer/recognizer_result.py def append_analysis_explenation_text ( self , text : str ) -> None : \"\"\"Add text to the analysis explanation.\"\"\" if self . analysis_explanation : self . analysis_explanation . append_textual_explanation_line ( text ) contained_in ( self , other ) Check if self is contained in a different RecognizerResult. Returns: Type Description bool true if contained Source code in presidio_analyzer/recognizer_result.py def contained_in ( self , other : \"RecognizerResult\" ) -> bool : \"\"\" Check if self is contained in a different RecognizerResult. :return: true if contained \"\"\" return self . start >= other . start and self . end <= other . end intersects ( self , other ) Check if self intersects with a different RecognizerResult. Returns: Type Description int If intersecting, returns the number of intersecting characters. If not, returns 0 Source code in presidio_analyzer/recognizer_result.py def intersects ( self , other : \"RecognizerResult\" ) -> int : \"\"\" Check if self intersects with a different RecognizerResult. :return: If intersecting, returns the number of intersecting characters. If not, returns 0 \"\"\" # if they do not overlap the intersection is 0 if self . end < other . start or other . end < self . start : return 0 # otherwise the intersection is min(end) - max(start) return min ( self . end , other . end ) - max ( self . start , other . start ) to_dict ( self ) Serialize self to dictionary. Returns: Type Description Dict a dictionary Source code in presidio_analyzer/recognizer_result.py def to_dict ( self ) -> Dict : \"\"\" Serialize self to dictionary. :return: a dictionary \"\"\" return self . __dict__ Pattern A class that represents a regex pattern. Parameters: Name Type Description Default name the name of the pattern required regex the regex pattern to detect required score the pattern's strength (values varies 0-1) required __repr__ ( self ) special Return string representation of instance. Source code in presidio_analyzer/pattern.py def __repr__ ( self ): \"\"\"Return string representation of instance.\"\"\" return json . dumps ( self . to_dict ()) __str__ ( self ) special Return string representation of instance. Source code in presidio_analyzer/pattern.py def __str__ ( self ): \"\"\"Return string representation of instance.\"\"\" return json . dumps ( self . to_dict ()) from_dict ( pattern_dict ) classmethod Load an instance from a dictionary. Parameters: Name Type Description Default pattern_dict Dict a dictionary holding the pattern's parameters required Returns: Type Description Pattern a Pattern instance Source code in presidio_analyzer/pattern.py @classmethod def from_dict ( cls , pattern_dict : Dict ) -> \"Pattern\" : \"\"\" Load an instance from a dictionary. :param pattern_dict: a dictionary holding the pattern's parameters :return: a Pattern instance \"\"\" return cls ( ** pattern_dict ) to_dict ( self ) Turn this instance into a dictionary. Returns: Type Description Dict a dictionary Source code in presidio_analyzer/pattern.py def to_dict ( self ) -> Dict : \"\"\" Turn this instance into a dictionary. :return: a dictionary \"\"\" return_dict = { \"name\" : self . name , \"score\" : self . score , \"regex\" : self . regex } return return_dict","title":"Presidio Analyzer Python API"},{"location":"api/analyzer_python/#presidio-analyzer-api-reference","text":"","title":"Presidio Analyzer API Reference"},{"location":"api/analyzer_python/#analyzerengine","text":"Entry point for Presidio Analyzer. Orchestrating the detection of PII entities and all related logic. Parameters: Name Type Description Default registry instance of type RecognizerRegistry required nlp_engine instance of type NlpEngine (for example SpacyNlpEngine) required app_tracer instance of type AppTracer, used to trace the logic used during each request for interpretability reasons. required log_decision_process bool, defines whether the decision process within the analyzer should be logged or not. required default_score_threshold Minimum confidence value for detected entities to be returned required supported_languages List of possible languages this engine could be run on. Used for loading the right NLP models and recognizers for these languages. required","title":"AnalyzerEngine"},{"location":"api/analyzer_python/#presidio_analyzer.analyzer_engine.AnalyzerEngine.analyze","text":"Find PII entities in text using different PII recognizers for a given language. :example: from presidio_analyzer import AnalyzerEngine","title":"analyze()"},{"location":"api/analyzer_python/#presidio_analyzer.analyzer_engine.AnalyzerEngine.analyze--set-up-the-engine-loads-the-nlp-module-spacy-model-by-default","text":"","title":"Set up the engine, loads the NLP module (spaCy model by default)"},{"location":"api/analyzer_python/#presidio_analyzer.analyzer_engine.AnalyzerEngine.analyze--and-other-pii-recognizers","text":"analyzer = AnalyzerEngine()","title":"and other PII recognizers"},{"location":"api/analyzer_python/#presidio_analyzer.analyzer_engine.AnalyzerEngine.analyze--call-analyzer-to-get-results","text":"results = analyzer.analyze(text='My phone number is 212-555-5555', entities=['PHONE_NUMBER'], language='en') # noqa D501 print(results) [type: PHONE_NUMBER, start: 19, end: 31, score: 0.85] Parameters: Name Type Description Default text str the text to analyze required language str the language of the text required entities Optional[List[str]] List of PII entities that should be looked for in the text. If entities=None then all entities are looked for. None correlation_id Optional[str] cross call ID for this request None score_threshold Optional[float] A minimum value for which to return an identified entity None return_decision_process Optional[bool] Whether the analysis decision process steps returned in the response. False Returns: Type Description List[presidio_analyzer.recognizer_result.RecognizerResult] an array of the found entities in the text Source code in presidio_analyzer/analyzer_engine.py def analyze ( self , text : str , language : str , entities : Optional [ List [ str ]] = None , correlation_id : Optional [ str ] = None , score_threshold : Optional [ float ] = None , return_decision_process : Optional [ bool ] = False , ) -> List [ RecognizerResult ]: \"\"\" Find PII entities in text using different PII recognizers for a given language. :param text: the text to analyze :param language: the language of the text :param entities: List of PII entities that should be looked for in the text. If entities=None then all entities are looked for. :param correlation_id: cross call ID for this request :param score_threshold: A minimum value for which to return an identified entity :param return_decision_process: Whether the analysis decision process steps returned in the response. :return: an array of the found entities in the text :example: >>> from presidio_analyzer import AnalyzerEngine >>> # Set up the engine, loads the NLP module (spaCy model by default) >>> # and other PII recognizers >>> analyzer = AnalyzerEngine() >>> # Call analyzer to get results >>> results = analyzer.analyze(text='My phone number is 212-555-5555', entities=['PHONE_NUMBER'], language='en') # noqa D501 >>> print(results) [type: PHONE_NUMBER, start: 19, end: 31, score: 0.85] \"\"\" all_fields = not entities recognizers = self . registry . get_recognizers ( language = language , entities = entities , all_fields = all_fields ) if all_fields : # Since all_fields=True, list all entities by iterating # over all recognizers entities = self . get_supported_entities ( language = language ) # run the nlp pipeline over the given text, store the results in # a NlpArtifacts instance nlp_artifacts = self . nlp_engine . process_text ( text , language ) if self . log_decision_process : self . app_tracer . trace ( correlation_id , \"nlp artifacts:\" + nlp_artifacts . to_json () ) results = [] for recognizer in recognizers : # Lazy loading of the relevant recognizers if not recognizer . is_loaded : recognizer . load () recognizer . is_loaded = True # analyze using the current recognizer and append the results current_results = recognizer . analyze ( text = text , entities = entities , nlp_artifacts = nlp_artifacts ) if current_results : results . extend ( current_results ) if self . log_decision_process : self . app_tracer . trace ( correlation_id , json . dumps ([ str ( result . to_dict ()) for result in results ]), ) # Remove duplicates or low score results results = EntityRecognizer . remove_duplicates ( results ) results = self . __remove_low_scores ( results , score_threshold ) if not return_decision_process : results = self . __remove_decision_process ( results ) return results","title":"Call analyzer to get results"},{"location":"api/analyzer_python/#presidio_analyzer.analyzer_engine.AnalyzerEngine.get_recognizers","text":"Return a list of PII recognizers currently loaded. Parameters: Name Type Description Default language Optional[str] Return the recognizers supporting a given language. None Returns: Type Description List[presidio_analyzer.entity_recognizer.EntityRecognizer] List of [Recognizer] as a RecognizersAllResponse Source code in presidio_analyzer/analyzer_engine.py def get_recognizers ( self , language : Optional [ str ] = None ) -> List [ EntityRecognizer ]: \"\"\" Return a list of PII recognizers currently loaded. :param language: Return the recognizers supporting a given language. :return: List of [Recognizer] as a RecognizersAllResponse \"\"\" if not language : languages = self . supported_languages else : languages = [ language ] recognizers = [] for language in languages : logger . info ( f \"Fetching all recognizers for language { language } \" ) recognizers . extend ( self . registry . get_recognizers ( language = language , all_fields = True ) ) return list ( set ( recognizers ))","title":"get_recognizers()"},{"location":"api/analyzer_python/#presidio_analyzer.analyzer_engine.AnalyzerEngine.get_supported_entities","text":"Return a list of the entities that can be detected. Parameters: Name Type Description Default language Optional[str] Return only entities supported in a specific language. None Returns: Type Description List[str] List of entity names Source code in presidio_analyzer/analyzer_engine.py def get_supported_entities ( self , language : Optional [ str ] = None ) -> List [ str ]: \"\"\" Return a list of the entities that can be detected. :param language: Return only entities supported in a specific language. :return: List of entity names \"\"\" recognizers = self . get_recognizers ( language = language ) supported_entities = [] for recognizer in recognizers : supported_entities . extend ( recognizer . get_supported_entities ()) return list ( set ( supported_entities ))","title":"get_supported_entities()"},{"location":"api/analyzer_python/#recognizerregistry","text":"Detect, register and hold all recognizers to be used by the analyzer. Parameters: Name Type Description Default recognizers An optional list of recognizers, that will be available instead of the predefined recognizers required","title":"RecognizerRegistry"},{"location":"api/analyzer_python/#presidio_analyzer.recognizer_registry.recognizer_registry.RecognizerRegistry.add_recognizer","text":"Add a new recognizer to the list of recognizers. Parameters: Name Type Description Default recognizer EntityRecognizer Recognizer to add required Source code in presidio_analyzer/recognizer_registry/recognizer_registry.py def add_recognizer ( self , recognizer : EntityRecognizer ) -> None : \"\"\" Add a new recognizer to the list of recognizers. :param recognizer: Recognizer to add \"\"\" if not isinstance ( recognizer , EntityRecognizer ): raise ValueError ( \"Input is not of type EntityRecognizer\" ) self . recognizers . append ( recognizer )","title":"add_recognizer()"},{"location":"api/analyzer_python/#presidio_analyzer.recognizer_registry.recognizer_registry.RecognizerRegistry.get_recognizers","text":"Return a list of recognizers which supports the specified name and language. Parameters: Name Type Description Default entities Optional[List[str]] the requested entities None language str the requested language required all_fields bool a flag to return all fields of a requested language. False Returns: Type Description List[presidio_analyzer.entity_recognizer.EntityRecognizer] A list of the recognizers which supports the supplied entities and language Source code in presidio_analyzer/recognizer_registry/recognizer_registry.py def get_recognizers ( self , language : str , entities : Optional [ List [ str ]] = None , all_fields : bool = False , ) -> List [ EntityRecognizer ]: \"\"\" Return a list of recognizers which supports the specified name and language. :param entities: the requested entities :param language: the requested language :param all_fields: a flag to return all fields of a requested language. :return: A list of the recognizers which supports the supplied entities and language \"\"\" if language is None : raise ValueError ( \"No language provided\" ) if entities is None and all_fields is False : raise ValueError ( \"No entities provided\" ) all_possible_recognizers = self . recognizers # filter out unwanted recognizers to_return = [] if all_fields : to_return = [ rec for rec in all_possible_recognizers if language == rec . supported_language ] else : for entity in entities : subset = [ rec for rec in all_possible_recognizers if entity in rec . supported_entities and language == rec . supported_language ] if not subset : logger . warning ( \"Entity %s doesn't have the corresponding\" \" recognizer in language : %s \" , entity , language , ) else : to_return . extend ( subset ) logger . debug ( \"Returning a total of %s recognizers\" , str ( len ( to_return )), ) if not to_return : raise ValueError ( \"No matching recognizers were found to serve the request.\" ) return to_return","title":"get_recognizers()"},{"location":"api/analyzer_python/#presidio_analyzer.recognizer_registry.recognizer_registry.RecognizerRegistry.load_predefined_recognizers","text":"Load the existing recognizers into memory. Parameters: Name Type Description Default languages Optional[List[str]] List of languages for which to load recognizers None nlp_engine NlpEngine The NLP engine to use. None Returns: Type Description None None Source code in presidio_analyzer/recognizer_registry/recognizer_registry.py def load_predefined_recognizers ( self , languages : Optional [ List [ str ]] = None , nlp_engine : NlpEngine = None ) -> None : \"\"\" Load the existing recognizers into memory. :param languages: List of languages for which to load recognizers :param nlp_engine: The NLP engine to use. :return: None \"\"\" if not languages : languages = [ \"en\" ] nlp_recognizer = self . _get_nlp_recognizer ( nlp_engine ) recognizers_map = { \"en\" : [ UsBankRecognizer , UsLicenseRecognizer , UsItinRecognizer , UsPassportRecognizer , UsPhoneRecognizer , UsSsnRecognizer , NhsRecognizer , SgFinRecognizer , ], \"es\" : [ EsNifRecognizer ], \"ALL\" : [ CreditCardRecognizer , CryptoRecognizer , DomainRecognizer , EmailRecognizer , IbanRecognizer , IpRecognizer , nlp_recognizer , ], } for lang in languages : lang_recognizers = [ rc () for rc in recognizers_map . get ( lang , [])] self . recognizers . extend ( lang_recognizers ) all_recognizers = [ rc ( supported_language = lang ) for rc in recognizers_map . get ( \"ALL\" , []) ] self . recognizers . extend ( all_recognizers )","title":"load_predefined_recognizers()"},{"location":"api/analyzer_python/#presidio_analyzer.recognizer_registry.recognizer_registry.RecognizerRegistry.remove_recognizer","text":"Remove a recognizer based on its name. Parameters: Name Type Description Default recognizer_name str Name of recognizer to remove required Source code in presidio_analyzer/recognizer_registry/recognizer_registry.py def remove_recognizer ( self , recognizer_name : str ) -> None : \"\"\" Remove a recognizer based on its name. :param recognizer_name: Name of recognizer to remove \"\"\" new_recognizers = [ rec for rec in self . recognizers if rec . name != recognizer_name ] logger . info ( \"Removed %s recognizers which had the name %s \" , str ( len ( self . recognizers ) - len ( new_recognizers )), recognizer_name , ) self . recognizers = new_recognizers","title":"remove_recognizer()"},{"location":"api/analyzer_python/#entityrecognizer","text":"A class representing an abstract PII entity recognizer. EntityRecognizer is an abstract class to be inherited by Recognizers which hold the logic for recognizing specific PII entities. Parameters: Name Type Description Default supported_entities the entities supported by this recognizer (for example, phone number, address, etc.) required supported_language the language supported by this recognizer. The supported langauge code is iso6391Name required name the name of this recognizer (optional) required version the recognizer current version required","title":"EntityRecognizer"},{"location":"api/analyzer_python/#presidio_analyzer.entity_recognizer.EntityRecognizer.analyze","text":"Analyze text to identify entities. Parameters: Name Type Description Default text str The text to be analyzed required entities List[str] The list of entities this recognizer is able to detect required nlp_artifacts NlpArtifacts A group of attributes which are the result of an NLP process over the input text. required Returns: Type Description List[presidio_analyzer.recognizer_result.RecognizerResult] List of results detected by this recognizer. Source code in presidio_analyzer/entity_recognizer.py @abstractmethod def analyze ( self , text : str , entities : List [ str ], nlp_artifacts : NlpArtifacts ) -> List [ RecognizerResult ]: \"\"\" Analyze text to identify entities. :param text: The text to be analyzed :param entities: The list of entities this recognizer is able to detect :param nlp_artifacts: A group of attributes which are the result of an NLP process over the input text. :return: List of results detected by this recognizer. \"\"\" return None","title":"analyze()"},{"location":"api/analyzer_python/#presidio_analyzer.entity_recognizer.EntityRecognizer.enhance_using_context","text":"Update results in case surrounding words are relevant to the context words. Using the surrounding words of the actual word matches, look for specific strings that if found contribute to the score of the result, improving the confidence that the match is indeed of that PII entity type Parameters: Name Type Description Default text str The actual text that was analyzed required raw_results List[presidio_analyzer.recognizer_result.RecognizerResult] Recognizer results which didn't take context into consideration required nlp_artifacts NlpArtifacts The nlp artifacts contains elements such as lemmatized tokens for better accuracy of the context enhancement process required recognizer_context_words List[str] The words the current recognizer supports (words to lookup) required Source code in presidio_analyzer/entity_recognizer.py def enhance_using_context ( self , text : str , raw_results : List [ RecognizerResult ], nlp_artifacts : NlpArtifacts , recognizer_context_words : List [ str ], ) -> List [ RecognizerResult ]: \"\"\" Update results in case surrounding words are relevant to the context words. Using the surrounding words of the actual word matches, look for specific strings that if found contribute to the score of the result, improving the confidence that the match is indeed of that PII entity type :param text: The actual text that was analyzed :param raw_results: Recognizer results which didn't take context into consideration :param nlp_artifacts: The nlp artifacts contains elements such as lemmatized tokens for better accuracy of the context enhancement process :param recognizer_context_words: The words the current recognizer supports (words to lookup) \"\"\" # create a deep copy of the results object so we can manipulate it results = copy . deepcopy ( raw_results ) # Sanity if nlp_artifacts is None : logger . warning ( \"[ %s ]. NLP artifacts were not provided\" , self . name ) return results if recognizer_context_words is None or recognizer_context_words == []: logger . info ( \"recognizer ' %s ' does not support context \" \"enhancement\" , self . name ) return results for result in results : # extract lemmatized context from the surrounding of the match word = text [ result . start : result . end ] surrounding_words = self . __extract_surrounding_words ( nlp_artifacts = nlp_artifacts , word = word , start = result . start ) supportive_context_word = self . __find_supportive_word_in_context ( surrounding_words , recognizer_context_words ) if supportive_context_word != \"\" : result . score += self . CONTEXT_SIMILARITY_FACTOR result . score = max ( result . score , self . MIN_SCORE_WITH_CONTEXT_SIMILARITY ) result . score = min ( result . score , EntityRecognizer . MAX_SCORE ) # Update the explainability object with context information # helped improving the score result . analysis_explanation . set_supportive_context_word ( supportive_context_word ) result . analysis_explanation . set_improved_score ( result . score ) return results","title":"enhance_using_context()"},{"location":"api/analyzer_python/#presidio_analyzer.entity_recognizer.EntityRecognizer.from_dict","text":"Create EntityRecognizer from a dict input. Parameters: Name Type Description Default entity_recognizer_dict Dict Dict containing keys and values for instantiation required Source code in presidio_analyzer/entity_recognizer.py @classmethod def from_dict ( cls , entity_recognizer_dict : Dict ) -> \"EntityRecognizer\" : \"\"\" Create EntityRecognizer from a dict input. :param entity_recognizer_dict: Dict containing keys and values for instantiation \"\"\" return cls ( ** entity_recognizer_dict )","title":"from_dict()"},{"location":"api/analyzer_python/#presidio_analyzer.entity_recognizer.EntityRecognizer.get_supported_entities","text":"Return the list of entities this recognizer can identify. Returns: Type Description List[str] A list of the supported entities by this recognizer Source code in presidio_analyzer/entity_recognizer.py def get_supported_entities ( self ) -> List [ str ]: \"\"\" Return the list of entities this recognizer can identify. :return: A list of the supported entities by this recognizer \"\"\" return self . supported_entities","title":"get_supported_entities()"},{"location":"api/analyzer_python/#presidio_analyzer.entity_recognizer.EntityRecognizer.get_supported_language","text":"Return the language this recognizer can support. Returns: Type Description str A list of the supported language by this recognizer Source code in presidio_analyzer/entity_recognizer.py def get_supported_language ( self ) -> str : \"\"\" Return the language this recognizer can support. :return: A list of the supported language by this recognizer \"\"\" return self . supported_language","title":"get_supported_language()"},{"location":"api/analyzer_python/#presidio_analyzer.entity_recognizer.EntityRecognizer.get_version","text":"Return the version of this recognizer. Returns: Type Description str The current version of this recognizer Source code in presidio_analyzer/entity_recognizer.py def get_version ( self ) -> str : \"\"\" Return the version of this recognizer. :return: The current version of this recognizer \"\"\" return self . version","title":"get_version()"},{"location":"api/analyzer_python/#presidio_analyzer.entity_recognizer.EntityRecognizer.load","text":"Initialize the recognizer assets if needed. (e.g. machine learning models) Source code in presidio_analyzer/entity_recognizer.py @abstractmethod def load ( self ) -> None : \"\"\" Initialize the recognizer assets if needed. (e.g. machine learning models) \"\"\"","title":"load()"},{"location":"api/analyzer_python/#presidio_analyzer.entity_recognizer.EntityRecognizer.remove_duplicates","text":"Remove duplicate results. Remove duplicates in case the two results have identical start and ends and types. Parameters: Name Type Description Default results List[presidio_analyzer.recognizer_result.RecognizerResult] List[RecognizerResult] required Returns: Type Description List[presidio_analyzer.recognizer_result.RecognizerResult] List[RecognizerResult] Source code in presidio_analyzer/entity_recognizer.py @staticmethod def remove_duplicates ( results : List [ RecognizerResult ]) -> List [ RecognizerResult ]: \"\"\" Remove duplicate results. Remove duplicates in case the two results have identical start and ends and types. :param results: List[RecognizerResult] :return: List[RecognizerResult] \"\"\" # bug# 597: Analyzer remove duplicates doesn't handle all cases of one # result as a substring of the other results = sorted ( results , key = lambda x : ( - x . score , x . start , x . end - x . start )) filtered_results = [] for result in results : if result . score == 0 : continue valid_result = True if result not in filtered_results : for filtered in filtered_results : # If result is equal to or substring of # one of the other results if ( result . contained_in ( filtered ) and result . entity_type == filtered . entity_type ): valid_result = False break if valid_result : filtered_results . append ( result ) return filtered_results","title":"remove_duplicates()"},{"location":"api/analyzer_python/#presidio_analyzer.entity_recognizer.EntityRecognizer.to_dict","text":"Serialize self to dictionary. Returns: Type Description Dict a dictionary Source code in presidio_analyzer/entity_recognizer.py def to_dict ( self ) -> Dict : \"\"\" Serialize self to dictionary. :return: a dictionary \"\"\" return_dict = { \"supported_entities\" : self . supported_entities , \"supported_language\" : self . supported_language , \"name\" : self . name , \"version\" : self . version , } return return_dict","title":"to_dict()"},{"location":"api/analyzer_python/#remoterecognizer","text":"A configuration for a recognizer that runs on a different process / remote machine. Parameters: Name Type Description Default supported_entities A list of entities this recognizer can identify required name name of recognizer required supported_language The language this recognizer can detect entities in required version Version of this recognizer required","title":"RemoteRecognizer"},{"location":"api/analyzer_python/#presidio_analyzer.remote_recognizer.RemoteRecognizer.analyze","text":"Call an external service for PII detection. Parameters: Name Type Description Default text str text to be analyzed required entities List[str] Entities that should be looked for required nlp_artifacts NlpArtifacts Additional metadata from the NLP engine required Returns: Type Description List of identified PII entities Source code in presidio_analyzer/remote_recognizer.py @abstractmethod def analyze ( self , text : str , entities : List [ str ], nlp_artifacts : NlpArtifacts ): # noqa ANN201 \"\"\" Call an external service for PII detection. :param text: text to be analyzed :param entities: Entities that should be looked for :param nlp_artifacts: Additional metadata from the NLP engine :return: List of identified PII entities \"\"\" # 1. Call the external service. # 2. Translate results into List[RecognizerResult] pass","title":"analyze()"},{"location":"api/analyzer_python/#presidio_analyzer.remote_recognizer.RemoteRecognizer.get_supported_entities","text":"Return the list of entities this recognizer can identify. Returns: Type Description List[str] A list of the supported entities by this recognizer Source code in presidio_analyzer/remote_recognizer.py @abstractmethod def get_supported_entities ( self ) -> List [ str ]: # noqa D102 pass","title":"get_supported_entities()"},{"location":"api/analyzer_python/#presidio_analyzer.remote_recognizer.RemoteRecognizer.load","text":"Initialize the recognizer assets if needed. (e.g. machine learning models) Source code in presidio_analyzer/remote_recognizer.py @abstractmethod def load ( self ): # noqa D102 pass","title":"load()"},{"location":"api/analyzer_python/#localrecognizer","text":"PII entity recognizer which runs on the same process as the AnalyzerEngine.","title":"LocalRecognizer"},{"location":"api/analyzer_python/#patternrecognizer","text":"PII entity recognizer using regular expressions or deny-lists. Parameters: Name Type Description Default patterns A list of patterns to detect required deny_list A list of words to detect, in case our recognizer uses a predefined list of words (deny list) required context list of context words required","title":"PatternRecognizer"},{"location":"api/analyzer_python/#presidio_analyzer.pattern_recognizer.PatternRecognizer.analyze","text":"Analyzes text to detect PII using regular expressions or deny-lists. Parameters: Name Type Description Default text str Text to be analyzed required entities List[str] Entities this recognizer can detect required nlp_artifacts NlpArtifacts Output values from the NLP engine None regex_flags int None Returns: Type Description List[presidio_analyzer.recognizer_result.RecognizerResult] Source code in presidio_analyzer/pattern_recognizer.py def analyze ( self , text : str , entities : List [ str ], nlp_artifacts : NlpArtifacts = None , regex_flags : int = None , ) -> List [ RecognizerResult ]: \"\"\" Analyzes text to detect PII using regular expressions or deny-lists. :param text: Text to be analyzed :param entities: Entities this recognizer can detect :param nlp_artifacts: Output values from the NLP engine :param regex_flags: :return: \"\"\" results = [] if self . patterns : pattern_result = self . __analyze_patterns ( text , regex_flags ) if pattern_result and self . context : # try to improve the results score using the surrounding # context words enhanced_result = self . enhance_using_context ( text , pattern_result , nlp_artifacts , self . context ) results . extend ( enhanced_result ) elif pattern_result : results . extend ( pattern_result ) return results","title":"analyze()"},{"location":"api/analyzer_python/#presidio_analyzer.pattern_recognizer.PatternRecognizer.build_regex_explanation","text":"Construct an explanation for why this entity was detected. Parameters: Name Type Description Default recognizer_name str Name of recognizer detecting the entity required pattern_name str Regex pattern name which detected the entity required pattern str Regex pattern logic required original_score float Score given by the recognizer required validation_result bool Whether validation was used and its result required Returns: Type Description AnalysisExplanation Analysis explanation Source code in presidio_analyzer/pattern_recognizer.py @staticmethod def build_regex_explanation ( recognizer_name : str , pattern_name : str , pattern : str , original_score : float , validation_result : bool , ) -> AnalysisExplanation : \"\"\" Construct an explanation for why this entity was detected. :param recognizer_name: Name of recognizer detecting the entity :param pattern_name: Regex pattern name which detected the entity :param pattern: Regex pattern logic :param original_score: Score given by the recognizer :param validation_result: Whether validation was used and its result :return: Analysis explanation \"\"\" explanation = AnalysisExplanation ( recognizer = recognizer_name , original_score = original_score , pattern_name = pattern_name , pattern = pattern , validation_result = validation_result , ) return explanation","title":"build_regex_explanation()"},{"location":"api/analyzer_python/#presidio_analyzer.pattern_recognizer.PatternRecognizer.from_dict","text":"Create instance from a serialized dict. Source code in presidio_analyzer/pattern_recognizer.py @classmethod def from_dict ( cls , entity_recognizer_dict : Dict ) -> \"PatternRecognizer\" : \"\"\"Create instance from a serialized dict.\"\"\" patterns = entity_recognizer_dict . get ( \"patterns\" ) if patterns : patterns_list = [ Pattern . from_dict ( pat ) for pat in patterns ] entity_recognizer_dict [ \"patterns\" ] = patterns_list return cls ( ** entity_recognizer_dict )","title":"from_dict()"},{"location":"api/analyzer_python/#presidio_analyzer.pattern_recognizer.PatternRecognizer.invalidate_result","text":"Logic to check for result invalidation by running pruning logic. For example, each SSN number group should not consist of all the same digits. Parameters: Name Type Description Default pattern_text str the text to validated. Only the part in text that was detected by the regex engine required Returns: Type Description Optional[bool] A bool indicating whether the result is invalidated Source code in presidio_analyzer/pattern_recognizer.py def invalidate_result ( self , pattern_text : str ) -> Optional [ bool ]: \"\"\" Logic to check for result invalidation by running pruning logic. For example, each SSN number group should not consist of all the same digits. :param pattern_text: the text to validated. Only the part in text that was detected by the regex engine :return: A bool indicating whether the result is invalidated \"\"\" return None","title":"invalidate_result()"},{"location":"api/analyzer_python/#presidio_analyzer.pattern_recognizer.PatternRecognizer.load","text":"Initialize the recognizer assets if needed. (e.g. machine learning models) Source code in presidio_analyzer/pattern_recognizer.py def load ( self ): # noqa D102 pass","title":"load()"},{"location":"api/analyzer_python/#presidio_analyzer.pattern_recognizer.PatternRecognizer.to_dict","text":"Serialize instance into a dictionary. Source code in presidio_analyzer/pattern_recognizer.py def to_dict ( self ) -> Dict : \"\"\"Serialize instance into a dictionary.\"\"\" return_dict = super () . to_dict () return_dict [ \"patterns\" ] = [ pat . to_dict () for pat in self . patterns ] return_dict [ \"deny_list\" ] = self . deny_list return_dict [ \"context\" ] = self . context return_dict [ \"supported_entity\" ] = return_dict [ \"supported_entities\" ][ 0 ] del return_dict [ \"supported_entities\" ] return return_dict","title":"to_dict()"},{"location":"api/analyzer_python/#presidio_analyzer.pattern_recognizer.PatternRecognizer.validate_result","text":"Validate the pattern logic e.g., by running checksum on a detected pattern. Parameters: Name Type Description Default pattern_text str the text to validated. Only the part in text that was detected by the regex engine required Returns: Type Description Optional[bool] A bool indicating whether the validation was successful. Source code in presidio_analyzer/pattern_recognizer.py def validate_result ( self , pattern_text : str ) -> Optional [ bool ]: \"\"\" Validate the pattern logic e.g., by running checksum on a detected pattern. :param pattern_text: the text to validated. Only the part in text that was detected by the regex engine :return: A bool indicating whether the validation was successful. \"\"\" return None","title":"validate_result()"},{"location":"api/analyzer_python/#nlpartifacts","text":"NlpArtifacts is an abstraction layer over the results of an NLP pipeline. processing over a given text, it holds attributes such as entities, tokens and lemmas which can be used by any recognizer","title":"NlpArtifacts"},{"location":"api/analyzer_python/#presidio_analyzer.nlp_engine.nlp_artifacts.NlpArtifacts.set_keywords","text":"Return keywords fpr text. Extracts lemmas with certain conditions as keywords. Source code in presidio_analyzer/nlp_engine/nlp_artifacts.py @staticmethod def set_keywords ( nlp_engine , lemmas : List [ str ], language : str # noqa ANN001 ) -> List [ str ]: \"\"\" Return keywords fpr text. Extracts lemmas with certain conditions as keywords. \"\"\" if not nlp_engine : return [] keywords = [ k . lower () for k in lemmas if not nlp_engine . is_stopword ( k , language ) and not nlp_engine . is_punct ( k , language ) and k != \"-PRON-\" and k != \"be\" ] # best effort, try even further to break tokens into sub tokens, # this can result in reducing false negatives keywords = [ i . split ( \":\" ) for i in keywords ] # splitting the list can, if happened, will result in list of lists, # we flatten the list keywords = [ item for sublist in keywords for item in sublist ] return keywords","title":"set_keywords()"},{"location":"api/analyzer_python/#presidio_analyzer.nlp_engine.nlp_artifacts.NlpArtifacts.to_json","text":"Convert nlp artifacts to json. Source code in presidio_analyzer/nlp_engine/nlp_artifacts.py def to_json ( self ) -> str : \"\"\"Convert nlp artifacts to json.\"\"\" return_dict = self . __dict__ . copy () # Converting spaCy tokens and spans to string as they are not serializable if \"tokens\" in return_dict : return_dict [ \"tokens\" ] = [ token . text for token in self . tokens ] if \"entities\" in return_dict : return_dict [ \"entities\" ] = [ entity . text for entity in self . entities ] return json . dumps ( return_dict ) NlpEngine is an abstraction layer over the nlp module. It provides NLP preprocessing functionality as well as other queries on tokens.","title":"to_json()"},{"location":"api/analyzer_python/#presidio_analyzer.nlp_engine.nlp_engine.NlpEngine.is_punct","text":"Return true if the given word is a punctuation word. (within the given language) Source code in presidio_analyzer/nlp_engine/nlp_engine.py @abstractmethod def is_punct ( self , word : str , language : str ) -> bool : \"\"\" Return true if the given word is a punctuation word. (within the given language) \"\"\"","title":"is_punct()"},{"location":"api/analyzer_python/#presidio_analyzer.nlp_engine.nlp_engine.NlpEngine.is_stopword","text":"Return true if the given word is a stop word. (within the given language) Source code in presidio_analyzer/nlp_engine/nlp_engine.py @abstractmethod def is_stopword ( self , word : str , language : str ) -> bool : \"\"\" Return true if the given word is a stop word. (within the given language) \"\"\"","title":"is_stopword()"},{"location":"api/analyzer_python/#presidio_analyzer.nlp_engine.nlp_engine.NlpEngine.process_text","text":"Execute the NLP pipeline on the given text and language. Source code in presidio_analyzer/nlp_engine/nlp_engine.py @abstractmethod def process_text ( self , text : str , language : str ) -> NlpArtifacts : \"\"\"Execute the NLP pipeline on the given text and language.\"\"\" SpacyNlpEngine is an abstraction layer over the nlp module. It provides processing functionality as well as other queries on tokens. The SpacyNlpEngine uses SpaCy as its NLP module","title":"process_text()"},{"location":"api/analyzer_python/#presidio_analyzer.nlp_engine.spacy_nlp_engine.SpacyNlpEngine.__init__","text":"Initialize a wrapper on spaCy functionality. Parameters: Name Type Description Default models Optional[Dict[str, str]] Dictionary with the name of the spaCy model per language. For example: models = {\"en\": \"en_core_web_lg\"} None Source code in presidio_analyzer/nlp_engine/spacy_nlp_engine.py def __init__ ( self , models : Optional [ Dict [ str , str ]] = None ): \"\"\" Initialize a wrapper on spaCy functionality. :param models: Dictionary with the name of the spaCy model per language. For example: models = {\"en\": \"en_core_web_lg\"} \"\"\" if not models : models = { \"en\" : \"en_core_web_lg\" } logger . debug ( f \"Loading SpaCy models: { models . values () } \" ) self . nlp = { lang_code : spacy . load ( model_name , disable = [ \"parser\" , \"tagger\" ]) for lang_code , model_name in models . items () }","title":"__init__()"},{"location":"api/analyzer_python/#presidio_analyzer.nlp_engine.spacy_nlp_engine.SpacyNlpEngine.get_nlp","text":"Return the language model loaded for a language. Parameters: Name Type Description Default language str Name of language required Returns: Type Description Language Language model from spaCy Source code in presidio_analyzer/nlp_engine/spacy_nlp_engine.py def get_nlp ( self , language : str ) -> Language : \"\"\" Return the language model loaded for a language. :param language: Name of language :return: Language model from spaCy \"\"\" return self . nlp [ language ]","title":"get_nlp()"},{"location":"api/analyzer_python/#presidio_analyzer.nlp_engine.spacy_nlp_engine.SpacyNlpEngine.is_punct","text":"Return true if the given word is a punctuation word. (within the given language). Source code in presidio_analyzer/nlp_engine/spacy_nlp_engine.py def is_punct ( self , word : str , language : str ) -> bool : \"\"\" Return true if the given word is a punctuation word. (within the given language). \"\"\" return self . nlp [ language ] . vocab [ word ] . is_punct","title":"is_punct()"},{"location":"api/analyzer_python/#presidio_analyzer.nlp_engine.spacy_nlp_engine.SpacyNlpEngine.is_stopword","text":"Return true if the given word is a stop word. (within the given language) Source code in presidio_analyzer/nlp_engine/spacy_nlp_engine.py def is_stopword ( self , word : str , language : str ) -> bool : \"\"\" Return true if the given word is a stop word. (within the given language) \"\"\" return self . nlp [ language ] . vocab [ word ] . is_stop","title":"is_stopword()"},{"location":"api/analyzer_python/#presidio_analyzer.nlp_engine.spacy_nlp_engine.SpacyNlpEngine.process_text","text":"Execute the SpaCy NLP pipeline on the given text and language. Source code in presidio_analyzer/nlp_engine/spacy_nlp_engine.py def process_text ( self , text : str , language : str ) -> NlpArtifacts : \"\"\"Execute the SpaCy NLP pipeline on the given text and language.\"\"\" doc = self . nlp [ language ]( text ) return self . _doc_to_nlp_artifact ( doc , language ) Create different NLP engines from configuration. Parameters: Name Type Description Default nlp_engines List of available NLP engines. Default: (SpacyNlpEngine, StanzaNlpEngine) required nlp_configuration Dict containing nlp configuration Example configuration: { \"nlp_engine_name\": \"spacy\", \"models\": [{\"lang_code\": \"en\", \"model_name\": \"en_core_web_lg\" }] } Nlp engine names available by default: spacy, stanza. required conf_file Path to yaml file containing nlp engine configuration. required","title":"process_text()"},{"location":"api/analyzer_python/#presidio_analyzer.nlp_engine.nlp_engine_provider.NlpEngineProvider.create_engine","text":"Create an NLP engine instance. Source code in presidio_analyzer/nlp_engine/nlp_engine_provider.py def create_engine ( self ) -> NlpEngine : \"\"\"Create an NLP engine instance.\"\"\" if ( not self . nlp_configuration or not self . nlp_configuration . get ( \"models\" ) or not self . nlp_configuration . get ( \"nlp_engine_name\" ) ): raise ValueError ( \"Illegal nlp configuration. \" \"Configuration should include nlp_engine_name and models \" \"(list of model_name for each lang_code).\" ) try : nlp_engine_name = self . nlp_configuration [ \"nlp_engine_name\" ] nlp_engine_class = self . nlp_engines [ nlp_engine_name ] nlp_engine_opts = { m [ \"lang_code\" ]: m [ \"model_name\" ] for m in self . nlp_configuration [ \"models\" ] } engine = nlp_engine_class ( nlp_engine_opts ) logger . info ( f \"Created NLP engine: { engine . engine_name } . \" f \"Loaded models: { list ( engine . nlp . keys ()) } \" ) return engine except KeyError : raise ValueError ( \"Wrong NLP engine configuration\" )","title":"create_engine()"},{"location":"api/analyzer_python/#recognizerresult","text":"Recognizer Result represents the findings of the detected entity. Result of a recognizer analyzing the text. Parameters: Name Type Description Default entity_type the type of the entity required start the start location of the detected entity required end the end location of the detected entity required score the score of the detection required analysis_explanation contains the explanation of why this entity was identified required","title":"RecognizerResult"},{"location":"api/analyzer_python/#presidio_analyzer.recognizer_result.RecognizerResult.__repr__","text":"Return a string representation of the instance. Source code in presidio_analyzer/recognizer_result.py def __repr__ ( self ) -> str : \"\"\"Return a string representation of the instance.\"\"\" return self . __str__ ()","title":"__repr__()"},{"location":"api/analyzer_python/#presidio_analyzer.recognizer_result.RecognizerResult.__str__","text":"Return a string representation of the instance. Source code in presidio_analyzer/recognizer_result.py def __str__ ( self ) -> str : \"\"\"Return a string representation of the instance.\"\"\" return ( f \"type: { self . entity_type } , \" f \"start: { self . start } , \" f \"end: { self . end } , \" f \"score: { self . score } \" )","title":"__str__()"},{"location":"api/analyzer_python/#presidio_analyzer.recognizer_result.RecognizerResult.append_analysis_explenation_text","text":"Add text to the analysis explanation. Source code in presidio_analyzer/recognizer_result.py def append_analysis_explenation_text ( self , text : str ) -> None : \"\"\"Add text to the analysis explanation.\"\"\" if self . analysis_explanation : self . analysis_explanation . append_textual_explanation_line ( text )","title":"append_analysis_explenation_text()"},{"location":"api/analyzer_python/#presidio_analyzer.recognizer_result.RecognizerResult.contained_in","text":"Check if self is contained in a different RecognizerResult. Returns: Type Description bool true if contained Source code in presidio_analyzer/recognizer_result.py def contained_in ( self , other : \"RecognizerResult\" ) -> bool : \"\"\" Check if self is contained in a different RecognizerResult. :return: true if contained \"\"\" return self . start >= other . start and self . end <= other . end","title":"contained_in()"},{"location":"api/analyzer_python/#presidio_analyzer.recognizer_result.RecognizerResult.intersects","text":"Check if self intersects with a different RecognizerResult. Returns: Type Description int If intersecting, returns the number of intersecting characters. If not, returns 0 Source code in presidio_analyzer/recognizer_result.py def intersects ( self , other : \"RecognizerResult\" ) -> int : \"\"\" Check if self intersects with a different RecognizerResult. :return: If intersecting, returns the number of intersecting characters. If not, returns 0 \"\"\" # if they do not overlap the intersection is 0 if self . end < other . start or other . end < self . start : return 0 # otherwise the intersection is min(end) - max(start) return min ( self . end , other . end ) - max ( self . start , other . start )","title":"intersects()"},{"location":"api/analyzer_python/#presidio_analyzer.recognizer_result.RecognizerResult.to_dict","text":"Serialize self to dictionary. Returns: Type Description Dict a dictionary Source code in presidio_analyzer/recognizer_result.py def to_dict ( self ) -> Dict : \"\"\" Serialize self to dictionary. :return: a dictionary \"\"\" return self . __dict__","title":"to_dict()"},{"location":"api/analyzer_python/#pattern","text":"A class that represents a regex pattern. Parameters: Name Type Description Default name the name of the pattern required regex the regex pattern to detect required score the pattern's strength (values varies 0-1) required","title":"Pattern"},{"location":"api/analyzer_python/#presidio_analyzer.pattern.Pattern.__repr__","text":"Return string representation of instance. Source code in presidio_analyzer/pattern.py def __repr__ ( self ): \"\"\"Return string representation of instance.\"\"\" return json . dumps ( self . to_dict ())","title":"__repr__()"},{"location":"api/analyzer_python/#presidio_analyzer.pattern.Pattern.__str__","text":"Return string representation of instance. Source code in presidio_analyzer/pattern.py def __str__ ( self ): \"\"\"Return string representation of instance.\"\"\" return json . dumps ( self . to_dict ())","title":"__str__()"},{"location":"api/analyzer_python/#presidio_analyzer.pattern.Pattern.from_dict","text":"Load an instance from a dictionary. Parameters: Name Type Description Default pattern_dict Dict a dictionary holding the pattern's parameters required Returns: Type Description Pattern a Pattern instance Source code in presidio_analyzer/pattern.py @classmethod def from_dict ( cls , pattern_dict : Dict ) -> \"Pattern\" : \"\"\" Load an instance from a dictionary. :param pattern_dict: a dictionary holding the pattern's parameters :return: a Pattern instance \"\"\" return cls ( ** pattern_dict )","title":"from_dict()"},{"location":"api/analyzer_python/#presidio_analyzer.pattern.Pattern.to_dict","text":"Turn this instance into a dictionary. Returns: Type Description Dict a dictionary Source code in presidio_analyzer/pattern.py def to_dict ( self ) -> Dict : \"\"\" Turn this instance into a dictionary. :return: a dictionary \"\"\" return_dict = { \"name\" : self . name , \"score\" : self . score , \"regex\" : self . regex } return return_dict","title":"to_dict()"},{"location":"api/anonymizer_python/","text":"Presidio Anonymizer API Reference Anonymizer root module. anonymizer_engine Handles the entire logic of the Presidio-anonymizer and text anonymizing. AnonymizerEngine AnonymizerEngine class. Handles the entire logic of the Presidio-anonymizer. Gets the original text and replaces the PII entities with the desired anonymizers. anonymize ( self , text , analyzer_results , anonymizers_config = None ) Anonymize method to anonymize the given text. Parameters: Name Type Description Default text str the text we are anonymizing required analyzer_results List[presidio_anonymizer.entities.analyzer_result.AnalyzerResult] A list of AnalyzerResult class -> The results we received from the analyzer required anonymizers_config Optional[Dict[str, presidio_anonymizer.entities.anonymizer_config.AnonymizerConfig]] The configuration of the anonymizers we would like to use for each entity e.g.: {\"PHONE_NUMBER\":AnonymizerConfig(\"redact\", {})} received from the analyzer None Returns: Type Description str the anonymized text Source code in presidio_anonymizer/anonymizer_engine.py def anonymize ( self , text : str , analyzer_results : List [ AnalyzerResult ], anonymizers_config : Optional [ Dict [ str , AnonymizerConfig ]] = None ) -> str : \"\"\"Anonymize method to anonymize the given text. :param text: the text we are anonymizing :param analyzer_results: A list of AnalyzerResult class -> The results we received from the analyzer :param anonymizers_config: The configuration of the anonymizers we would like to use for each entity e.g.: {\"PHONE_NUMBER\":AnonymizerConfig(\"redact\", {})} received from the analyzer :return: the anonymized text \"\"\" text_builder = AnonymizedTextBuilder ( original_text = text ) if not anonymizers_config : anonymizers_config = {} analyzer_results = ( AnalyzerResults ( analyzer_results ) . to_sorted_unique_results ( True ) ) # loop over each analyzer result # get AnonymizerConfig for the analyzer result # trigger the anonymize method on the section of the text # perform the anonymization # concat the anonymized string into the output string for analyzer_result in analyzer_results : text_to_anonymize = text_builder . get_text_in_position ( analyzer_result . start , analyzer_result . end ) anonymizer_config = self . __get_anonymizer_config_by_entity_type ( analyzer_result . entity_type , anonymizers_config ) self . logger . debug ( f \"for analyzer result { analyzer_result } received config \" f \" { anonymizer_config } \" ) anonymized_text = self . __extract_anonymizer_and_anonymize ( analyzer_result . entity_type , anonymizer_config , text_to_anonymize ) text_builder . replace_text ( anonymized_text , analyzer_result . start , analyzer_result . end ) return text_builder . output_text get_anonymizers () staticmethod Return a list of supported anonymizers. Source code in presidio_anonymizer/anonymizer_engine.py @staticmethod def get_anonymizers () -> List [ str ]: \"\"\"Return a list of supported anonymizers.\"\"\" names = [ p for p in Anonymizer . get_anonymizers () . keys ()] return names anonymizers special Initializing all the existing anonymizers. anonymizer Anonymizers abstraction - each anonymizer should implement this class. Anonymizer Anonymizer abstract class to be implemented by each anonymizer. anonymize ( self , text , params = None ) Anonymize method to be implemented in each anonymizer. Source code in presidio_anonymizer/anonymizers/anonymizer.py @abstractmethod def anonymize ( self , text : str , params : Dict = None ) -> str : \"\"\"Anonymize method to be implemented in each anonymizer.\"\"\" pass anonymizer_name ( self ) Return anonymizer name. Source code in presidio_anonymizer/anonymizers/anonymizer.py @abstractmethod def anonymizer_name ( self ) -> str : \"\"\"Return anonymizer name.\"\"\" pass get_anonymizers () staticmethod Return all anonymizers classes currently available. Source code in presidio_anonymizer/anonymizers/anonymizer.py @staticmethod def get_anonymizers () -> Dict [ str , 'Anonymizer' ]: \"\"\"Return all anonymizers classes currently available.\"\"\" if not Anonymizer . _anonymizers : Anonymizer . _anonymizers = { cls . anonymizer_name ( cls ): cls for cls in Anonymizer . __subclasses__ () } return Anonymizer . _anonymizers validate ( self , params = None ) Validate each anonymizer parameters. Source code in presidio_anonymizer/anonymizers/anonymizer.py @abstractmethod def validate ( self , params : Dict = None ) -> None : \"\"\"Validate each anonymizer parameters.\"\"\" pass hash Hashes the PII text entity. Hash Hash given text with sha256/sha512/md5 algorithm. anonymize ( self , text = None , params = None ) Hash given value using sha256. Returns: Type Description str hashed original text Source code in presidio_anonymizer/anonymizers/hash.py def anonymize ( self , text : str = None , params : Dict = None ) -> str : \"\"\" Hash given value using sha256. :return: hashed original text \"\"\" hash_type = self . _get_hash_type_or_default ( params ) hash_switcher = { self . SHA256 : lambda s : sha256 ( s ), self . SHA512 : lambda s : sha512 ( s ), self . MD5 : lambda s : md5 ( s ), } return hash_switcher . get ( hash_type )( text . encode ()) . hexdigest () anonymizer_name ( self ) Return anonymizer name. Source code in presidio_anonymizer/anonymizers/hash.py def anonymizer_name ( self ) -> str : \"\"\"Return anonymizer name.\"\"\" return \"hash\" validate ( self , params = None ) Validate the hash type is string and in range of allowed hash types. Source code in presidio_anonymizer/anonymizers/hash.py def validate ( self , params : Dict = None ) -> None : \"\"\"Validate the hash type is string and in range of allowed hash types.\"\"\" validate_parameter_in_range ( [ self . SHA256 , self . SHA512 , self . MD5 ], self . _get_hash_type_or_default ( params ), self . HASH_TYPE , str , ) pass mask Mask some or all given text entity PII with given character. Mask Mask the given text with given value. anonymize ( self , text = None , params = None ) Mask a given amount of text with a given character. Parameters: Name Type Description Default text str the text to be masked None params Dict None Returns: Type Description str the masked text Source code in presidio_anonymizer/anonymizers/mask.py def anonymize ( self , text : str = None , params : Dict = None ) -> str : \"\"\" Mask a given amount of text with a given character. :param text: the text to be masked :param params: masking_char: The character to be masked with chars_to_mask: The amount of characters to mask from_end: Whether to mask the text from it's end :return: the masked text \"\"\" effective_chars_to_mask = self . _get_effective_chars_to_mask ( text , params . get ( self . CHARS_TO_MASK ) ) from_end = params . get ( self . FROM_END ) masking_char = params . get ( self . MASKING_CHAR ) return self . _get_anonymized_text ( text , effective_chars_to_mask , from_end , masking_char ) anonymizer_name ( self ) Return anonymizer name. Source code in presidio_anonymizer/anonymizers/mask.py def anonymizer_name ( self ) -> str : \"\"\"Return anonymizer name.\"\"\" return \"mask\" validate ( self , params = None ) Validate the parameters for mask. Parameters: Name Type Description Default params Dict None Source code in presidio_anonymizer/anonymizers/mask.py def validate ( self , params : Dict = None ) -> None : \"\"\" Validate the parameters for mask. :param params: masking_char: The character to be masked with chars_to_mask: The amount of characters to mask from_end: Whether to mask the text from it's end \"\"\" masking_char = params . get ( self . MASKING_CHAR ) validate_parameter ( masking_char , self . MASKING_CHAR , str ) if len ( masking_char ) > 1 : raise InvalidParamException ( f \"Invalid input, { self . MASKING_CHAR } must be a character\" ) validate_parameter ( params . get ( self . CHARS_TO_MASK ), self . CHARS_TO_MASK , int ) validate_parameter ( params . get ( self . FROM_END ), self . FROM_END , bool ) redact Replaces the PII text entity with empty string. Redact Redact the string - empty value. anonymize ( self , text = None , params = None ) Returns: Type Description str an empty value. Source code in presidio_anonymizer/anonymizers/redact.py def anonymize ( self , text : str = None , params : Dict = None ) -> str : \"\"\":return: an empty value.\"\"\" return \"\" anonymizer_name ( self ) Return anonymizer name. Source code in presidio_anonymizer/anonymizers/redact.py def anonymizer_name ( self ) -> str : \"\"\"Return anonymizer name.\"\"\" return \"redact\" validate ( self , params = None ) Redact does not require any paramters so no validation is needed. Source code in presidio_anonymizer/anonymizers/redact.py def validate ( self , params : Dict = None ) -> None : \"\"\"Redact does not require any paramters so no validation is needed.\"\"\" pass replace Replaces the PII text entity with new string. Replace Receives new text to replace old PII text entity with. anonymize ( self , text = None , params = None ) Returns: Type Description str new_value. Source code in presidio_anonymizer/anonymizers/replace.py def anonymize ( self , text : str = None , params : Dict = None ) -> str : \"\"\":return: new_value.\"\"\" new_val = params . get ( self . NEW_VALUE ) if not new_val : return f \"< { params . get ( 'entity_type' ) } >\" return new_val anonymizer_name ( self ) Return anonymizer name. Source code in presidio_anonymizer/anonymizers/replace.py def anonymizer_name ( self ) -> str : \"\"\"Return anonymizer name.\"\"\" return \"replace\" validate ( self , params = None ) Validate the new value is string. Source code in presidio_anonymizer/anonymizers/replace.py def validate ( self , params : Dict = None ) -> None : \"\"\"Validate the new value is string.\"\"\" validate_type ( params . get ( self . NEW_VALUE ), self . NEW_VALUE , str ) pass validators Anomnymizers validations utility methods. validate_parameter ( parameter_value , parameter_name , parameter_type ) Validate an anonymizer parameter. Both validate the existence of an anonymizer parameter and that it is an instance of the parameter_type. Otherwise, raise the appropriate InvalidParamException with the parameter_name as content. Source code in presidio_anonymizer/anonymizers/validators.py def validate_parameter ( parameter_value , parameter_name : str , parameter_type : type ) -> None : \"\"\"Validate an anonymizer parameter. Both validate the existence of an anonymizer parameter and that it is an instance of the parameter_type. Otherwise, raise the appropriate InvalidParamException with the parameter_name as content. \"\"\" if parameter_value is None : raise InvalidParamException ( f \"Expected parameter { parameter_name } \" ) validate_type ( parameter_value , parameter_name , parameter_type ) validate_parameter_in_range ( values_range , parameter_value , parameter_name , parameter_type ) Validate an anonymizer parameter. validates the existence of an anonymizer parameter and that it is an instance of the parameter_type and that it is within the range of provided values. Otherwise, raise the appropriate InvalidParamException with the parameter_name as content. Source code in presidio_anonymizer/anonymizers/validators.py def validate_parameter_in_range ( values_range , parameter_value , parameter_name : str , parameter_type : type ) -> None : \"\"\"Validate an anonymizer parameter. validates the existence of an anonymizer parameter and that it is an instance of the parameter_type and that it is within the range of provided values. Otherwise, raise the appropriate InvalidParamException with the parameter_name as content. \"\"\" validate_parameter ( parameter_value , parameter_name , object ) if parameter_value not in values_range : raise InvalidParamException ( f \"Parameter { parameter_name } value { parameter_value } is not in \" f \"range of values { values_range } \" ) validate_type ( parameter_value , parameter_name , parameter_type ) Validate an anonymizer parameter. Validate it exists and if so, that it is the instance of the parameter_type. Otherwise, raise the appropriate InvalidParamException with the parameter_name as content. Source code in presidio_anonymizer/anonymizers/validators.py def validate_type ( parameter_value , parameter_name , parameter_type ): \"\"\" Validate an anonymizer parameter. Validate it exists and if so, that it is the instance of the parameter_type. Otherwise, raise the appropriate InvalidParamException with the parameter_name as content. \"\"\" if parameter_value and not isinstance ( parameter_value , parameter_type ): message = _get_bad_typed_parameter_error_message ( parameter_name , expected_type = parameter_type , actual_type = type ( parameter_value ), ) raise InvalidParamException ( message ) entities special Handles all the entities objects (structs) of the anonymizer. analyzer_result AnalyzerResult is the exact copy of the recognizer result. Represents the findings of detected entity. AnalyzerResult AnalyzerResult is the output of the analyze process. Validate and compare an recognizer result object. __eq__ ( self , other ) special Check two results are equal by using all class fields. Parameters: Name Type Description Default other another analyzer_result required Returns: Type Description bool Source code in presidio_anonymizer/entities/analyzer_result.py def __eq__ ( self , other ): \"\"\" Check two results are equal by using all class fields. :param other: another analyzer_result :return: bool \"\"\" equal_type = self . entity_type == other . entity_type equal_score = self . score is other . score return self . equal_indices ( other ) and equal_type and equal_score __gt__ ( self , other ) special Check if one result is greater by using the results indices in the text. Parameters: Name Type Description Default other another analyzer_result required Returns: Type Description bool Source code in presidio_anonymizer/entities/analyzer_result.py def __gt__ ( self , other ): \"\"\" Check if one result is greater by using the results indices in the text. :param other: another analyzer_result :return: bool \"\"\" if self . start == other . start : return self . end > other . end return self . start > other . start __hash__ ( self ) special Hash the result data by using all class fields. Returns: Type Description int Source code in presidio_anonymizer/entities/analyzer_result.py def __hash__ ( self ): \"\"\" Hash the result data by using all class fields. :return: int \"\"\" return hash ( f \" { str ( self . start ) } { str ( self . end ) } { str ( self . score ) } { self . entity_type } \" ) __str__ ( self ) special Analyzer_result class data to string. Source code in presidio_anonymizer/entities/analyzer_result.py def __str__ ( self ): \"\"\"Analyzer_result class data to string.\"\"\" return f \"start: { str ( self . start ) } , end: { str ( self . end ) } , \" \\ f \"score: { str ( self . score ) } , entity_type: { self . entity_type } \" contains ( self , other ) Check if one result is contained or equal to another result. Parameters: Name Type Description Default other another analyzer_result required Returns: Type Description bool Source code in presidio_anonymizer/entities/analyzer_result.py def contains ( self , other ): \"\"\" Check if one result is contained or equal to another result. :param other: another analyzer_result :return: bool \"\"\" return self . start <= other . start and self . end >= other . end equal_indices ( self , other ) Check if the indices are equal between two results. Parameters: Name Type Description Default other another analyzer_result required Returns: Type Description Source code in presidio_anonymizer/entities/analyzer_result.py def equal_indices ( self , other ): \"\"\" Check if the indices are equal between two results. :param other: another analyzer_result :return: \"\"\" return self . start == other . start and self . end == other . end from_json ( data ) classmethod Create AnalyzerResult from json. Parameters: Name Type Description Default data Dict e.g. { \"start\": 24, \"end\": 32, \"score\": 0.8, \"entity_type\": \"NAME\" } required Returns: Type Description AnalyzerResult Source code in presidio_anonymizer/entities/analyzer_result.py @classmethod def from_json ( cls , data : Dict ): \"\"\" Create AnalyzerResult from json. :param data: e.g. { \"start\": 24, \"end\": 32, \"score\": 0.8, \"entity_type\": \"NAME\" } :return: AnalyzerResult \"\"\" score = data . get ( \"score\" ) entity_type = data . get ( \"entity_type\" ) start = data . get ( \"start\" ) end = data . get ( \"end\" ) return cls ( entity_type , start , end , score ) has_conflict ( self , other ) Check if two analyzer results are conflicted or not. I have a conflict if: 1. My indices are the same as the other and my score is lower. 2. If my indices are contained in another. Parameters: Name Type Description Default other AnalyzerResult required Returns: Type Description Source code in presidio_anonymizer/entities/analyzer_result.py def has_conflict ( self , other ): \"\"\" Check if two analyzer results are conflicted or not. I have a conflict if: 1. My indices are the same as the other and my score is lower. 2. If my indices are contained in another. :param other: AnalyzerResult :return: \"\"\" if self . equal_indices ( other ): return self . score <= other . score return other . contains ( self ) analyzer_results A List of AnalyzerResult which sort the list using AnalyzerResult. gt . AnalyzerResults A class which provides operations over the analyzer result list.. It includes removal of unused results and sort by indices order. Additional information about the rational of this class: - One PII - uses a given or default anonymizer to anonymize and replace the PII text entity. - Full overlap of PIIs - When one text have several PIIs, the PII with the higher score will be taken. Between PIIs with similar scores, the selection will be arbitrary. - One PII is contained in another - anonymizer will use the PII with larger text. - Partial intersection - both will be returned concatenated. to_sorted_unique_results ( self , reverse = False ) Create a sorted list with unique results from the list. _remove_conflicts method - removes results which impact the same text and should be ignored. using the logic: - One PII - uses a given or default anonymizer to anonymize and replace the PII text entity. - Full overlap of PIIs - When one text have several PIIs, the PII with the higher score will be taken. Between PIIs with similar scores, the selection will be arbitrary. - One PII is contained in another - anonymizer will use the PII with larger text. - Partial intersection - both will be returned concatenated. sort - Use gt of AnalyzerResult to compare and sort Returns: Type Description List[presidio_anonymizer.entities.analyzer_result.AnalyzerResult] List Source code in presidio_anonymizer/entities/analyzer_results.py def to_sorted_unique_results ( self , reverse = False ) -> List [ AnalyzerResult ]: \"\"\" Create a sorted list with unique results from the list. _remove_conflicts method - removes results which impact the same text and should be ignored. using the logic: - One PII - uses a given or default anonymizer to anonymize and replace the PII text entity. - Full overlap of PIIs - When one text have several PIIs, the PII with the higher score will be taken. Between PIIs with similar scores, the selection will be arbitrary. - One PII is contained in another - anonymizer will use the PII with larger text. - Partial intersection - both will be returned concatenated. sort - Use __gt__ of AnalyzerResult to compare and sort :return: List \"\"\" self . logger . debug ( \"removing conflicts and sorting analyzer results list\" ) analyzer_results = self . _remove_conflicts () return sorted ( analyzer_results , reverse = reverse ) anonymized_text_builder Handles the original text and creates a new one according to changes requests. AnonymizedTextBuilder Creates new text according to users request. get_text_in_position ( self , start , end ) Get part of the text inside the original text. Parameters: Name Type Description Default start int start position of inner text required end int end position of inner text required Returns: Type Description str str - part of the original text Source code in presidio_anonymizer/entities/anonymized_text_builder.py def get_text_in_position ( self , start : int , end : int ) -> str : \"\"\" Get part of the text inside the original text. :param start: start position of inner text :param end: end position of inner text :return: str - part of the original text \"\"\" self . __validate_position_in_text ( start , end ) return self . output_text [ start : end ] replace_text ( self , anonymized_text , start , end ) Replace text in a specific position with the anonymized text. Parameters: Name Type Description Default anonymized_text str required start int the startpoint to replace the text required end int the endpoint to replace the text required Returns: Type Description Source code in presidio_anonymizer/entities/anonymized_text_builder.py def replace_text ( self , anonymized_text : str , start : int , end : int ): \"\"\" Replace text in a specific position with the anonymized text. :param anonymized_text: :param start: the startpoint to replace the text :param end: the endpoint to replace the text :return: \"\"\" end_of_text = min ( end , self . last_replacement_point ) self . last_replacement_point = start self . output_text = self . output_text [ : start ] + anonymized_text + self . output_text [ end_of_text :] anonymizer_config Handle the anonymizers data - anonymizer class and params. AnonymizerConfig Handle the anonymizers data - anonymizer class and params. __eq__ ( self , other ) special Verify two AnonymizerConfig are equal. Source code in presidio_anonymizer/entities/anonymizer_config.py def __eq__ ( self , other ): \"\"\"Verify two AnonymizerConfig are equal.\"\"\" anonymizer_class_equals = self . anonymizer_class == other . anonymizer_class return self . params == other . params and anonymizer_class_equals __init__ ( self , anonymizer_name , params = None ) special Create AnonymizerConfig entity. Parameters: Name Type Description Default anonymizer_name str the anonymizer name string - represents the class of the anonymizer in lower case letters. e.g.: redact required params Dict the parameters to use in the selected anonymizer class None Source code in presidio_anonymizer/entities/anonymizer_config.py def __init__ ( self , anonymizer_name : str , params : Dict = None ): \"\"\" Create AnonymizerConfig entity. :param anonymizer_name: the anonymizer name string - represents the class of the anonymizer in lower case letters. e.g.: redact :param params: the parameters to use in the selected anonymizer class \"\"\" self . logger = logging . getLogger ( \"presidio-anonymizer\" ) self . anonymizer_class = self . __get_anonymizer_class ( anonymizer_name ) self . params = params if not params : self . params = {} from_json ( params ) classmethod Create AnonymizerConfig from json. Parameters: Name Type Description Default params dict json e.g.: { \"type\": \"mask\", \"masking_char\": \"*\", \"chars_to_mask\": 4, \"from_end\": true } required Returns: Type Description AnonymizerConfig Source code in presidio_anonymizer/entities/anonymizer_config.py @classmethod def from_json ( cls , params : dict ): \"\"\" Create AnonymizerConfig from json. :param params: json e.g.: { \"type\": \"mask\", \"masking_char\": \"*\", \"chars_to_mask\": 4, \"from_end\": true } :return: AnonymizerConfig \"\"\" anonymizer_name = params . get ( \"type\" ) if anonymizer_name : params . pop ( \"type\" ) return cls ( anonymizer_name , params ) anonymizer_request Engine request entity. It get the data and validate it before the engine receives it. AnonymizerRequest Input validation for the anonymize process. get_anonymizer_configs_from_json ( data ) classmethod Go over the anonymizers and get the relevant anonymizer class for it. Inserts the class to the anonymizer so the engine will use it. Parameters: Name Type Description Default data Dict contains the text, configuration and analyzer_results value - AnonynmizerConfig required Source code in presidio_anonymizer/entities/anonymizer_request.py @classmethod def get_anonymizer_configs_from_json ( cls , data : Dict ) -> \\ Dict [ str , AnonymizerConfig ]: \"\"\" Go over the anonymizers and get the relevant anonymizer class for it. Inserts the class to the anonymizer so the engine will use it. :param data: contains the text, configuration and analyzer_results value - AnonynmizerConfig \"\"\" anonymizers_config = {} anonymizers = data . get ( \"anonymizers\" ) if anonymizers is not None : for key , anonymizer_json in anonymizers . items (): cls . logger . debug ( f \"converting { anonymizer_json } to anonymizer config class\" ) anonymizer_config = AnonymizerConfig . from_json ( anonymizer_json ) anonymizers_config [ key ] = anonymizer_config return anonymizers_config handle_analyzer_results_json ( data ) classmethod Go over analyzer results, validate them and convert to List[AnalyzeResult]. Parameters: Name Type Description Default data Dict contains the anonymizers and analyzer_results_json required Source code in presidio_anonymizer/entities/anonymizer_request.py @classmethod def handle_analyzer_results_json ( cls , data : Dict ) -> List [ AnalyzerResult ]: \"\"\" Go over analyzer results, validate them and convert to List[AnalyzeResult]. :param data: contains the anonymizers and analyzer_results_json \"\"\" analyzer_results = AnalyzerResults () analyzer_results_json = data . get ( \"analyzer_results\" ) if not analyzer_results_json : cls . logger . debug ( \"invalid input, json missing field: analyzer_results_json\" ) raise InvalidParamException ( \"Invalid input, \" \"analyzer results can not be empty\" ) for analyzer_result in analyzer_results_json : analyzer_result = AnalyzerResult . from_json ( analyzer_result ) analyzer_results . append ( analyzer_result ) return analyzer_results error_response Handle a serializable error response. ErrorResponse Error Response. Parameters: Name Type Description Default msg the error message to return required to_json ( self ) Return a json string serializing this instance. Source code in presidio_anonymizer/entities/error_response.py def to_json ( self ) -> str : \"\"\"Return a json string serializing this instance.\"\"\" return json . dumps ( self , default = lambda x : x . __dict__ ) invalid_exception Exception to indicate the request we received is invalid. InvalidParamException Throw exception with error when user input is not valid.","title":"Presidio Anonymizer Python API"},{"location":"api/anonymizer_python/#presidio-anonymizer-api-reference","text":"Anonymizer root module.","title":"Presidio Anonymizer API Reference"},{"location":"api/anonymizer_python/#presidio_anonymizer.anonymizer_engine","text":"Handles the entire logic of the Presidio-anonymizer and text anonymizing.","title":"anonymizer_engine"},{"location":"api/anonymizer_python/#presidio_anonymizer.anonymizer_engine.AnonymizerEngine","text":"AnonymizerEngine class. Handles the entire logic of the Presidio-anonymizer. Gets the original text and replaces the PII entities with the desired anonymizers.","title":"AnonymizerEngine"},{"location":"api/anonymizer_python/#presidio_anonymizer.anonymizer_engine.AnonymizerEngine.anonymize","text":"Anonymize method to anonymize the given text. Parameters: Name Type Description Default text str the text we are anonymizing required analyzer_results List[presidio_anonymizer.entities.analyzer_result.AnalyzerResult] A list of AnalyzerResult class -> The results we received from the analyzer required anonymizers_config Optional[Dict[str, presidio_anonymizer.entities.anonymizer_config.AnonymizerConfig]] The configuration of the anonymizers we would like to use for each entity e.g.: {\"PHONE_NUMBER\":AnonymizerConfig(\"redact\", {})} received from the analyzer None Returns: Type Description str the anonymized text Source code in presidio_anonymizer/anonymizer_engine.py def anonymize ( self , text : str , analyzer_results : List [ AnalyzerResult ], anonymizers_config : Optional [ Dict [ str , AnonymizerConfig ]] = None ) -> str : \"\"\"Anonymize method to anonymize the given text. :param text: the text we are anonymizing :param analyzer_results: A list of AnalyzerResult class -> The results we received from the analyzer :param anonymizers_config: The configuration of the anonymizers we would like to use for each entity e.g.: {\"PHONE_NUMBER\":AnonymizerConfig(\"redact\", {})} received from the analyzer :return: the anonymized text \"\"\" text_builder = AnonymizedTextBuilder ( original_text = text ) if not anonymizers_config : anonymizers_config = {} analyzer_results = ( AnalyzerResults ( analyzer_results ) . to_sorted_unique_results ( True ) ) # loop over each analyzer result # get AnonymizerConfig for the analyzer result # trigger the anonymize method on the section of the text # perform the anonymization # concat the anonymized string into the output string for analyzer_result in analyzer_results : text_to_anonymize = text_builder . get_text_in_position ( analyzer_result . start , analyzer_result . end ) anonymizer_config = self . __get_anonymizer_config_by_entity_type ( analyzer_result . entity_type , anonymizers_config ) self . logger . debug ( f \"for analyzer result { analyzer_result } received config \" f \" { anonymizer_config } \" ) anonymized_text = self . __extract_anonymizer_and_anonymize ( analyzer_result . entity_type , anonymizer_config , text_to_anonymize ) text_builder . replace_text ( anonymized_text , analyzer_result . start , analyzer_result . end ) return text_builder . output_text","title":"anonymize()"},{"location":"api/anonymizer_python/#presidio_anonymizer.anonymizer_engine.AnonymizerEngine.get_anonymizers","text":"Return a list of supported anonymizers. Source code in presidio_anonymizer/anonymizer_engine.py @staticmethod def get_anonymizers () -> List [ str ]: \"\"\"Return a list of supported anonymizers.\"\"\" names = [ p for p in Anonymizer . get_anonymizers () . keys ()] return names","title":"get_anonymizers()"},{"location":"api/anonymizer_python/#presidio_anonymizer.anonymizers","text":"Initializing all the existing anonymizers.","title":"anonymizers"},{"location":"api/anonymizer_python/#presidio_anonymizer.anonymizers.anonymizer","text":"Anonymizers abstraction - each anonymizer should implement this class.","title":"anonymizer"},{"location":"api/anonymizer_python/#presidio_anonymizer.anonymizers.anonymizer.Anonymizer","text":"Anonymizer abstract class to be implemented by each anonymizer.","title":"Anonymizer"},{"location":"api/anonymizer_python/#presidio_anonymizer.anonymizers.anonymizer.Anonymizer.anonymize","text":"Anonymize method to be implemented in each anonymizer. Source code in presidio_anonymizer/anonymizers/anonymizer.py @abstractmethod def anonymize ( self , text : str , params : Dict = None ) -> str : \"\"\"Anonymize method to be implemented in each anonymizer.\"\"\" pass","title":"anonymize()"},{"location":"api/anonymizer_python/#presidio_anonymizer.anonymizers.anonymizer.Anonymizer.anonymizer_name","text":"Return anonymizer name. Source code in presidio_anonymizer/anonymizers/anonymizer.py @abstractmethod def anonymizer_name ( self ) -> str : \"\"\"Return anonymizer name.\"\"\" pass","title":"anonymizer_name()"},{"location":"api/anonymizer_python/#presidio_anonymizer.anonymizers.anonymizer.Anonymizer.get_anonymizers","text":"Return all anonymizers classes currently available. Source code in presidio_anonymizer/anonymizers/anonymizer.py @staticmethod def get_anonymizers () -> Dict [ str , 'Anonymizer' ]: \"\"\"Return all anonymizers classes currently available.\"\"\" if not Anonymizer . _anonymizers : Anonymizer . _anonymizers = { cls . anonymizer_name ( cls ): cls for cls in Anonymizer . __subclasses__ () } return Anonymizer . _anonymizers","title":"get_anonymizers()"},{"location":"api/anonymizer_python/#presidio_anonymizer.anonymizers.anonymizer.Anonymizer.validate","text":"Validate each anonymizer parameters. Source code in presidio_anonymizer/anonymizers/anonymizer.py @abstractmethod def validate ( self , params : Dict = None ) -> None : \"\"\"Validate each anonymizer parameters.\"\"\" pass","title":"validate()"},{"location":"api/anonymizer_python/#presidio_anonymizer.anonymizers.hash","text":"Hashes the PII text entity.","title":"hash"},{"location":"api/anonymizer_python/#presidio_anonymizer.anonymizers.hash.Hash","text":"Hash given text with sha256/sha512/md5 algorithm.","title":"Hash"},{"location":"api/anonymizer_python/#presidio_anonymizer.anonymizers.hash.Hash.anonymize","text":"Hash given value using sha256. Returns: Type Description str hashed original text Source code in presidio_anonymizer/anonymizers/hash.py def anonymize ( self , text : str = None , params : Dict = None ) -> str : \"\"\" Hash given value using sha256. :return: hashed original text \"\"\" hash_type = self . _get_hash_type_or_default ( params ) hash_switcher = { self . SHA256 : lambda s : sha256 ( s ), self . SHA512 : lambda s : sha512 ( s ), self . MD5 : lambda s : md5 ( s ), } return hash_switcher . get ( hash_type )( text . encode ()) . hexdigest ()","title":"anonymize()"},{"location":"api/anonymizer_python/#presidio_anonymizer.anonymizers.hash.Hash.anonymizer_name","text":"Return anonymizer name. Source code in presidio_anonymizer/anonymizers/hash.py def anonymizer_name ( self ) -> str : \"\"\"Return anonymizer name.\"\"\" return \"hash\"","title":"anonymizer_name()"},{"location":"api/anonymizer_python/#presidio_anonymizer.anonymizers.hash.Hash.validate","text":"Validate the hash type is string and in range of allowed hash types. Source code in presidio_anonymizer/anonymizers/hash.py def validate ( self , params : Dict = None ) -> None : \"\"\"Validate the hash type is string and in range of allowed hash types.\"\"\" validate_parameter_in_range ( [ self . SHA256 , self . SHA512 , self . MD5 ], self . _get_hash_type_or_default ( params ), self . HASH_TYPE , str , ) pass","title":"validate()"},{"location":"api/anonymizer_python/#presidio_anonymizer.anonymizers.mask","text":"Mask some or all given text entity PII with given character.","title":"mask"},{"location":"api/anonymizer_python/#presidio_anonymizer.anonymizers.mask.Mask","text":"Mask the given text with given value.","title":"Mask"},{"location":"api/anonymizer_python/#presidio_anonymizer.anonymizers.mask.Mask.anonymize","text":"Mask a given amount of text with a given character. Parameters: Name Type Description Default text str the text to be masked None params Dict None Returns: Type Description str the masked text Source code in presidio_anonymizer/anonymizers/mask.py def anonymize ( self , text : str = None , params : Dict = None ) -> str : \"\"\" Mask a given amount of text with a given character. :param text: the text to be masked :param params: masking_char: The character to be masked with chars_to_mask: The amount of characters to mask from_end: Whether to mask the text from it's end :return: the masked text \"\"\" effective_chars_to_mask = self . _get_effective_chars_to_mask ( text , params . get ( self . CHARS_TO_MASK ) ) from_end = params . get ( self . FROM_END ) masking_char = params . get ( self . MASKING_CHAR ) return self . _get_anonymized_text ( text , effective_chars_to_mask , from_end , masking_char )","title":"anonymize()"},{"location":"api/anonymizer_python/#presidio_anonymizer.anonymizers.mask.Mask.anonymizer_name","text":"Return anonymizer name. Source code in presidio_anonymizer/anonymizers/mask.py def anonymizer_name ( self ) -> str : \"\"\"Return anonymizer name.\"\"\" return \"mask\"","title":"anonymizer_name()"},{"location":"api/anonymizer_python/#presidio_anonymizer.anonymizers.mask.Mask.validate","text":"Validate the parameters for mask. Parameters: Name Type Description Default params Dict None Source code in presidio_anonymizer/anonymizers/mask.py def validate ( self , params : Dict = None ) -> None : \"\"\" Validate the parameters for mask. :param params: masking_char: The character to be masked with chars_to_mask: The amount of characters to mask from_end: Whether to mask the text from it's end \"\"\" masking_char = params . get ( self . MASKING_CHAR ) validate_parameter ( masking_char , self . MASKING_CHAR , str ) if len ( masking_char ) > 1 : raise InvalidParamException ( f \"Invalid input, { self . MASKING_CHAR } must be a character\" ) validate_parameter ( params . get ( self . CHARS_TO_MASK ), self . CHARS_TO_MASK , int ) validate_parameter ( params . get ( self . FROM_END ), self . FROM_END , bool )","title":"validate()"},{"location":"api/anonymizer_python/#presidio_anonymizer.anonymizers.redact","text":"Replaces the PII text entity with empty string.","title":"redact"},{"location":"api/anonymizer_python/#presidio_anonymizer.anonymizers.redact.Redact","text":"Redact the string - empty value.","title":"Redact"},{"location":"api/anonymizer_python/#presidio_anonymizer.anonymizers.redact.Redact.anonymize","text":"Returns: Type Description str an empty value. Source code in presidio_anonymizer/anonymizers/redact.py def anonymize ( self , text : str = None , params : Dict = None ) -> str : \"\"\":return: an empty value.\"\"\" return \"\"","title":"anonymize()"},{"location":"api/anonymizer_python/#presidio_anonymizer.anonymizers.redact.Redact.anonymizer_name","text":"Return anonymizer name. Source code in presidio_anonymizer/anonymizers/redact.py def anonymizer_name ( self ) -> str : \"\"\"Return anonymizer name.\"\"\" return \"redact\"","title":"anonymizer_name()"},{"location":"api/anonymizer_python/#presidio_anonymizer.anonymizers.redact.Redact.validate","text":"Redact does not require any paramters so no validation is needed. Source code in presidio_anonymizer/anonymizers/redact.py def validate ( self , params : Dict = None ) -> None : \"\"\"Redact does not require any paramters so no validation is needed.\"\"\" pass","title":"validate()"},{"location":"api/anonymizer_python/#presidio_anonymizer.anonymizers.replace","text":"Replaces the PII text entity with new string.","title":"replace"},{"location":"api/anonymizer_python/#presidio_anonymizer.anonymizers.replace.Replace","text":"Receives new text to replace old PII text entity with.","title":"Replace"},{"location":"api/anonymizer_python/#presidio_anonymizer.anonymizers.replace.Replace.anonymize","text":"Returns: Type Description str new_value. Source code in presidio_anonymizer/anonymizers/replace.py def anonymize ( self , text : str = None , params : Dict = None ) -> str : \"\"\":return: new_value.\"\"\" new_val = params . get ( self . NEW_VALUE ) if not new_val : return f \"< { params . get ( 'entity_type' ) } >\" return new_val","title":"anonymize()"},{"location":"api/anonymizer_python/#presidio_anonymizer.anonymizers.replace.Replace.anonymizer_name","text":"Return anonymizer name. Source code in presidio_anonymizer/anonymizers/replace.py def anonymizer_name ( self ) -> str : \"\"\"Return anonymizer name.\"\"\" return \"replace\"","title":"anonymizer_name()"},{"location":"api/anonymizer_python/#presidio_anonymizer.anonymizers.replace.Replace.validate","text":"Validate the new value is string. Source code in presidio_anonymizer/anonymizers/replace.py def validate ( self , params : Dict = None ) -> None : \"\"\"Validate the new value is string.\"\"\" validate_type ( params . get ( self . NEW_VALUE ), self . NEW_VALUE , str ) pass","title":"validate()"},{"location":"api/anonymizer_python/#presidio_anonymizer.anonymizers.validators","text":"Anomnymizers validations utility methods.","title":"validators"},{"location":"api/anonymizer_python/#presidio_anonymizer.anonymizers.validators.validate_parameter","text":"Validate an anonymizer parameter. Both validate the existence of an anonymizer parameter and that it is an instance of the parameter_type. Otherwise, raise the appropriate InvalidParamException with the parameter_name as content. Source code in presidio_anonymizer/anonymizers/validators.py def validate_parameter ( parameter_value , parameter_name : str , parameter_type : type ) -> None : \"\"\"Validate an anonymizer parameter. Both validate the existence of an anonymizer parameter and that it is an instance of the parameter_type. Otherwise, raise the appropriate InvalidParamException with the parameter_name as content. \"\"\" if parameter_value is None : raise InvalidParamException ( f \"Expected parameter { parameter_name } \" ) validate_type ( parameter_value , parameter_name , parameter_type )","title":"validate_parameter()"},{"location":"api/anonymizer_python/#presidio_anonymizer.anonymizers.validators.validate_parameter_in_range","text":"Validate an anonymizer parameter. validates the existence of an anonymizer parameter and that it is an instance of the parameter_type and that it is within the range of provided values. Otherwise, raise the appropriate InvalidParamException with the parameter_name as content. Source code in presidio_anonymizer/anonymizers/validators.py def validate_parameter_in_range ( values_range , parameter_value , parameter_name : str , parameter_type : type ) -> None : \"\"\"Validate an anonymizer parameter. validates the existence of an anonymizer parameter and that it is an instance of the parameter_type and that it is within the range of provided values. Otherwise, raise the appropriate InvalidParamException with the parameter_name as content. \"\"\" validate_parameter ( parameter_value , parameter_name , object ) if parameter_value not in values_range : raise InvalidParamException ( f \"Parameter { parameter_name } value { parameter_value } is not in \" f \"range of values { values_range } \" )","title":"validate_parameter_in_range()"},{"location":"api/anonymizer_python/#presidio_anonymizer.anonymizers.validators.validate_type","text":"Validate an anonymizer parameter. Validate it exists and if so, that it is the instance of the parameter_type. Otherwise, raise the appropriate InvalidParamException with the parameter_name as content. Source code in presidio_anonymizer/anonymizers/validators.py def validate_type ( parameter_value , parameter_name , parameter_type ): \"\"\" Validate an anonymizer parameter. Validate it exists and if so, that it is the instance of the parameter_type. Otherwise, raise the appropriate InvalidParamException with the parameter_name as content. \"\"\" if parameter_value and not isinstance ( parameter_value , parameter_type ): message = _get_bad_typed_parameter_error_message ( parameter_name , expected_type = parameter_type , actual_type = type ( parameter_value ), ) raise InvalidParamException ( message )","title":"validate_type()"},{"location":"api/anonymizer_python/#presidio_anonymizer.entities","text":"Handles all the entities objects (structs) of the anonymizer.","title":"entities"},{"location":"api/anonymizer_python/#presidio_anonymizer.entities.analyzer_result","text":"AnalyzerResult is the exact copy of the recognizer result. Represents the findings of detected entity.","title":"analyzer_result"},{"location":"api/anonymizer_python/#presidio_anonymizer.entities.analyzer_result.AnalyzerResult","text":"AnalyzerResult is the output of the analyze process. Validate and compare an recognizer result object.","title":"AnalyzerResult"},{"location":"api/anonymizer_python/#presidio_anonymizer.entities.analyzer_result.AnalyzerResult.__eq__","text":"Check two results are equal by using all class fields. Parameters: Name Type Description Default other another analyzer_result required Returns: Type Description bool Source code in presidio_anonymizer/entities/analyzer_result.py def __eq__ ( self , other ): \"\"\" Check two results are equal by using all class fields. :param other: another analyzer_result :return: bool \"\"\" equal_type = self . entity_type == other . entity_type equal_score = self . score is other . score return self . equal_indices ( other ) and equal_type and equal_score","title":"__eq__()"},{"location":"api/anonymizer_python/#presidio_anonymizer.entities.analyzer_result.AnalyzerResult.__gt__","text":"Check if one result is greater by using the results indices in the text. Parameters: Name Type Description Default other another analyzer_result required Returns: Type Description bool Source code in presidio_anonymizer/entities/analyzer_result.py def __gt__ ( self , other ): \"\"\" Check if one result is greater by using the results indices in the text. :param other: another analyzer_result :return: bool \"\"\" if self . start == other . start : return self . end > other . end return self . start > other . start","title":"__gt__()"},{"location":"api/anonymizer_python/#presidio_anonymizer.entities.analyzer_result.AnalyzerResult.__hash__","text":"Hash the result data by using all class fields. Returns: Type Description int Source code in presidio_anonymizer/entities/analyzer_result.py def __hash__ ( self ): \"\"\" Hash the result data by using all class fields. :return: int \"\"\" return hash ( f \" { str ( self . start ) } { str ( self . end ) } { str ( self . score ) } { self . entity_type } \" )","title":"__hash__()"},{"location":"api/anonymizer_python/#presidio_anonymizer.entities.analyzer_result.AnalyzerResult.__str__","text":"Analyzer_result class data to string. Source code in presidio_anonymizer/entities/analyzer_result.py def __str__ ( self ): \"\"\"Analyzer_result class data to string.\"\"\" return f \"start: { str ( self . start ) } , end: { str ( self . end ) } , \" \\ f \"score: { str ( self . score ) } , entity_type: { self . entity_type } \"","title":"__str__()"},{"location":"api/anonymizer_python/#presidio_anonymizer.entities.analyzer_result.AnalyzerResult.contains","text":"Check if one result is contained or equal to another result. Parameters: Name Type Description Default other another analyzer_result required Returns: Type Description bool Source code in presidio_anonymizer/entities/analyzer_result.py def contains ( self , other ): \"\"\" Check if one result is contained or equal to another result. :param other: another analyzer_result :return: bool \"\"\" return self . start <= other . start and self . end >= other . end","title":"contains()"},{"location":"api/anonymizer_python/#presidio_anonymizer.entities.analyzer_result.AnalyzerResult.equal_indices","text":"Check if the indices are equal between two results. Parameters: Name Type Description Default other another analyzer_result required Returns: Type Description Source code in presidio_anonymizer/entities/analyzer_result.py def equal_indices ( self , other ): \"\"\" Check if the indices are equal between two results. :param other: another analyzer_result :return: \"\"\" return self . start == other . start and self . end == other . end","title":"equal_indices()"},{"location":"api/anonymizer_python/#presidio_anonymizer.entities.analyzer_result.AnalyzerResult.from_json","text":"Create AnalyzerResult from json. Parameters: Name Type Description Default data Dict e.g. { \"start\": 24, \"end\": 32, \"score\": 0.8, \"entity_type\": \"NAME\" } required Returns: Type Description AnalyzerResult Source code in presidio_anonymizer/entities/analyzer_result.py @classmethod def from_json ( cls , data : Dict ): \"\"\" Create AnalyzerResult from json. :param data: e.g. { \"start\": 24, \"end\": 32, \"score\": 0.8, \"entity_type\": \"NAME\" } :return: AnalyzerResult \"\"\" score = data . get ( \"score\" ) entity_type = data . get ( \"entity_type\" ) start = data . get ( \"start\" ) end = data . get ( \"end\" ) return cls ( entity_type , start , end , score )","title":"from_json()"},{"location":"api/anonymizer_python/#presidio_anonymizer.entities.analyzer_result.AnalyzerResult.has_conflict","text":"Check if two analyzer results are conflicted or not. I have a conflict if: 1. My indices are the same as the other and my score is lower. 2. If my indices are contained in another. Parameters: Name Type Description Default other AnalyzerResult required Returns: Type Description Source code in presidio_anonymizer/entities/analyzer_result.py def has_conflict ( self , other ): \"\"\" Check if two analyzer results are conflicted or not. I have a conflict if: 1. My indices are the same as the other and my score is lower. 2. If my indices are contained in another. :param other: AnalyzerResult :return: \"\"\" if self . equal_indices ( other ): return self . score <= other . score return other . contains ( self )","title":"has_conflict()"},{"location":"api/anonymizer_python/#presidio_anonymizer.entities.analyzer_results","text":"A List of AnalyzerResult which sort the list using AnalyzerResult. gt .","title":"analyzer_results"},{"location":"api/anonymizer_python/#presidio_anonymizer.entities.analyzer_results.AnalyzerResults","text":"A class which provides operations over the analyzer result list.. It includes removal of unused results and sort by indices order. Additional information about the rational of this class: - One PII - uses a given or default anonymizer to anonymize and replace the PII text entity. - Full overlap of PIIs - When one text have several PIIs, the PII with the higher score will be taken. Between PIIs with similar scores, the selection will be arbitrary. - One PII is contained in another - anonymizer will use the PII with larger text. - Partial intersection - both will be returned concatenated.","title":"AnalyzerResults"},{"location":"api/anonymizer_python/#presidio_anonymizer.entities.analyzer_results.AnalyzerResults.to_sorted_unique_results","text":"Create a sorted list with unique results from the list. _remove_conflicts method - removes results which impact the same text and should be ignored. using the logic: - One PII - uses a given or default anonymizer to anonymize and replace the PII text entity. - Full overlap of PIIs - When one text have several PIIs, the PII with the higher score will be taken. Between PIIs with similar scores, the selection will be arbitrary. - One PII is contained in another - anonymizer will use the PII with larger text. - Partial intersection - both will be returned concatenated. sort - Use gt of AnalyzerResult to compare and sort Returns: Type Description List[presidio_anonymizer.entities.analyzer_result.AnalyzerResult] List Source code in presidio_anonymizer/entities/analyzer_results.py def to_sorted_unique_results ( self , reverse = False ) -> List [ AnalyzerResult ]: \"\"\" Create a sorted list with unique results from the list. _remove_conflicts method - removes results which impact the same text and should be ignored. using the logic: - One PII - uses a given or default anonymizer to anonymize and replace the PII text entity. - Full overlap of PIIs - When one text have several PIIs, the PII with the higher score will be taken. Between PIIs with similar scores, the selection will be arbitrary. - One PII is contained in another - anonymizer will use the PII with larger text. - Partial intersection - both will be returned concatenated. sort - Use __gt__ of AnalyzerResult to compare and sort :return: List \"\"\" self . logger . debug ( \"removing conflicts and sorting analyzer results list\" ) analyzer_results = self . _remove_conflicts () return sorted ( analyzer_results , reverse = reverse )","title":"to_sorted_unique_results()"},{"location":"api/anonymizer_python/#presidio_anonymizer.entities.anonymized_text_builder","text":"Handles the original text and creates a new one according to changes requests.","title":"anonymized_text_builder"},{"location":"api/anonymizer_python/#presidio_anonymizer.entities.anonymized_text_builder.AnonymizedTextBuilder","text":"Creates new text according to users request.","title":"AnonymizedTextBuilder"},{"location":"api/anonymizer_python/#presidio_anonymizer.entities.anonymized_text_builder.AnonymizedTextBuilder.get_text_in_position","text":"Get part of the text inside the original text. Parameters: Name Type Description Default start int start position of inner text required end int end position of inner text required Returns: Type Description str str - part of the original text Source code in presidio_anonymizer/entities/anonymized_text_builder.py def get_text_in_position ( self , start : int , end : int ) -> str : \"\"\" Get part of the text inside the original text. :param start: start position of inner text :param end: end position of inner text :return: str - part of the original text \"\"\" self . __validate_position_in_text ( start , end ) return self . output_text [ start : end ]","title":"get_text_in_position()"},{"location":"api/anonymizer_python/#presidio_anonymizer.entities.anonymized_text_builder.AnonymizedTextBuilder.replace_text","text":"Replace text in a specific position with the anonymized text. Parameters: Name Type Description Default anonymized_text str required start int the startpoint to replace the text required end int the endpoint to replace the text required Returns: Type Description Source code in presidio_anonymizer/entities/anonymized_text_builder.py def replace_text ( self , anonymized_text : str , start : int , end : int ): \"\"\" Replace text in a specific position with the anonymized text. :param anonymized_text: :param start: the startpoint to replace the text :param end: the endpoint to replace the text :return: \"\"\" end_of_text = min ( end , self . last_replacement_point ) self . last_replacement_point = start self . output_text = self . output_text [ : start ] + anonymized_text + self . output_text [ end_of_text :]","title":"replace_text()"},{"location":"api/anonymizer_python/#presidio_anonymizer.entities.anonymizer_config","text":"Handle the anonymizers data - anonymizer class and params.","title":"anonymizer_config"},{"location":"api/anonymizer_python/#presidio_anonymizer.entities.anonymizer_config.AnonymizerConfig","text":"Handle the anonymizers data - anonymizer class and params.","title":"AnonymizerConfig"},{"location":"api/anonymizer_python/#presidio_anonymizer.entities.anonymizer_config.AnonymizerConfig.__eq__","text":"Verify two AnonymizerConfig are equal. Source code in presidio_anonymizer/entities/anonymizer_config.py def __eq__ ( self , other ): \"\"\"Verify two AnonymizerConfig are equal.\"\"\" anonymizer_class_equals = self . anonymizer_class == other . anonymizer_class return self . params == other . params and anonymizer_class_equals","title":"__eq__()"},{"location":"api/anonymizer_python/#presidio_anonymizer.entities.anonymizer_config.AnonymizerConfig.__init__","text":"Create AnonymizerConfig entity. Parameters: Name Type Description Default anonymizer_name str the anonymizer name string - represents the class of the anonymizer in lower case letters. e.g.: redact required params Dict the parameters to use in the selected anonymizer class None Source code in presidio_anonymizer/entities/anonymizer_config.py def __init__ ( self , anonymizer_name : str , params : Dict = None ): \"\"\" Create AnonymizerConfig entity. :param anonymizer_name: the anonymizer name string - represents the class of the anonymizer in lower case letters. e.g.: redact :param params: the parameters to use in the selected anonymizer class \"\"\" self . logger = logging . getLogger ( \"presidio-anonymizer\" ) self . anonymizer_class = self . __get_anonymizer_class ( anonymizer_name ) self . params = params if not params : self . params = {}","title":"__init__()"},{"location":"api/anonymizer_python/#presidio_anonymizer.entities.anonymizer_config.AnonymizerConfig.from_json","text":"Create AnonymizerConfig from json. Parameters: Name Type Description Default params dict json e.g.: { \"type\": \"mask\", \"masking_char\": \"*\", \"chars_to_mask\": 4, \"from_end\": true } required Returns: Type Description AnonymizerConfig Source code in presidio_anonymizer/entities/anonymizer_config.py @classmethod def from_json ( cls , params : dict ): \"\"\" Create AnonymizerConfig from json. :param params: json e.g.: { \"type\": \"mask\", \"masking_char\": \"*\", \"chars_to_mask\": 4, \"from_end\": true } :return: AnonymizerConfig \"\"\" anonymizer_name = params . get ( \"type\" ) if anonymizer_name : params . pop ( \"type\" ) return cls ( anonymizer_name , params )","title":"from_json()"},{"location":"api/anonymizer_python/#presidio_anonymizer.entities.anonymizer_request","text":"Engine request entity. It get the data and validate it before the engine receives it.","title":"anonymizer_request"},{"location":"api/anonymizer_python/#presidio_anonymizer.entities.anonymizer_request.AnonymizerRequest","text":"Input validation for the anonymize process.","title":"AnonymizerRequest"},{"location":"api/anonymizer_python/#presidio_anonymizer.entities.anonymizer_request.AnonymizerRequest.get_anonymizer_configs_from_json","text":"Go over the anonymizers and get the relevant anonymizer class for it. Inserts the class to the anonymizer so the engine will use it. Parameters: Name Type Description Default data Dict contains the text, configuration and analyzer_results value - AnonynmizerConfig required Source code in presidio_anonymizer/entities/anonymizer_request.py @classmethod def get_anonymizer_configs_from_json ( cls , data : Dict ) -> \\ Dict [ str , AnonymizerConfig ]: \"\"\" Go over the anonymizers and get the relevant anonymizer class for it. Inserts the class to the anonymizer so the engine will use it. :param data: contains the text, configuration and analyzer_results value - AnonynmizerConfig \"\"\" anonymizers_config = {} anonymizers = data . get ( \"anonymizers\" ) if anonymizers is not None : for key , anonymizer_json in anonymizers . items (): cls . logger . debug ( f \"converting { anonymizer_json } to anonymizer config class\" ) anonymizer_config = AnonymizerConfig . from_json ( anonymizer_json ) anonymizers_config [ key ] = anonymizer_config return anonymizers_config","title":"get_anonymizer_configs_from_json()"},{"location":"api/anonymizer_python/#presidio_anonymizer.entities.anonymizer_request.AnonymizerRequest.handle_analyzer_results_json","text":"Go over analyzer results, validate them and convert to List[AnalyzeResult]. Parameters: Name Type Description Default data Dict contains the anonymizers and analyzer_results_json required Source code in presidio_anonymizer/entities/anonymizer_request.py @classmethod def handle_analyzer_results_json ( cls , data : Dict ) -> List [ AnalyzerResult ]: \"\"\" Go over analyzer results, validate them and convert to List[AnalyzeResult]. :param data: contains the anonymizers and analyzer_results_json \"\"\" analyzer_results = AnalyzerResults () analyzer_results_json = data . get ( \"analyzer_results\" ) if not analyzer_results_json : cls . logger . debug ( \"invalid input, json missing field: analyzer_results_json\" ) raise InvalidParamException ( \"Invalid input, \" \"analyzer results can not be empty\" ) for analyzer_result in analyzer_results_json : analyzer_result = AnalyzerResult . from_json ( analyzer_result ) analyzer_results . append ( analyzer_result ) return analyzer_results","title":"handle_analyzer_results_json()"},{"location":"api/anonymizer_python/#presidio_anonymizer.entities.error_response","text":"Handle a serializable error response.","title":"error_response"},{"location":"api/anonymizer_python/#presidio_anonymizer.entities.error_response.ErrorResponse","text":"Error Response. Parameters: Name Type Description Default msg the error message to return required","title":"ErrorResponse"},{"location":"api/anonymizer_python/#presidio_anonymizer.entities.error_response.ErrorResponse.to_json","text":"Return a json string serializing this instance. Source code in presidio_anonymizer/entities/error_response.py def to_json ( self ) -> str : \"\"\"Return a json string serializing this instance.\"\"\" return json . dumps ( self , default = lambda x : x . __dict__ )","title":"to_json()"},{"location":"api/anonymizer_python/#presidio_anonymizer.entities.invalid_exception","text":"Exception to indicate the request we received is invalid.","title":"invalid_exception"},{"location":"api/anonymizer_python/#presidio_anonymizer.entities.invalid_exception.InvalidParamException","text":"Throw exception with error when user input is not valid.","title":"InvalidParamException"},{"location":"api/image_redactor_python/","text":"Presidio Image Redactor API Reference ImageRedactorEngine class ImageRedactorEngine class only supporting redaction currently. redact ( self , image , fill = ( 0 , 0 , 0 )) Redact method to redact the given image. Please notice, this method duplicates the image, creates a new instance and manipulate it. Parameters: Name Type Description Default image <module 'PIL.Image' from '/opt/hostedtoolcache/Python/3.9.1/x64/lib/python3.9/site-packages/PIL/Image.py'> PIL Image to be processed required fill Union[int, Tuple[int, int, int]] colour to fill the shape - int (0-255) for grayscale or Tuple(R, G, B) for RGB (0, 0, 0) Returns: Type Description <module 'PIL.Image' from '/opt/hostedtoolcache/Python/3.9.1/x64/lib/python3.9/site-packages/PIL/Image.py'> the redacted image Source code in presidio_image_redactor/image_redactor_engine.py def redact ( self , image : Image , fill : Union [ int , Tuple [ int , int , int ]] = ( 0 , 0 , 0 ) ) -> Image : \"\"\"Redact method to redact the given image. Please notice, this method duplicates the image, creates a new instance and manipulate it. :param image: PIL Image to be processed :param fill: colour to fill the shape - int (0-255) for grayscale or Tuple(R, G, B) for RGB :return: the redacted image \"\"\" image = ImageChops . duplicate ( image ) bboxes = self . analyzer_engine . analyze ( image ) draw = ImageDraw . Draw ( image ) for box in bboxes : x0 = box . left y0 = box . top x1 = x0 + box . width y1 = y0 + box . height draw . rectangle ([ x0 , y0 , x1 , y1 ], fill = fill ) return image ImageAnalyzerEngine class ImageAnalyzerEngine class. analyze ( self , image , ** kwargs ) Analyse method to analyse the given image. Parameters: Name Type Description Default image object PIL Image/numpy array or file path(str) to be processed required Returns: Type Description List[presidio_image_redactor.entities.image_recognizer_result.ImageRecognizerResult] list of the extract entities with image bounding boxes Source code in presidio_image_redactor/image_analyzer_engine.py def analyze ( self , image : object , ** kwargs ) -> List [ ImageRecognizerResult ]: \"\"\"Analyse method to analyse the given image. :param image: PIL Image/numpy array or file path(str) to be processed :return: list of the extract entities with image bounding boxes \"\"\" ocr_result = OCR () . perform_ocr ( image ) text = OCR () . get_text_from_ocr_dict ( ocr_result ) analyzer = AnalyzerEngine () analyzer_result = analyzer . analyze ( text = text , language = \"en\" , ** kwargs ) bboxes = self . map_analyzer_results_to_bounding_boxes ( analyzer_result , ocr_result , text ) return bboxes map_analyzer_results_to_bounding_boxes ( text_analyzer_results , ocr_result , text ) staticmethod Map extracted PII entities to image bounding boxes. Matching is based on the position of the recognized entity from analyzer and word (in ocr dict) in the text. Parameters: Name Type Description Default text_analyzer_results List[presidio_analyzer.recognizer_result.RecognizerResult] PII entities recognized by presidio analyzer required ocr_result dict dict results with words and bboxes from OCR required text str text the results are based on return: list of extracted entities with image bounding boxes required Source code in presidio_image_redactor/image_analyzer_engine.py @staticmethod def map_analyzer_results_to_bounding_boxes ( text_analyzer_results : List [ RecognizerResult ], ocr_result : dict , text : str ) -> List [ ImageRecognizerResult ]: \"\"\"Map extracted PII entities to image bounding boxes. Matching is based on the position of the recognized entity from analyzer and word (in ocr dict) in the text. :param text_analyzer_results: PII entities recognized by presidio analyzer :param ocr_result: dict results with words and bboxes from OCR :param text: text the results are based on return: list of extracted entities with image bounding boxes \"\"\" if ( not ocr_result ) or ( not text_analyzer_results ): return [] bboxes = [] proc_indexes = 0 indexes = len ( text_analyzer_results ) pos = 0 iter_ocr = enumerate ( ocr_result [ \"text\" ]) for index , word in iter_ocr : if not word : pos += 1 else : for element in text_analyzer_results : text_element = text [ element . start : element . end ] # check position and text of ocr word matches recognized entity if ( max ( pos , element . start ) < min ( element . end , pos + len ( word )) ) and (( text_element in word ) or ( word in text_element )): bboxes . append ( ImageRecognizerResult ( element . entity_type , element . start , element . end , element . score , ocr_result [ \"left\" ][ index ], ocr_result [ \"top\" ][ index ], ocr_result [ \"width\" ][ index ], ocr_result [ \"height\" ][ index ], ) ) # add bounding boxes for all words in ocr dict # contained within the text of recognized entity # based on relative position in the full text while pos + len ( word ) < element . end : index , word = next ( iter_ocr ) if word : bboxes . append ( ImageRecognizerResult ( element . entity_type , element . start , element . end , element . score , ocr_result [ \"left\" ][ index ], ocr_result [ \"top\" ][ index ], ocr_result [ \"width\" ][ index ], ocr_result [ \"height\" ][ index ], ) ) pos += len ( word ) + 1 proc_indexes += 1 if proc_indexes == indexes : break pos += len ( word ) + 1 return bboxes","title":"Presidio Image Redactor Python API"},{"location":"api/image_redactor_python/#presidio-image-redactor-api-reference","text":"","title":"Presidio Image Redactor API Reference"},{"location":"api/image_redactor_python/#imageredactorengine-class","text":"ImageRedactorEngine class only supporting redaction currently.","title":"ImageRedactorEngine class"},{"location":"api/image_redactor_python/#presidio_image_redactor.image_redactor_engine.ImageRedactorEngine.redact","text":"Redact method to redact the given image. Please notice, this method duplicates the image, creates a new instance and manipulate it. Parameters: Name Type Description Default image <module 'PIL.Image' from '/opt/hostedtoolcache/Python/3.9.1/x64/lib/python3.9/site-packages/PIL/Image.py'> PIL Image to be processed required fill Union[int, Tuple[int, int, int]] colour to fill the shape - int (0-255) for grayscale or Tuple(R, G, B) for RGB (0, 0, 0) Returns: Type Description <module 'PIL.Image' from '/opt/hostedtoolcache/Python/3.9.1/x64/lib/python3.9/site-packages/PIL/Image.py'> the redacted image Source code in presidio_image_redactor/image_redactor_engine.py def redact ( self , image : Image , fill : Union [ int , Tuple [ int , int , int ]] = ( 0 , 0 , 0 ) ) -> Image : \"\"\"Redact method to redact the given image. Please notice, this method duplicates the image, creates a new instance and manipulate it. :param image: PIL Image to be processed :param fill: colour to fill the shape - int (0-255) for grayscale or Tuple(R, G, B) for RGB :return: the redacted image \"\"\" image = ImageChops . duplicate ( image ) bboxes = self . analyzer_engine . analyze ( image ) draw = ImageDraw . Draw ( image ) for box in bboxes : x0 = box . left y0 = box . top x1 = x0 + box . width y1 = y0 + box . height draw . rectangle ([ x0 , y0 , x1 , y1 ], fill = fill ) return image","title":"redact()"},{"location":"api/image_redactor_python/#imageanalyzerengine-class","text":"ImageAnalyzerEngine class.","title":"ImageAnalyzerEngine class"},{"location":"api/image_redactor_python/#presidio_image_redactor.image_analyzer_engine.ImageAnalyzerEngine.analyze","text":"Analyse method to analyse the given image. Parameters: Name Type Description Default image object PIL Image/numpy array or file path(str) to be processed required Returns: Type Description List[presidio_image_redactor.entities.image_recognizer_result.ImageRecognizerResult] list of the extract entities with image bounding boxes Source code in presidio_image_redactor/image_analyzer_engine.py def analyze ( self , image : object , ** kwargs ) -> List [ ImageRecognizerResult ]: \"\"\"Analyse method to analyse the given image. :param image: PIL Image/numpy array or file path(str) to be processed :return: list of the extract entities with image bounding boxes \"\"\" ocr_result = OCR () . perform_ocr ( image ) text = OCR () . get_text_from_ocr_dict ( ocr_result ) analyzer = AnalyzerEngine () analyzer_result = analyzer . analyze ( text = text , language = \"en\" , ** kwargs ) bboxes = self . map_analyzer_results_to_bounding_boxes ( analyzer_result , ocr_result , text ) return bboxes","title":"analyze()"},{"location":"api/image_redactor_python/#presidio_image_redactor.image_analyzer_engine.ImageAnalyzerEngine.map_analyzer_results_to_bounding_boxes","text":"Map extracted PII entities to image bounding boxes. Matching is based on the position of the recognized entity from analyzer and word (in ocr dict) in the text. Parameters: Name Type Description Default text_analyzer_results List[presidio_analyzer.recognizer_result.RecognizerResult] PII entities recognized by presidio analyzer required ocr_result dict dict results with words and bboxes from OCR required text str text the results are based on return: list of extracted entities with image bounding boxes required Source code in presidio_image_redactor/image_analyzer_engine.py @staticmethod def map_analyzer_results_to_bounding_boxes ( text_analyzer_results : List [ RecognizerResult ], ocr_result : dict , text : str ) -> List [ ImageRecognizerResult ]: \"\"\"Map extracted PII entities to image bounding boxes. Matching is based on the position of the recognized entity from analyzer and word (in ocr dict) in the text. :param text_analyzer_results: PII entities recognized by presidio analyzer :param ocr_result: dict results with words and bboxes from OCR :param text: text the results are based on return: list of extracted entities with image bounding boxes \"\"\" if ( not ocr_result ) or ( not text_analyzer_results ): return [] bboxes = [] proc_indexes = 0 indexes = len ( text_analyzer_results ) pos = 0 iter_ocr = enumerate ( ocr_result [ \"text\" ]) for index , word in iter_ocr : if not word : pos += 1 else : for element in text_analyzer_results : text_element = text [ element . start : element . end ] # check position and text of ocr word matches recognized entity if ( max ( pos , element . start ) < min ( element . end , pos + len ( word )) ) and (( text_element in word ) or ( word in text_element )): bboxes . append ( ImageRecognizerResult ( element . entity_type , element . start , element . end , element . score , ocr_result [ \"left\" ][ index ], ocr_result [ \"top\" ][ index ], ocr_result [ \"width\" ][ index ], ocr_result [ \"height\" ][ index ], ) ) # add bounding boxes for all words in ocr dict # contained within the text of recognized entity # based on relative position in the full text while pos + len ( word ) < element . end : index , word = next ( iter_ocr ) if word : bboxes . append ( ImageRecognizerResult ( element . entity_type , element . start , element . end , element . score , ocr_result [ \"left\" ][ index ], ocr_result [ \"top\" ][ index ], ocr_result [ \"width\" ][ index ], ocr_result [ \"height\" ][ index ], ) ) pos += len ( word ) + 1 proc_indexes += 1 if proc_indexes == indexes : break pos += len ( word ) + 1 return bboxes","title":"map_analyzer_results_to_bounding_boxes()"},{"location":"image-redactor/","text":"Presidio Image Redactor Please notice, this package is still in beta and not production ready. Description The Presidio Image Redactor is a Python based module for detecting and redacting PII text entities in images. Installation Pre-requisites: Install Tesseract OCR by following the instructions on how to install it for your operating system. !!! note \"Note\" For now, image redactor only supports version 4.0.0 Using pip Note Consider installing the Presidio python packages on a virtual environment like venv or conda. To get started with Presidio-image-redactor, download the package and the en_core_web_lg spaCy model: pip install presidio-image-redactor python -m spacy download en_core_web_lg Using Docker Note This requires Docker to be installed. Download Docker . # Download image from Dockerhub docker pull mcr.microsoft.com/presidio-image-redactor # Run the container with the default port docker run -d -p 5003 :5003 mcr.microsoft.com/presidio-image-redactor:latest From source First, clone the Presidio repo. See here for instructions . Then, build the presidio-image-redactor container: cd presidio-image-redactor docker build . -t presidio/presidio-image-redactor Getting started Python Once the Presidio-image-redactor package is installed, run this simple script: from PIL import Image from presidio_image_redactor import ImageRedactorEngine # Get the image to redact using PIL lib (pillow) image = Image . open ( \"ocr_text.png\" ) # Initialize the engine engine = ImageRedactorEngine () # Redact the image with pink color redacted_image = engine . redact ( image , ( 255 , 192 , 203 )) # save the redacted image redacted_image . save ( \"new_image.png\" ) # open the image for viewing redacted_image . show () As an HTTP server You can run presidio image redactor as an http server using either python runtime or using a docker container. Using docker container cd presidio-image-redactor docker run -p 5003 :5003 presidio-image-redactor Using python runtime Note This requires the Presidio Github repository to be cloned. cd presidio-image-redactor python app.py # use ocr_test.png as the image to redact, and 255 as the color fill. # out.png is the new redacted image received from the server. curl -XPOST \"http://localhost:3000/redact\" -H \"content-type: multipart/form-data\" -F \"image=@ocr_test.png\" -F \"data=\\\"{'color_fill':'255'}\\\"\" > out.png Python script example can be found under: /presidio/e2e-tests/tests/test_image_redactor.py API reference the API Spec for the Image Redactor REST API reference details and Image Redactor Python API for Python API reference","title":"Home"},{"location":"image-redactor/#presidio-image-redactor","text":"Please notice, this package is still in beta and not production ready.","title":"Presidio Image Redactor"},{"location":"image-redactor/#description","text":"The Presidio Image Redactor is a Python based module for detecting and redacting PII text entities in images.","title":"Description"},{"location":"image-redactor/#installation","text":"Pre-requisites: Install Tesseract OCR by following the instructions on how to install it for your operating system. !!! note \"Note\" For now, image redactor only supports version 4.0.0 Using pip Note Consider installing the Presidio python packages on a virtual environment like venv or conda. To get started with Presidio-image-redactor, download the package and the en_core_web_lg spaCy model: pip install presidio-image-redactor python -m spacy download en_core_web_lg Using Docker Note This requires Docker to be installed. Download Docker . # Download image from Dockerhub docker pull mcr.microsoft.com/presidio-image-redactor # Run the container with the default port docker run -d -p 5003 :5003 mcr.microsoft.com/presidio-image-redactor:latest From source First, clone the Presidio repo. See here for instructions . Then, build the presidio-image-redactor container: cd presidio-image-redactor docker build . -t presidio/presidio-image-redactor","title":"Installation"},{"location":"image-redactor/#getting-started","text":"Python Once the Presidio-image-redactor package is installed, run this simple script: from PIL import Image from presidio_image_redactor import ImageRedactorEngine # Get the image to redact using PIL lib (pillow) image = Image . open ( \"ocr_text.png\" ) # Initialize the engine engine = ImageRedactorEngine () # Redact the image with pink color redacted_image = engine . redact ( image , ( 255 , 192 , 203 )) # save the redacted image redacted_image . save ( \"new_image.png\" ) # open the image for viewing redacted_image . show () As an HTTP server You can run presidio image redactor as an http server using either python runtime or using a docker container.","title":"Getting started"},{"location":"image-redactor/#using-docker-container","text":"cd presidio-image-redactor docker run -p 5003 :5003 presidio-image-redactor","title":"Using docker container"},{"location":"image-redactor/#using-python-runtime","text":"Note This requires the Presidio Github repository to be cloned. cd presidio-image-redactor python app.py # use ocr_test.png as the image to redact, and 255 as the color fill. # out.png is the new redacted image received from the server. curl -XPOST \"http://localhost:3000/redact\" -H \"content-type: multipart/form-data\" -F \"image=@ocr_test.png\" -F \"data=\\\"{'color_fill':'255'}\\\"\" > out.png Python script example can be found under: /presidio/e2e-tests/tests/test_image_redactor.py","title":"Using python runtime"},{"location":"image-redactor/#api-reference","text":"the API Spec for the Image Redactor REST API reference details and Image Redactor Python API for Python API reference","title":"API reference"},{"location":"samples/","text":"Samples Usage Samples Running in a Python pipeline Running using Flask in Docker Deployment Samples Azure App service Kubernetes","title":"Samples Home"},{"location":"samples/#samples","text":"","title":"Samples"},{"location":"samples/#usage-samples","text":"Running in a Python pipeline Running using Flask in Docker","title":"Usage Samples"},{"location":"samples/#deployment-samples","text":"Azure App service Kubernetes","title":"Deployment Samples"},{"location":"samples/deployments/","text":"Example deployments Azure App Service Kubernetes","title":"Example deployments"},{"location":"samples/deployments/#example-deployments","text":"Azure App Service Kubernetes","title":"Example deployments"},{"location":"samples/deployments/app-service/","text":"Deploy presidio services to an Azure App Service Presidio containers can be hosted on an Azure App Service . Azure App Service provides a managed production environment, which supports docker containers and devops optimizations. It is a global scale service with built in security and compliance features that fits multiple cloud workloads. The presidio team uses Azure App Service for both its development environment and the presidio demo website. Deploy Presidio services to Azure Use the following button to deploy presidio services to your Azure subscription. Deploy using command-line script The following script can be used alternatively to the ARM template deployment above. It sets up the same components which are required for each of the presidio services (analyzer and anonymizer) as the template. Basic setup RESOURCE_GROUP = <resource group name> APP_SERVICE_NAME = <name of app service> LOCATION = <location> APP_SERVICE_SKU = <sku> IMAGE_NAME = mcr.microsoft.com/presidio-analyzer # the following parameters are only required if you build and deploy your own containers from a private registry ACR_USER_NAME = <user name> ACR_USER_PASSWORD = <password> # create the resource group az group create --name $RESOURCE_GROUP # create the app service plan az appservice plan create --name $APP_SERVICE_NAME -plan --resource-group $RESOURCE_GROUP \\ --is-linux --location $LOCATION --sku $APP_SERVICE_SKU # create the web app using the official presidio images az webapp create --name $APP_SERVICE_NAME --plan $APP_SERVICE_NAME -plan \\ --resource-group $RESOURCE_GROUP -i $IMAGE_NAME # or alternatively, if building presidio and deploying from a private container registry az webapp create --name $APP_SERVICE_NAME --plan $APP_SERVICE_NAME -plan \\ --resource-group $RESOURCE_GROUP -i $IMAGE_NAME -s $ACR_USER_NAME -w $ACR_USER_PASSWORD Blocking network access Use the following script to restrict network access for a specific ip such as your computer, a front-end website or an API management. FRONT_END_IP_RANGE =[ front end ip range ] az webapp config access-restriction add --resource-group $RESOURCE_GROUP --name $APP_SERVICE_NAME \\ --rule-name 'Front-end allow rule' --action Allow --ip-address $FRONT_END_IP_RANGE --priority 100 Further network isolation, using virtual networks, is possible using an Isolated tier of Azure App Service. Configure App Service Logging Logging to the App Service File System az webapp log config --name $APP_SERVICE_NAME --resource-group $RESOURCE_GROUP \\ --application-logging filesystem --detailed-error-messages true \\ --docker-container-logging filesystem --level information Logging to Log Analytics Workspace LOG_ANALYTICS_WORKSPACE_RESROUCE_GROUP = <resource group of log analytics> LOG_ANALYTICS_WORKSPACE_NAME = <log analytics name> # create a log analytics workspace az monitor log-analytics workspace create --resource-group $LOG_ANALYTICS_WORKSPACE_RESROUCE_GROUP --workspace-name $LOG_ANALYTICS_WORKSPACE_NAME # query the log analytics workspace id LOG_ANALYTICS_WORKSPACE_ID = $( az monitor log-analytics workspace show --resource-group $LOG_ANALYTICS_WORKSPACE_RESROUCE_GROUP --workspace-name $LOG_ANALYTICS_WORKSPACE_NAME --query id -o tsv ) # query the app service id APP_SERVICE_ID = $( az monitor log-analytics workspace show --resource-group $RESOURCE_GROUP --name $APP_SERVICE_NAME --query id -o tsv ) # create the diagnostics settings az monitor diagnostic-settings create --name $APP_SERVICE_NAME -diagnostics --resource / $APP_SERVICE_ID --logs '[{\"category\": \"AppServicePlatformLogs\",\"enabled\": true}, {\"category\": \"AppServiceConsoleLogs\", \"enabled\": true}]' --metrics '[{\"category\": \"AllMetrics\",\"enabled\": true}]' --workspace $LOG_ANALYTICS_WORKSPACE_ID Using an ARM template Alternatlively, you can use the provided ARM template which can deploy either both or any of the presidio services. Note that while Log Analytics integration with Azure App Service is in preview, the ARM template deployment will not create a Log Analytics resource or configure the diagnostics settings from the App Service to a Log Analytics workspace. To deploy the app services using the provided ARM template, fill in the provided values.json file with the required values and run the following script. az deployment group create --resource-group $RESOURCE_GROUP --template-file presidio-services.json --parameters @values.json","title":"Azure App Service"},{"location":"samples/deployments/app-service/#deploy-presidio-services-to-an-azure-app-service","text":"Presidio containers can be hosted on an Azure App Service . Azure App Service provides a managed production environment, which supports docker containers and devops optimizations. It is a global scale service with built in security and compliance features that fits multiple cloud workloads. The presidio team uses Azure App Service for both its development environment and the presidio demo website.","title":"Deploy presidio services to an Azure App Service"},{"location":"samples/deployments/app-service/#deploy-presidio-services-to-azure","text":"Use the following button to deploy presidio services to your Azure subscription.","title":"Deploy Presidio services to Azure"},{"location":"samples/deployments/app-service/#deploy-using-command-line-script","text":"The following script can be used alternatively to the ARM template deployment above. It sets up the same components which are required for each of the presidio services (analyzer and anonymizer) as the template.","title":"Deploy using command-line script"},{"location":"samples/deployments/app-service/#basic-setup","text":"RESOURCE_GROUP = <resource group name> APP_SERVICE_NAME = <name of app service> LOCATION = <location> APP_SERVICE_SKU = <sku> IMAGE_NAME = mcr.microsoft.com/presidio-analyzer # the following parameters are only required if you build and deploy your own containers from a private registry ACR_USER_NAME = <user name> ACR_USER_PASSWORD = <password> # create the resource group az group create --name $RESOURCE_GROUP # create the app service plan az appservice plan create --name $APP_SERVICE_NAME -plan --resource-group $RESOURCE_GROUP \\ --is-linux --location $LOCATION --sku $APP_SERVICE_SKU # create the web app using the official presidio images az webapp create --name $APP_SERVICE_NAME --plan $APP_SERVICE_NAME -plan \\ --resource-group $RESOURCE_GROUP -i $IMAGE_NAME # or alternatively, if building presidio and deploying from a private container registry az webapp create --name $APP_SERVICE_NAME --plan $APP_SERVICE_NAME -plan \\ --resource-group $RESOURCE_GROUP -i $IMAGE_NAME -s $ACR_USER_NAME -w $ACR_USER_PASSWORD","title":"Basic setup"},{"location":"samples/deployments/app-service/#blocking-network-access","text":"Use the following script to restrict network access for a specific ip such as your computer, a front-end website or an API management. FRONT_END_IP_RANGE =[ front end ip range ] az webapp config access-restriction add --resource-group $RESOURCE_GROUP --name $APP_SERVICE_NAME \\ --rule-name 'Front-end allow rule' --action Allow --ip-address $FRONT_END_IP_RANGE --priority 100 Further network isolation, using virtual networks, is possible using an Isolated tier of Azure App Service.","title":"Blocking network access"},{"location":"samples/deployments/app-service/#configure-app-service-logging","text":"","title":"Configure App Service Logging"},{"location":"samples/deployments/app-service/#logging-to-the-app-service-file-system","text":"az webapp log config --name $APP_SERVICE_NAME --resource-group $RESOURCE_GROUP \\ --application-logging filesystem --detailed-error-messages true \\ --docker-container-logging filesystem --level information","title":"Logging to the App Service File System"},{"location":"samples/deployments/app-service/#logging-to-log-analytics-workspace","text":"LOG_ANALYTICS_WORKSPACE_RESROUCE_GROUP = <resource group of log analytics> LOG_ANALYTICS_WORKSPACE_NAME = <log analytics name> # create a log analytics workspace az monitor log-analytics workspace create --resource-group $LOG_ANALYTICS_WORKSPACE_RESROUCE_GROUP --workspace-name $LOG_ANALYTICS_WORKSPACE_NAME # query the log analytics workspace id LOG_ANALYTICS_WORKSPACE_ID = $( az monitor log-analytics workspace show --resource-group $LOG_ANALYTICS_WORKSPACE_RESROUCE_GROUP --workspace-name $LOG_ANALYTICS_WORKSPACE_NAME --query id -o tsv ) # query the app service id APP_SERVICE_ID = $( az monitor log-analytics workspace show --resource-group $RESOURCE_GROUP --name $APP_SERVICE_NAME --query id -o tsv ) # create the diagnostics settings az monitor diagnostic-settings create --name $APP_SERVICE_NAME -diagnostics --resource / $APP_SERVICE_ID --logs '[{\"category\": \"AppServicePlatformLogs\",\"enabled\": true}, {\"category\": \"AppServiceConsoleLogs\", \"enabled\": true}]' --metrics '[{\"category\": \"AllMetrics\",\"enabled\": true}]' --workspace $LOG_ANALYTICS_WORKSPACE_ID","title":"Logging to Log Analytics Workspace"},{"location":"samples/deployments/app-service/#using-an-arm-template","text":"Alternatlively, you can use the provided ARM template which can deploy either both or any of the presidio services. Note that while Log Analytics integration with Azure App Service is in preview, the ARM template deployment will not create a Log Analytics resource or configure the diagnostics settings from the App Service to a Log Analytics workspace. To deploy the app services using the provided ARM template, fill in the provided values.json file with the required values and run the following script. az deployment group create --resource-group $RESOURCE_GROUP --template-file presidio-services.json --parameters @values.json","title":"Using an ARM template"},{"location":"samples/deployments/k8s/","text":"Deploy presidio to Kubernetes You can install Presidio locally using KIND , as a service in Kubernetes or AKS . Deploy locally using KIND Deploy with Kubernetes Prerequisites Step by Step Deployment with customizable parameters Deploy locally with KIND KIND (Kubernetes IN Docker) . Install Docker . Clone Presidio. Run the following script, which will use KIND (Kubernetes emulation in Docker) cd docs/samples/deployments/k8s/deployment/ ./run-with-kind.sh Wait and verify all pods are running: kubectl get pod -n presidio Port forwarding of HTTP requests to the API micro-service will be done automatically. In order to run manual: kubectl port-forward <presidio-analyzer-pod-name> 8080 :8080 -n presidio Presidio As a Service with Kubernetes Prerequisites A Kubernetes 1.18+ cluster with RBAC enabled. If you are using AKS RBAC is enabled by default. !!! note: Note Note the pod's resources requirements (CPU and memory) and plan the cluster accordingly. kubectl installed. Verify you can communicate with the cluster by running: kubectl version Local helm client. Optional - Container Registry - such as ACR . Only needed if you are using your own presidio images and not the default ones from from Microsoft syndicates container catalog Recent presidio repo is cloned on your local machine. Step by step deployment with customizable parameters Install Helm with RBAC . Optional - Ingress controller for presidio API, e.g., NGINX . Note: Presidio is not deployed with an ingress controller by default. to change this behavior, deploy the helm chart with ingress.enabled=true and specify they type of ingress controller to be used with ingress.class=nginx (supported classes are: nginx ). Deploy from /docs/samples/deployments/k8s/charts/presidio # Based on the DOCKER_REGISTRY and PRESIDIO_LABEL from the previous steps helm install --name demo --set registry = ${ DOCKER_REGISTRY } ,tag = ${ PRESIDIO_LABEL } . --namespace presidio","title":"Kubernetes"},{"location":"samples/deployments/k8s/#deploy-presidio-to-kubernetes","text":"You can install Presidio locally using KIND , as a service in Kubernetes or AKS . Deploy locally using KIND Deploy with Kubernetes Prerequisites Step by Step Deployment with customizable parameters","title":"Deploy presidio to Kubernetes"},{"location":"samples/deployments/k8s/#deploy-locally-with-kind","text":"KIND (Kubernetes IN Docker) . Install Docker . Clone Presidio. Run the following script, which will use KIND (Kubernetes emulation in Docker) cd docs/samples/deployments/k8s/deployment/ ./run-with-kind.sh Wait and verify all pods are running: kubectl get pod -n presidio Port forwarding of HTTP requests to the API micro-service will be done automatically. In order to run manual: kubectl port-forward <presidio-analyzer-pod-name> 8080 :8080 -n presidio","title":"Deploy locally with KIND"},{"location":"samples/deployments/k8s/#presidio-as-a-service-with-kubernetes","text":"","title":"Presidio As a Service with Kubernetes"},{"location":"samples/deployments/k8s/#prerequisites","text":"A Kubernetes 1.18+ cluster with RBAC enabled. If you are using AKS RBAC is enabled by default. !!! note: Note Note the pod's resources requirements (CPU and memory) and plan the cluster accordingly. kubectl installed. Verify you can communicate with the cluster by running: kubectl version Local helm client. Optional - Container Registry - such as ACR . Only needed if you are using your own presidio images and not the default ones from from Microsoft syndicates container catalog Recent presidio repo is cloned on your local machine.","title":"Prerequisites"},{"location":"samples/deployments/k8s/#step-by-step-deployment-with-customizable-parameters","text":"Install Helm with RBAC . Optional - Ingress controller for presidio API, e.g., NGINX . Note: Presidio is not deployed with an ingress controller by default. to change this behavior, deploy the helm chart with ingress.enabled=true and specify they type of ingress controller to be used with ingress.class=nginx (supported classes are: nginx ). Deploy from /docs/samples/deployments/k8s/charts/presidio # Based on the DOCKER_REGISTRY and PRESIDIO_LABEL from the previous steps helm install --name demo --set registry = ${ DOCKER_REGISTRY } ,tag = ${ PRESIDIO_LABEL } . --namespace presidio","title":"Step by step deployment with customizable parameters"},{"location":"samples/docker/","text":"Using Presidio in Docker Description Presidio can expose REST endpoints for each service using Flask and Docker. Follow the installation guide to learn how to install and run presidio-analyzer and presidio-anonymizer using docker. Postman collection This repository contains a postman collection with sample REST API request for each service. Follow this tutorial to learn how to export the sample requests into postman Download Presidio Analyzer postman requests Download Presidio Anonymizer postman requests Sample API Calls Simple Text Analysis curl -X POST http://localhost:5002/analyze -H \"Content-type: application/json\" --data \"{ \\\"text\\\": \\\"John Smith drivers license is AC432223\\\", \\\"language\\\" : \\\"en\\\"}\" Simple Text Anonymization curl -X POST http://localhost:5001/anonymize -H \"Content-type: application/json\" --data \"{\\\"text\\\": \\\"hello world, my name is Jane Doe. My number is: 034453334\\\", \\\"analyzer_results\\\": [{\\\"start\\\": 24, \\\"end\\\": 32, \\\"score\\\": 0.8, \\\"entity_type\\\": \\\"NAME\\\"}, { \\\"start\\\": 48, \\\"end\\\": 57, \\\"score\\\": 0.95,\\\"entity_type\\\": \\\"PHONE_NUMBER\\\" }], \\\"anonymizers\\\": {\\\"DEFAULT\\\": { \\\"type\\\": \\\"replace\\\", \\\"new_value\\\": \\\"ANONYMIZED\\\" },\\\"PHONE_NUMBER\\\": { \\\"type\\\": \\\"mask\\\", \\\"masking_char\\\": \\\"*\\\", \\\"chars_to_mask\\\": 4, \\\"from_end\\\": true }}}\"","title":"Docker"},{"location":"samples/docker/#using-presidio-in-docker","text":"","title":"Using Presidio in Docker"},{"location":"samples/docker/#description","text":"Presidio can expose REST endpoints for each service using Flask and Docker. Follow the installation guide to learn how to install and run presidio-analyzer and presidio-anonymizer using docker.","title":"Description"},{"location":"samples/docker/#postman-collection","text":"This repository contains a postman collection with sample REST API request for each service. Follow this tutorial to learn how to export the sample requests into postman Download Presidio Analyzer postman requests Download Presidio Anonymizer postman requests","title":"Postman collection"},{"location":"samples/docker/#sample-api-calls","text":"","title":"Sample API Calls"},{"location":"samples/docker/#simple-text-analysis","text":"curl -X POST http://localhost:5002/analyze -H \"Content-type: application/json\" --data \"{ \\\"text\\\": \\\"John Smith drivers license is AC432223\\\", \\\"language\\\" : \\\"en\\\"}\"","title":"Simple Text Analysis"},{"location":"samples/docker/#simple-text-anonymization","text":"curl -X POST http://localhost:5001/anonymize -H \"Content-type: application/json\" --data \"{\\\"text\\\": \\\"hello world, my name is Jane Doe. My number is: 034453334\\\", \\\"analyzer_results\\\": [{\\\"start\\\": 24, \\\"end\\\": 32, \\\"score\\\": 0.8, \\\"entity_type\\\": \\\"NAME\\\"}, { \\\"start\\\": 48, \\\"end\\\": 57, \\\"score\\\": 0.95,\\\"entity_type\\\": \\\"PHONE_NUMBER\\\" }], \\\"anonymizers\\\": {\\\"DEFAULT\\\": { \\\"type\\\": \\\"replace\\\", \\\"new_value\\\": \\\"ANONYMIZED\\\" },\\\"PHONE_NUMBER\\\": { \\\"type\\\": \\\"mask\\\", \\\"masking_char\\\": \\\"*\\\", \\\"chars_to_mask\\\": 4, \\\"from_end\\\": true }}}\"","title":"Simple Text Anonymization"},{"location":"samples/python/","text":"Using Presidio in a Python script Description Presidio service can be used as python packages inside python scripts Table of contents Jupiter notebook Remote Recognizer","title":"Python"},{"location":"samples/python/#using-presidio-in-a-python-script","text":"","title":"Using Presidio in a Python script"},{"location":"samples/python/#description","text":"Presidio service can be used as python packages inside python scripts","title":"Description"},{"location":"samples/python/#table-of-contents","text":"Jupiter notebook Remote Recognizer","title":"Table of contents"}]}